{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5XDBefNIgZE7"
      },
      "source": [
        "## Scientific Computing 2023: Homework Assignment 2\n",
        "Due Sunday October 22, 2023 (23:59)\n",
        "\n",
        "### Problem 1 (2 points)\n",
        "Let $A_q=\\left(\\begin{matrix}1 & q\\\\ 0 & 1\\end{matrix}\\right)$ with $q\\in\\mathbb R$.\n",
        "* For any $q$, find condition number $\\kappa(A_q)$ with respect to the $l^2$-norm.\n",
        "* Give an example of specific values of $q,\\mathbf b, \\Delta\\mathbf b$ such that, when solving $A_q\\mathbf x = \\mathbf b$ and $A_q(\\mathbf x+\\Delta \\mathbf x)=\\mathbf b +\\Delta\\mathbf b$, we get\n",
        "\n",
        "$$\\frac{\\|\\Delta \\mathbf x\\|}{\\|\\mathbf x\\|}\\ge 10^6\\frac{\\|\\Delta\\mathbf b\\|}{\\|\\mathbf b\\|}.$$"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Answer 1"
      ],
      "metadata": {
        "id": "LQB0eDLyVZ5n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* If $\\|\\cdot\\|$ is the $l^2$-norm and $A$ is arbitrary, then\n",
        "\n",
        "$$\\kappa(A)=\\sqrt{\\frac{\\lambda_{\\max}(A^*A)}{\\lambda_{\\min}(A^*A)}}$$\n",
        "\n",
        "$A^* A = \\left(\\begin{matrix}1 & 0\\\\ q & 1\\end{matrix}\\right) \\left(\\begin{matrix}1 & q\\\\ 0 & 1\\end{matrix}\\right) = \\left(\\begin{matrix}1 & q\\\\ q & q^2 + 1\\end{matrix}\\right)$.\n",
        "\n",
        "In order to obtain $\\lambda_i$, we need to solve next equation: $$det(A^*A -\\lambda I) = det\\left(\\begin{matrix}1 -\\lambda& q\\\\ q & q^2 + 1-\\lambda\\end{matrix}\\right) = 0$$\n",
        "\n",
        "\n",
        "\n",
        "$$ 4q^2+1- \\lambda -\\lambda q^2 -\\lambda+ \\lambda^2 -q^2 = 0$$\n",
        "\n",
        "$$ \\lambda^2 - \\lambda(2+q^2) +1 =0 $$\n",
        "\n",
        "Then we obtain the eigenvalues: $\\lambda_{max,min} = \\frac{1}{2} (2+q^2 \\pm \\sqrt{q^4+4q^2})$.\n",
        "So the condition number with respect to the $l^2$-norm:\n",
        "\n",
        "$$\\kappa(A_q) =\\sqrt{\\frac{\\lambda_{\\max}(A^*A)}{\\lambda_{\\min}(A^*A)}} =  \\sqrt{\\frac{2+q^2 + \\sqrt{q^4 + 4q^2}}{2+q^2 -\\sqrt{q^4 + 4q^2}}}$$\n",
        "\n",
        "* Let the values be as follows:\n",
        "\n",
        "$\\mathbf b =  \\left(\\begin{matrix}10^7 & 1\\end{matrix}\\right)^T$,\n",
        "\n",
        "$\\Delta\\mathbf b =  \\left(\\begin{matrix}10^8 & 10^9\\end{matrix}\\right)^T$,\n",
        "\n",
        "$q = 10^{10} $\n",
        "\n",
        "Let's calculate $\\frac{\\|\\Delta \\mathbf{x}\\|}{\\|\\mathbf{x}\\|}/\\frac{\\|\\Delta \\mathbf{b}\\|}{\\|\\mathbf{b}\\|}$ and compare it with $10^6$:\n"
      ],
      "metadata": {
        "id": "UqT3I-qHVTC-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "q = 10**10\n",
        "A = np.array([[1,q],[0,1]])\n",
        "b = np.array([10**7,1])\n",
        "d_b = np.array([10**8,10**9])\n",
        "\n",
        "x_norm = np.linalg.norm(np.dot(np.linalg.inv(A), b))\n",
        "d_x_norm = np.linalg.norm(np.dot(np.linalg.inv(A), d_b))\n",
        "b_norm = np.linalg.norm(b)\n",
        "d_b_norm =np.linalg.norm(d_b)\n",
        "\n",
        "#lets calculate the fraction of fractions of norms to compare it with 10^6\n",
        "fraction = (d_x_norm/x_norm) / (d_b_norm/b_norm)\n",
        "\n",
        "\n",
        "print(f'{fraction:.2e} is greater than 10^6, so considered parameters b, d_b and q satisfy the task.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4iGeQ0jVR8q",
        "outputId": "9479728a-9088-44ff-865a-02dbf12dfebc"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9.96e+06 is greater than 10^6, so considered parameters b, d_b and q satisfy the task.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6jKRLB72gZFE"
      },
      "source": [
        "### Problem 2 (2 points)\n",
        "* Write a program to compute an approximate value for the derivative of a function using the finite-difference formula\n",
        "\n",
        "  $$f'(x)\\approx \\frac{f(x+h)-f(x)}{h}.$$\n",
        "\n",
        "  Test your program using the function $\\tan(x)$ at $x=1$. Determine the error by comparing with the value obtained using the analytic derivative. Plot the magnitude of the error as a function of $h$, for $h=10^{-k}, k=0,\\ldots,16$. You should use log scale for $h$ and for the magnitude of the error. What is the minimum value of the error and at which $h$ is it achieved? Explain this result theoretically.\n",
        "* Repeat the exercise using the centered difference approximation\n",
        "\n",
        " $$f'(x)\\approx \\frac{f(x+h)-f(x-h)}{2h}.$$\n",
        "\n",
        " What is now different and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Answer 2"
      ],
      "metadata": {
        "id": "qAReavS4V1CA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def tan_derivative(x):\n",
        "    return 1/(np.cos(x))**2\n",
        "\n",
        "def finite_difference(f, x, h):\n",
        "    return (f(x + h) - f(x))/h\n",
        "\n",
        "def centered_difference(f, x, h):\n",
        "    return (f(x + h) - f(x - h))/(2 *h)\n",
        "\n",
        "h_list = []\n",
        "er_finite = []\n",
        "\n",
        "for k in range(17):\n",
        "    h_list.append(10**(-k))\n",
        "    er_finite.append(np.abs(finite_difference(np.tan, 1, h_list[k]) - tan_derivative(1)))\n",
        "\n",
        "fig = plt.figure(figsize=[7,3])\n",
        "plt.scatter(h_list, er_finite, color = 'black')\n",
        "plt.xlabel('h')\n",
        "plt.ylabel('er')\n",
        "plt.gca().set_xscale('log')\n",
        "plt.gca().set_yscale('log');\n",
        "\n",
        "print(f' Min error: {min(er_finite).round(11)}, h of min error: {h_list[er_finite.index(min(er_finite))]}.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "id": "13aHY4vBWBYB",
        "outputId": "c16e96be-6416-4488-ff63-66f4485d6651"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Min error: 2.554e-08, h of min error: 1e-08.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 700x300 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In addition to approximation errors, which increase with increasing step h, rounding errors occur, which, on the contrary, increase with decreasing grid step (i.e., with increasing number of steps).\n"
      ],
      "metadata": {
        "id": "MSKmf4-kHkVp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets use centered difference approximation instead of finite-difference\n",
        "\n",
        "h_list = []\n",
        "er_cent = []\n",
        "\n",
        "for k in range(17):\n",
        "    h_list.append(10**(-k))\n",
        "    er_cent.append(np.abs(centered_difference(np.tan, 1, h_list[k]) - tan_derivative(1)))\n",
        "\n",
        "fig = plt.figure(figsize=[7,3])\n",
        "plt.scatter(h_list, er_cent)\n",
        "plt.xlabel('h')\n",
        "plt.ylabel('er')\n",
        "plt.gca().set_xscale('log')\n",
        "plt.gca().set_yscale('log');\n",
        "\n",
        "print(f' Min error: {min(er_cent).round(15)}, h of min error: {h_list[er_cent.index(min(er_cent))]}.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "lxyHA2TbHlDI",
        "outputId": "70a12f88-902a-46a5-ed4b-64626d0e912f"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Min error: 6.224e-12, h of min error: 1e-07.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 700x300 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Let's explain results theoretically.\n",
        "Since $\\tilde f (x + h) = f (x + h) + \\varepsilon_1$ and $\\tilde f (x − h) = f (x − h) + \\varepsilon_2$, where $|\\varepsilon_1|$,|$\\varepsilon_2$| ≈\n",
        "$\\varepsilon_r,$ where $\\varepsilon_r$ represents machine epsilon; the difference between the correct f(x) and the machine version of the\n",
        "finite-difference formula:\n",
        "\n",
        "$$f'_{correct}(x) - {f'}_{machine} (x) = f'(x) - \\dfrac{\\tilde{f}(x+h) -\\tilde{f}(x)}{h} = f'(x) - \\dfrac{f(x+h) + \\varepsilon_1 - f(x) - \\varepsilon_2}{h} =$$\n",
        "\n",
        "$$=f'(x) - \\dfrac{f(x+h) - f(x)}{h} + \\dfrac{\\varepsilon_2 - \\varepsilon_1}{h} = \\text{[apply Taylor Series for  $f(x+h)$, c $\\in [x, x+h]$]} =\\\\\n",
        "= -\\dfrac{h}{2} f''(c) + \\dfrac{\\varepsilon_2 - \\varepsilon_1}{h} $$\n",
        "\n",
        "$$\\left|\\dfrac{\\varepsilon_2 - \\varepsilon_1}{h}\\right| \\leq\\dfrac{2 \\varepsilon_r}{h}$$\n",
        "\n",
        "Then absolute value of error: $Er(h)\\equiv  \\dfrac{h}{2} |f''(c)| + \\dfrac{2 \\varepsilon_r}{h}$\n",
        "\n",
        "Let's differentiate $Er(h)$ in order to obtain its minimum: $$\\frac{dEr(h)}{dh} = \\dfrac{\\left|f''(c)\\right|}{2} - \\dfrac{2 \\varepsilon_r}{h^2} = 0,$$\n",
        "\n",
        "$$h_0 = 2 \\sqrt{\\dfrac{\\varepsilon_r}{\\left|f''(c)\\right|}}=[f(x)=tan (x)] \\approx 9.124 \\cdot 10^{-9}.$$\n",
        "\n",
        "$$Er(h_0) \\approx 9.735 \\cdot 10^{-8}.$$\n",
        "\n",
        "Similarly for centered difference formula we get:\n",
        "\n",
        "$Er(h)\\equiv  \\dfrac{h^2}{6} |f'''(c)| + \\dfrac{\\varepsilon_r}{h}$, $c \\in [x-h,x+h]$\n",
        "\n",
        "Let's differentiate $Er(h)$ in order to obtain its minimum: $$\\frac{dEr(h)}{dh} = \\dfrac{h\\left| f'''(c)\\right|}{3} - \\dfrac{\\varepsilon_r}{h^2} = 0,$$\n",
        "\n",
        "$$h_0 = \\left( \\dfrac{3 \\varepsilon_r}{\\left|f'''(c)\\right|} \\right)^{\\frac{1}{3}} =[f(x)=tan (x)] \\approx 2.273 \\cdot 10^{-6}.$$\n",
        "\n",
        "$$Er(h_0) \\approx 1.465 \\cdot 10^{-10}.$$\n",
        "\n",
        "As we can see, the experimentally obtained values are approximately consistent with the theory.\n",
        "For centered difference formula we obtaibed much less minimum value of error than for finite-difference version, and the minimum was achieved at smaller h-value."
      ],
      "metadata": {
        "id": "x0F6OcaJV96O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# code for calculating of h0 and Er(h0) mentioned above\n",
        "\n",
        "#  finite-difference version\n",
        "h0 = 2*np.sqrt(np.finfo(float).eps/abs(2*np.sin(1)/(np.cos(1)**3))).round(12)\n",
        "Er_h0 = (h0*abs(abs(2*np.sin(1)/(np.cos(1)**3)))/2 + 2*np.finfo(float).eps/h0).round(11)\n",
        "print(f'finite-difference version: h0 = {h0}, Er(h0) = {Er_h0}')\n",
        "\n",
        "# centered difference version\n",
        "h0 = ((3 * np.finfo(float).eps/abs((2 + 4 * np.sin(1)**2)/(np.cos(1)**4)))**(1/3)).round(9)\n",
        "Er_h0 = (h0**2*abs((2 + 4 * np.sin(1)**2)/(np.cos(1)**4))/6 + np.finfo(float).eps/h0).round(13)\n",
        "print(f'centered difference version: h0 = {h0}, Er(h0) = {Er_h0}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ozr_qszMWRT8",
        "outputId": "d8569293-bf70-4c56-e03f-763eb420fd9a"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "finite-difference version: h0 = 9.124e-09, Er(h0) = 9.735e-08\n",
            "centered difference version: h0 = 2.273e-06, Er(h0) = 1.465e-10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OlohFH9bgZFG"
      },
      "source": [
        "### Problem 3 (2 points)\n",
        "* Implement regularized regression with an adaptive choice of regularization parameter. Your algorithm must accept the training data (`Xtrain`, `Ytrain`) and the input part of test data (`Xtest`), and output a prediction for test data (`Ypred`). You may use standard linear algebra libraries, but not specialized predictive modeling software (e.g., `scikit-learn`). Your algorithm should choose the regularization parameter by some optimization over a reasonable range of values and may use a sub-division of the training data into a train-in-train and a test-in-train components.\n",
        "* Test your algorithm on real data from UCI repository:\n",
        "  * https://archive.ics.uci.edu/ml/datasets/Relative+location+of+CT+slices+on+axial+axis\n",
        "  * https://archive.ics.uci.edu/ml/datasets/Physicochemical+Properties+of+Protein+Tertiary+Structure\n",
        "  \n",
        "  Use random subsets of 300 rows as training sets, and the remaining rows as the test sets. Use the relative RMS error as the measure of accuracy.\n",
        "  Compare your results with results of some linear models implemented in standard predictive modeling software    (e.g., `Ridge` and `LinearRegression` from `scikit-learn`)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Answer 3"
      ],
      "metadata": {
        "id": "ocX0eHTEWWnP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_fit(X_train, y_train, mu):\n",
        "    Q = X_train.T.dot(X_train)\n",
        "    y1 = X_train.T.dot(y_train)\n",
        "\n",
        "    return np.linalg.inv(Q+mu*np.eye(X_train.shape[1])).dot(y1)\n",
        "\n",
        "def custom_predict(X_test, coeffs):\n",
        "    return X_test.dot(coeffs)\n",
        "\n",
        "def getRRMSE(y_test, y_pred):\n",
        "    return np.linalg.norm(y_pred-y_test)/np.linalg.norm(y_test-np.mean(y_test))\n",
        "\n",
        "# Implementing deafult kfold gridsearch with number of splits = 5\n",
        "def custom_gridsearch(X_train, y_train, X_test):\n",
        "    n_splits = 5\n",
        "    fold = Ntrain // n_splits\n",
        "    RRMSEs = []\n",
        "    mus = np.logspace(-6, 2, 100)\n",
        "\n",
        "    for mu in mus:\n",
        "        RRMSE = 0\n",
        "\n",
        "        for n in range(n_splits):\n",
        "            X_train_fold = np.concatenate((X_train[0:n*fold], X_train[(n+1)*fold: Ntrain]))\n",
        "            y_train_fold = np.concatenate((y_train[0:n*fold], y_train[(n+1)*fold: Ntrain]))\n",
        "\n",
        "            X_test_fold = X_train[n*fold: (n+1)*fold]\n",
        "            y_test_fold = y_train[n*fold: (n+1)*fold]\n",
        "\n",
        "            coefs = custom_fit(X_train_fold, y_train_fold, mu)\n",
        "            y_pred_fold = custom_predict(X_test_fold, coefs)\n",
        "            RRMSE += getRRMSE(y_test_fold, y_pred_fold)\n",
        "\n",
        "        RRMSEs.append(RRMSE)\n",
        "\n",
        "    mu_best = mus[np.argmin(RRMSEs)]\n",
        "    coeffs = custom_fit(X_train, y_train, mu_best)\n",
        "    y_pred = custom_predict(X_test, coeffs)\n",
        "\n",
        "    return y_pred"
      ],
      "metadata": {
        "id": "V1EsqCvvWZhn"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing on first dataset\n",
        "\n",
        "data = np.loadtxt('slice_localization_data.csv', skiprows=1, delimiter=',')\n",
        "\n",
        "N = len(data)\n",
        "X = data[:, 1:-1] # input values\n",
        "y = data[:, -1]\n",
        "\n",
        "Ntrain = 300\n",
        "\n",
        "inds = np.random.permutation(N)\n",
        "\n",
        "train = inds[:Ntrain]\n",
        "test = inds[Ntrain:]\n",
        "X_train = X[train]\n",
        "y_train = y[train]\n",
        "X_test = X[test]\n",
        "y_test = y[test]"
      ],
      "metadata": {
        "id": "xAz39VuEWdiS"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Comparing results of algorithm with results of linear models from sklearn\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Custom algorithm (custom ridge + custom gridsearch)\n",
        "y_pred = custom_gridsearch(X_train, y_train, X_test)\n",
        "print(f'Custom algorithm RRMSE: {getRRMSE(y_test, y_pred).round(3)}')\n",
        "\n",
        "# Gridsearch Ridge\n",
        "grid = {\n",
        "    'alpha':np.logspace(-6,2,100)\n",
        "}\n",
        "gs = GridSearchCV(Ridge(), param_grid=grid)\n",
        "gs.fit(X_train, y_train)\n",
        "print(f'Ridge() RRMSE: {getRRMSE(y_test, gs.predict(X_test)).round(3)}')\n",
        "\n",
        "# Linear regression without gridsearch\n",
        "clf = LinearRegression()\n",
        "clf.fit(X_train, y_train)\n",
        "print(f'LinearRegression() RRMSE: {getRRMSE(y_test, clf.predict(X_test)).round(3)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O5s_OxbiXI0u",
        "outputId": "2b7f3694-2f47-476a-84ac-d7a06c932caf"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Custom algorithm RRMSE: 0.483\n",
            "Ridge() RRMSE: 0.452\n",
            "LinearRegression() RRMSE: 1.216\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing using second dataset\n",
        "\n",
        "data = np.loadtxt('CASP.csv', skiprows=1, delimiter=',')\n",
        "N = len(data)\n",
        "X = data[:, 1:] # input values\n",
        "y = data[:, 0] # output values\n",
        "\n",
        "Ntrain = 300\n",
        "\n",
        "inds = np.random.permutation(N)\n",
        "\n",
        "train = inds[:Ntrain]\n",
        "test = inds[Ntrain:]\n",
        "X_train = X[train]\n",
        "y_train = y[train]\n",
        "X_test = X[test]\n",
        "y_test = y[test]"
      ],
      "metadata": {
        "id": "i2S2Ys9fnlpE"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Custom algorithm (custom ridge + custom gridsearch)\n",
        "y_pred = custom_gridsearch(X_train, y_train, X_test)\n",
        "print(f'Custom algorithm RRMSE: {getRRMSE(y_test, y_pred).round(3)}')\n",
        "\n",
        "# Gridsearch Ridge\n",
        "grid = {\n",
        "    'alpha':np.logspace(-6,2,100)\n",
        "}\n",
        "gs = GridSearchCV(Ridge(), param_grid=grid)\n",
        "gs.fit(X_train, y_train)\n",
        "print(f'Ridge() RRMSE: {getRRMSE(y_test, gs.predict(X_test)).round(3)}')\n",
        "\n",
        "# Linear regression without gridsearch\n",
        "clf = LinearRegression()\n",
        "clf.fit(X_train, y_train)\n",
        "print(f'LinearRegression() RRMSE: {getRRMSE(y_test, clf.predict(X_test)).round(3)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bCnLfNAonrmN",
        "outputId": "b7580161-2705-4fe1-b675-b5afa68f161b"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Custom algorithm RRMSE: 0.898\n",
            "Ridge() RRMSE: 0.902\n",
            "LinearRegression() RRMSE: 0.902\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Values for our algorithm are close to values for sklearn ridge for both datasets."
      ],
      "metadata": {
        "id": "FZsp8h-tH3XZ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3l6EgKSAgZFI"
      },
      "source": [
        "### Problem 4 (2 points)\n",
        "Suppose that we use the Leapfrog algorithm with some $\\Delta t$ to simulate the dynamics of the harmonic oscillator (https://en.wikipedia.org/wiki/Harmonic_oscillator) with positive mass $m$ and force constant $k$ (in other words, with the energy function $H=\\frac{m\\dot x^2}{2}+\\frac{kx^2}{2}$). Assuming a perfect implementation of Leapfrog, at which combinations of $\\Delta t, m, k$ will the simulation diverge as $n\\to\\infty$, in the sense that $\\sup_n(\\tilde x_n^2+\\tilde v_{n+1/2}^2)=\\infty$?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Answer 4"
      ],
      "metadata": {
        "id": "7R20QPMEn05f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Leapfrog integration method:\n",
        "\n",
        "\\begin{align}\n",
        "\\tilde x_{n+1} &= \\tilde x_{n}+\\tilde v_{n+1/2}\\Delta t\\\\\n",
        "\\tilde v_{n+1/2} &= \\tilde v_{n-1/2}+f_1(\\tilde x_n)\\Delta t\n",
        "\\end{align}\n",
        "\n",
        "Considering dynamics of the harmonic oscillator we want to solve next system:\n",
        "\n",
        "$$\\frac{d}{dt}{x\\choose v}={v\\choose f_1(x)}= {v\\choose -\\frac{kx}{m}}$$\n",
        "\n",
        "\\begin{align}\n",
        "\\tilde x_{n+1} &= \\tilde x_{n}+\\tilde v_{n+1/2}\\Delta t\\\\\n",
        "\\tilde v_{n+1/2} &= \\tilde v_{n-1/2} -\\frac{k}{m}\\tilde x_n\\Delta t\n",
        "\\end{align}\n",
        "$$\\Downarrow$$\n",
        "\n",
        "$$\\left(\\begin{matrix}\\tilde x_{n+1}\\\\ \\tilde v_{n+1/2}\\end{matrix}\\right)=\\left(\\begin{matrix}1 - \\frac{k}{m} {\\Delta t}^2 &\\Delta t\\\\-\\frac{k}{m}\\Delta t & 1 \\end{matrix}\\right) \\left(\\begin{matrix}\\tilde x_{n}\\\\ \\tilde v_{n-1/2}\\end{matrix}\\right)$$\n",
        "\n",
        "$$\\det\\left(\\begin{matrix}1 - \\frac{k}{m} {\\Delta t}^2 - \\lambda &\\Delta t\\\\-\\frac{k}{m}\\Delta t & 1 - \\lambda \\end{matrix}\\right) = 0$$\n",
        "\n",
        "We form a basis from the eigenvectors, decompose the initial condition according to this basis, then we move forward using a matrix, the matrix acts on the eigenvectors by multiplying by the eigenvalue, after n steps of the algorithm, we multiply the eigenvectors by the eigenvalues n times.\n",
        "\n",
        "Let's say $\\lambda_{1,2}$ - eigenvalues matrix, $\\textbf{y}_{1,2}$ eigenvectors, then\n",
        "\n",
        "$$\\left(\\begin{matrix}\\tilde x_{n+1}\\\\ \\tilde v_{n+1/2} \\end{matrix}\\right) = {\\lambda_1}^n \\textbf{y}_{1} + {\\lambda_2}^n \\textbf{y}_{2},$$\n",
        "\n",
        "$$\\text{where  }\\lambda_{1,2} = \\frac{2-\\frac{k\\Delta t^2}{m} \\pm \\sqrt{\\frac{k^2\\Delta t^4}{m^2} - \\frac{4k\\Delta t^2}{m}}}{2}$$\n",
        "\n",
        "In case of $\\frac{k{\\Delta t}^2}{m}  > 4$ one can notice, that $|\\lambda|>1$, so $|\\lambda^n|\\to\\inf, $ if $n \\to \\inf$; so simulation diverge as  $𝑛 \\to \\infty$, in the sense that $\\sup_n(\\tilde x_n^2+\\tilde v_{n+1/2}^2)=\\infty$.\n",
        "\n",
        "Answer: $\\frac{k{\\Delta t}^2}{m}  > 4$"
      ],
      "metadata": {
        "id": "OPCaFA_goEhX"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0JlnITqYgZFJ"
      },
      "source": [
        "### Problem 5 (2 points)\n",
        "Suppose that we are solving the ODE $\\frac{d}{dt}\\mathbf {x}=f(\\mathbf x)$ (with, generally, a vector-valued $\\mathbf x(t)$) by iterations\n",
        "\n",
        "$$\\left\\{\\begin{align}\\mathbf k &= f(\\tilde{\\mathbf x}_{n})\\Delta t\\\\\n",
        "\\tilde {\\mathbf x}_{n+1} &= \\tilde {\\mathbf x}_{n}+f(\\tilde{\\mathbf x}_{n}+\\tfrac{1}{2}\\mathbf k)\\Delta t\n",
        "\\end{align}\\right.$$\n",
        "\n",
        "Find the global convergence order of this method, and verify it experimentally."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Answer 5\n",
        "\n",
        "Reforming the ODE with the given system and a time step $ h $, and the solution $ y_n $ at the $ n $th time step, let's say that we wish to compute $ y_{n+1} $ in the following fashion:\n",
        "\n",
        "$$ k_1 = hf(y_n, t_n) \\\\\n",
        "k_2 = hf(y_n, + βk_1, t_{n} + \\alpha h) \\\\\n",
        "y_{n+1} = y_{n} + ak_{1} + bk_{2} $$\n",
        "\n",
        "where the constants $ \\alpha $, $ β $, a and b have to be evaluated so that the resulting method has $ O(h3) $. Note that if $ k_{2}=0 $ and $ a=1 $, then next equation reduces to the forward Euler method:\n",
        "\n",
        "Now, let's write down the Taylor series expansion of $ y $ in the neighborhood of $ t_n $ correct to the $ h^2 $ term:\n",
        "\n",
        "$$ y(t_{n+1}) = y(t_n) + h\\frac{dy}{dt}|t_n + \\frac{h^2 d^2y}{2dt^2}|t_n + O(h^{3}) $$\n",
        "\n",
        "However, we know that $ dy/dt = f(y,t) $ so that\n",
        "\n",
        "$$ \\frac{d^2y}{dt^2} = \\frac{df(y, t)}{dt} = \\frac{\\partial f}{\\partial t} + \\frac{\\partial f dy}{\\partial y dt} = \\frac{\\partial f}{\\partial t} + f\\frac{\\partial f}{\\partial y} $$\n",
        "\n",
        "So from the above analysis, we get\n",
        "\n",
        "$$ y_{n+1} = y_n + hf(y_n, t_n) + \\frac{h^2}{2} \\Big[\\frac{\\partial f}{\\partial t} + f\\frac{\\partial f}{\\partial y}\\Big] (y_n, t_n) + O(h^3)  $$\n",
        "\n",
        "However, the term $ k_2 $ in the proposed Runge Kutta(RK) method of first equation can be expanded correct to $ O(h^{3}) $ as\n",
        "\n",
        "$$ k_2 = hf(y_n + βk_1, t_n + αh) \\\\\n",
        "= h \\Big( f(y_n, t_n) + αh\\frac{\\partial f}{\\partial t}(y_n, t_n) + βk_1\\frac{\\partial f}{\\partial t}(y_n, t_n) \\Big) + O(h^{3}) $$\n",
        "\n",
        "Now, substituting for $ k_2 $ from previous equations, we get\n",
        "\n",
        "$$ y_{n+1} = y_n + (a+b)hf(y_n, t_n) + bh^2(α\\frac{\\partial f}{\\partial t} + βf\\frac{\\partial f}{\\partial t})(y_n, t_n) + O(h^{3}) $$\n",
        "\n",
        "Comparing the terms with identical coefficients gives us the following system of equations to determine the constants:\n",
        "\n",
        "$$ a + b = 1 \\\\\n",
        "αb = \\frac{1}{2} \\\\\n",
        "βb = \\frac{1}{2} $$\n",
        "\n",
        "There are infinitely many choices of a, b, $\\alpha$ and $\\beta$ which satisfy, we can choose for instance $\\alpha = \\beta = 1$ and $ a=b=\\frac{1}{2} $. With this choice, we have the classical second order accurate Runge-Kutta method (RK2). In a sequence, with a similar fashion Runge-Kutta methods of higher order can be developed."
      ],
      "metadata": {
        "id": "OyEza3gw3HRH"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U2i4k4Mf4NqD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}