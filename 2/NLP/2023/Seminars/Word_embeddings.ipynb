{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMpWuwAzaipN"
      },
      "source": [
        "# Credits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HlnWEwBdMbTR"
      },
      "source": [
        "\n",
        "\n",
        "The seminar includes materials from  the following sources:\n",
        "\n",
        "* [Kaggle competition for \"Women's E-Commerce Clothing Reviews\" TF-IDF kernel](https://www.kaggle.com/shivam1600/simple-information-retrieval-using-tf-idf-and-lsa)\n",
        "* [Information retrival: TF-IDF Ranking](https://github.com/williamscott701/Information-Retrieval/blob/master/2.%20TF-IDF%20Ranking%20-%20Cosine%20Similarity,%20Matching%20Score/TF-IDF.ipynb)\n",
        "* [YDS word vectors seminar](https://github.com/yandexdataschool/nlp_course/tree/2019/week01_embeddings)\n",
        "* [Lena Voita's Word Embeddings Lecture](https://drive.google.com/file/d/1y2GKIKBzie7l8iycBO6gTKGiTTfJc4Dr/view)\n",
        "* [Word2Vec Pytorch implementation](https://github.com/blackredscarf/pytorch-SkipGram)\n",
        "* [Doc2Vec tutorial](https://github.com/RaRe-Technologies/gensim/blob/ca0dcaa1eca8b1764f6456adac5719309e0d8e6d/docs/notebooks/doc2vec-IMDB.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bu7utHtZaCf2"
      },
      "source": [
        "# Downloads"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSATTTPcu43h"
      },
      "source": [
        "Prerequisite download:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TIrZTb7uu50f"
      },
      "outputs": [],
      "source": [
        "# For Count-based models section\n",
        "!wget https://raw.githubusercontent.com/dardem/word2vec_seminar/master/Womens%20Clothing%20E-Commerce%20Reviews.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_pSWoe-8u5tl"
      },
      "outputs": [],
      "source": [
        "# For Word2Vec section\n",
        "!wget http://mattmahoney.net/dc/text8.zip\n",
        "!unzip text8.zip\n",
        "!wget https://github.com/blackredscarf/pytorch-SkipGram/raw/master/data_utils.py\n",
        "!wget https://github.com/blackredscarf/pytorch-SkipGram/raw/master/vector_handle.py\n",
        "!wget https://github.com/dardem/word2vec_seminar/raw/master/eval.zip\n",
        "!unzip eval.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uwnWO5Juu5lc"
      },
      "outputs": [],
      "source": [
        "# For Pretrained models examples\n",
        "\n",
        "# English\n",
        "!wget https://www.dropbox.com/s/obaitrix9jyu84r/quora.txt?dl=1 -O ./quora.txt\n",
        "!wget nlp.stanford.edu/data/wordvecs/glove.6B.zip\n",
        "!unzip glove.6B.zip\n",
        "\n",
        "# Russian\n",
        "!wget http://vectors.nlpl.eu/repository/20/214.zip\n",
        "!unzip 214.zip -d ru_fasttext_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-jd6kfJMvh4"
      },
      "source": [
        "# Vector text representation: Motivation\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GM_1pDZyS0JE"
      },
      "source": [
        "<img src=\"https://github.com/dardem/word2vec_seminar/raw/master/img/Vector-representation-motivation.png\" style=\"width:100%\">\n",
        "\n",
        "Source: https://drive.google.com/file/d/1y2GKIKBzie7l8iycBO6gTKGiTTfJc4Dr/view"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VoEHSqWBOeDx"
      },
      "source": [
        "# Count-based models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wq2hLeMSCLlO"
      },
      "source": [
        "<img src=\"https://github.com/dardem/word2vec_seminar/raw/master/img/td-idf-idea.png\" style=\"width:100%\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5CTrVJKUS1VH"
      },
      "source": [
        "We are going to solve the **task**:\n",
        "*   the dataset of products reviews is given;\n",
        "*   find the most similar review from this dataset to the given query."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1pE4jkMTxULr"
      },
      "source": [
        "## Data preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wUToade_s_G-"
      },
      "outputs": [],
      "source": [
        "# Data download\n",
        "# !wget https://raw.githubusercontent.com/dardem/word2vec_seminar/master/Womens%20Clothing%20E-Commerce%20Reviews.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5yLYKHcrt1yQ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "reviews = pd.read_csv('Womens Clothing E-Commerce Reviews.csv', index_col=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ppsD6kcQyILQ",
        "outputId": "8a8bc9ad-0630-48c1-e7a1-37bca6c07fdd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(23486, 10)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "reviews.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "wI7BKT8EwZdm",
        "outputId": "7e0d0a10-eb81-4350-f698-dc8f4efaf283"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Clothing ID</th>\n",
              "      <th>Age</th>\n",
              "      <th>Title</th>\n",
              "      <th>Review Text</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Recommended IND</th>\n",
              "      <th>Positive Feedback Count</th>\n",
              "      <th>Division Name</th>\n",
              "      <th>Department Name</th>\n",
              "      <th>Class Name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>767</td>\n",
              "      <td>33</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Absolutely wonderful - silky and sexy and comf...</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Initmates</td>\n",
              "      <td>Intimate</td>\n",
              "      <td>Intimates</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1080</td>\n",
              "      <td>34</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Love this dress!  it's sooo pretty.  i happene...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>General</td>\n",
              "      <td>Dresses</td>\n",
              "      <td>Dresses</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1077</td>\n",
              "      <td>60</td>\n",
              "      <td>Some major design flaws</td>\n",
              "      <td>I had such high hopes for this dress and reall...</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>General</td>\n",
              "      <td>Dresses</td>\n",
              "      <td>Dresses</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1049</td>\n",
              "      <td>50</td>\n",
              "      <td>My favorite buy!</td>\n",
              "      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>General Petite</td>\n",
              "      <td>Bottoms</td>\n",
              "      <td>Pants</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>847</td>\n",
              "      <td>47</td>\n",
              "      <td>Flattering shirt</td>\n",
              "      <td>This shirt is very flattering to all due to th...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>General</td>\n",
              "      <td>Tops</td>\n",
              "      <td>Blouses</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Clothing ID  Age                    Title  \\\n",
              "0          767   33                      NaN   \n",
              "1         1080   34                      NaN   \n",
              "2         1077   60  Some major design flaws   \n",
              "3         1049   50         My favorite buy!   \n",
              "4          847   47         Flattering shirt   \n",
              "\n",
              "                                         Review Text  Rating  Recommended IND  \\\n",
              "0  Absolutely wonderful - silky and sexy and comf...       4                1   \n",
              "1  Love this dress!  it's sooo pretty.  i happene...       5                1   \n",
              "2  I had such high hopes for this dress and reall...       3                0   \n",
              "3  I love, love, love this jumpsuit. it's fun, fl...       5                1   \n",
              "4  This shirt is very flattering to all due to th...       5                1   \n",
              "\n",
              "   Positive Feedback Count   Division Name Department Name Class Name  \n",
              "0                        0       Initmates        Intimate  Intimates  \n",
              "1                        4         General         Dresses    Dresses  \n",
              "2                        0         General         Dresses    Dresses  \n",
              "3                        0  General Petite         Bottoms      Pants  \n",
              "4                        6         General            Tops    Blouses  "
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "reviews.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEeo7KkGxWRW"
      },
      "source": [
        "## Classic preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZojzmK1Yx4Hb",
        "outputId": "eeb4bcff-cb5e-4c53-c097-317be7287400"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /home/moskovskii/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /home/moskovskii/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to\n",
            "[nltk_data]     /home/moskovskii/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "wordnet_lemmatizer = WordNetLemmatizer()\n",
        "tokenizer = RegexpTokenizer(r'[a-z]+')\n",
        "stop_words = set(stopwords.words('english'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vcp7UL8KQmqP",
        "outputId": "295b2b7d-c323-479e-c1e8-bf0ef399a386"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['и', 'в', 'во', 'не', 'что', 'он', 'на', 'я', 'с', 'со']"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "stopwords.words('russian')[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "4xNxKJFHQOmZ",
        "jupyter": {
          "outputs_hidden": true
        },
        "tags": [],
        "outputId": "23066545-a0be-42fb-ed5b-b6bd42e57f03"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'a',\n",
              " 'about',\n",
              " 'above',\n",
              " 'after',\n",
              " 'again',\n",
              " 'against',\n",
              " 'ain',\n",
              " 'all',\n",
              " 'am',\n",
              " 'an',\n",
              " 'and',\n",
              " 'any',\n",
              " 'are',\n",
              " 'aren',\n",
              " \"aren't\",\n",
              " 'as',\n",
              " 'at',\n",
              " 'be',\n",
              " 'because',\n",
              " 'been',\n",
              " 'before',\n",
              " 'being',\n",
              " 'below',\n",
              " 'between',\n",
              " 'both',\n",
              " 'but',\n",
              " 'by',\n",
              " 'can',\n",
              " 'couldn',\n",
              " \"couldn't\",\n",
              " 'd',\n",
              " 'did',\n",
              " 'didn',\n",
              " \"didn't\",\n",
              " 'do',\n",
              " 'does',\n",
              " 'doesn',\n",
              " \"doesn't\",\n",
              " 'doing',\n",
              " 'don',\n",
              " \"don't\",\n",
              " 'down',\n",
              " 'during',\n",
              " 'each',\n",
              " 'few',\n",
              " 'for',\n",
              " 'from',\n",
              " 'further',\n",
              " 'had',\n",
              " 'hadn',\n",
              " \"hadn't\",\n",
              " 'has',\n",
              " 'hasn',\n",
              " \"hasn't\",\n",
              " 'have',\n",
              " 'haven',\n",
              " \"haven't\",\n",
              " 'having',\n",
              " 'he',\n",
              " 'her',\n",
              " 'here',\n",
              " 'hers',\n",
              " 'herself',\n",
              " 'him',\n",
              " 'himself',\n",
              " 'his',\n",
              " 'how',\n",
              " 'i',\n",
              " 'if',\n",
              " 'in',\n",
              " 'into',\n",
              " 'is',\n",
              " 'isn',\n",
              " \"isn't\",\n",
              " 'it',\n",
              " \"it's\",\n",
              " 'its',\n",
              " 'itself',\n",
              " 'just',\n",
              " 'll',\n",
              " 'm',\n",
              " 'ma',\n",
              " 'me',\n",
              " 'mightn',\n",
              " \"mightn't\",\n",
              " 'more',\n",
              " 'most',\n",
              " 'mustn',\n",
              " \"mustn't\",\n",
              " 'my',\n",
              " 'myself',\n",
              " 'needn',\n",
              " \"needn't\",\n",
              " 'no',\n",
              " 'nor',\n",
              " 'not',\n",
              " 'now',\n",
              " 'o',\n",
              " 'of',\n",
              " 'off',\n",
              " 'on',\n",
              " 'once',\n",
              " 'only',\n",
              " 'or',\n",
              " 'other',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'out',\n",
              " 'over',\n",
              " 'own',\n",
              " 're',\n",
              " 's',\n",
              " 'same',\n",
              " 'shan',\n",
              " \"shan't\",\n",
              " 'she',\n",
              " \"she's\",\n",
              " 'should',\n",
              " \"should've\",\n",
              " 'shouldn',\n",
              " \"shouldn't\",\n",
              " 'so',\n",
              " 'some',\n",
              " 'such',\n",
              " 't',\n",
              " 'than',\n",
              " 'that',\n",
              " \"that'll\",\n",
              " 'the',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'them',\n",
              " 'themselves',\n",
              " 'then',\n",
              " 'there',\n",
              " 'these',\n",
              " 'they',\n",
              " 'this',\n",
              " 'those',\n",
              " 'through',\n",
              " 'to',\n",
              " 'too',\n",
              " 'under',\n",
              " 'until',\n",
              " 'up',\n",
              " 've',\n",
              " 'very',\n",
              " 'was',\n",
              " 'wasn',\n",
              " \"wasn't\",\n",
              " 'we',\n",
              " 'were',\n",
              " 'weren',\n",
              " \"weren't\",\n",
              " 'what',\n",
              " 'when',\n",
              " 'where',\n",
              " 'which',\n",
              " 'while',\n",
              " 'who',\n",
              " 'whom',\n",
              " 'why',\n",
              " 'will',\n",
              " 'with',\n",
              " 'won',\n",
              " \"won't\",\n",
              " 'wouldn',\n",
              " \"wouldn't\",\n",
              " 'y',\n",
              " 'you',\n",
              " \"you'd\",\n",
              " \"you'll\",\n",
              " \"you're\",\n",
              " \"you've\",\n",
              " 'your',\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves'}"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "stop_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QxY3VYEDxY6q"
      },
      "outputs": [],
      "source": [
        "def preprocess(document):\n",
        "    \"\"\"\n",
        "    TODO: write your preprocessing function, including following steps:\n",
        "    - convert the whole text to the lowercase;\n",
        "    - tokenize the text;\n",
        "    - remove stopwords;\n",
        "    - lemmatize the text.\n",
        "    Return: string, resulted list of tokens joined with the space.\n",
        "    \"\"\"\n",
        "\n",
        "    document = document.lower() # Convert to lowercase\n",
        "    words = tokenizer.tokenize(document) # Tokenize\n",
        "    words = [w for w in words if not w in stop_words] # Removing stopwords\n",
        "    # Lemmatizing\n",
        "    for pos in [wordnet.NOUN, wordnet.VERB, wordnet.ADJ, wordnet.ADV]:\n",
        "        words = [wordnet_lemmatizer.lemmatize(x, pos) for x in words]\n",
        "    return \" \".join(words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "M_XaXHQu0xPQ",
        "outputId": "08725e88-039a-43b4-c0f9-015376a98331"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Recommended IND</th>\n",
              "      <th>Review Text</th>\n",
              "      <th>Processed Review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>I really wanted this to work. alas, it had a s...</td>\n",
              "      <td>really want work ala strange fit strap would s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>I love cute summer dresses and this one, espec...</td>\n",
              "      <td>love cute summer dress one especially make lin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>This is the perfect summer dress. it can be dr...</td>\n",
              "      <td>perfect summer dress dress quality linen fabri...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>Nice fit and flare style, not clingy at all. i...</td>\n",
              "      <td>nice fit flare style clingy get grey color pet...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>When i first opened this dress and tried it on...</td>\n",
              "      <td>first open dress try think adorable flat hourg...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Recommended IND                                        Review Text  \\\n",
              "0                0  I really wanted this to work. alas, it had a s...   \n",
              "1                1  I love cute summer dresses and this one, espec...   \n",
              "2                1  This is the perfect summer dress. it can be dr...   \n",
              "3                1  Nice fit and flare style, not clingy at all. i...   \n",
              "4                0  When i first opened this dress and tried it on...   \n",
              "\n",
              "                                    Processed Review  \n",
              "0  really want work ala strange fit strap would s...  \n",
              "1  love cute summer dress one especially make lin...  \n",
              "2  perfect summer dress dress quality linen fabri...  \n",
              "3  nice fit flare style clingy get grey color pet...  \n",
              "4  first open dress try think adorable flat hourg...  "
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# We are reducing the size of our dataset to decrease the running time of code\n",
        "reviews_pr = reviews.loc[reviews['Clothing ID'] == 1078 , :]\n",
        "reviews_pr\n",
        "\n",
        "# Delete missing observations for variables that we will be working with\n",
        "for x in [\"Recommended IND\",\"Review Text\"]:\n",
        "    reviews_pr = reviews_pr[reviews_pr[x].notnull()]\n",
        "\n",
        "# Keeping only those features that we will explore\n",
        "reviews_pr = reviews_pr[[\"Recommended IND\",\"Review Text\"]]\n",
        "\n",
        "# Resetting the index\n",
        "reviews_pr.index = pd.Series(list(range(reviews_pr.shape[0])))\n",
        "\n",
        "reviews_pr['Processed Review'] = reviews_pr['Review Text'].apply(preprocess)\n",
        "\n",
        "reviews_pr.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwnp2PfIHWBw"
      },
      "source": [
        "Let's look how our texts have changed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "erljsmEPFGAP"
      },
      "outputs": [],
      "source": [
        "from IPython.display import HTML, display"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VEBwrV4IFGy-"
      },
      "outputs": [],
      "source": [
        "def texts_comparison(text1, text2):\n",
        "    hdr = ''\n",
        "    hdr += '<th style=\"width:50%\">' + 'Original Text' + '</th>'\n",
        "    hdr += '<th style=\"width:50%\">' + 'Preprocessed Text' + '</th>'\n",
        "    hdr = '<tr style=\"background-color:#cbcdd1\">' + hdr + '</tr>'\n",
        "\n",
        "    dt = ''\n",
        "    dt = dt + '<tr>'\n",
        "    dt += '<td style=\"vertical-align:top\">' + text1 + '</td>'\n",
        "    dt += '<td style=\"vertical-align:top\">' + text2 + '</td>'\n",
        "    dt = dt + '</tr>'\n",
        "\n",
        "    display(HTML('<table style=\"width:80%\">' + hdr + dt + '</table>'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113
        },
        "id": "2MKf6_0fF1IV",
        "outputId": "771bcf53-07a0-4cf7-faf8-d2d314c1202b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<table style=\"width:80%\"><tr style=\"background-color:#cbcdd1\"><th style=\"width:50%\">Original Text</th><th style=\"width:50%\">Preprocessed Text</th></tr><tr><td style=\"vertical-align:top\">This knit dress is very comfortable. i liked the various colors used in the stripes. my only issue with it, is that the skirt of the dress flares out oddly and is quite short. in my opinion, this dress, with its sturdy fabric and long sleeves, would appear more proportional with a longer skirt. skirt length, along with horizontal stripes just did not work for me. regrettably, i sent it back.</td><td style=\"vertical-align:top\">knit dress comfortable like various color use stripe issue skirt dress flare oddly quite short opinion dress sturdy fabric long sleeve would appear proportional long skirt skirt length along horizontal stripe work regrettably send back</td></tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "texts_comparison(reviews_pr.iloc[13]['Review Text'], reviews_pr.iloc[13]['Processed Review']) #TODO: play with the index, notice the difference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bBhLEPzw0Cr"
      },
      "source": [
        "## Explicit implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnkZ0v9fQXtE"
      },
      "source": [
        "A small reminder:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QekNJ_nUQgGS"
      },
      "source": [
        "Our goal is to calculates:\n",
        "\n",
        "$tf$-$idf(t,d,D) = tf(t,d) \\times idf(t,D)$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "genow-UsQ8uI"
      },
      "source": [
        "So, the terms from this formula are:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Td1ehH7iPjnB"
      },
      "source": [
        "$tf(t,d) = \\frac{n_t}{\\sum_k n_k}$,\n",
        "\n",
        "where $n_t$ -- the number of word $t$ occurances in the document $d$, in the denominator -- total number of words in the documents set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gI52jErQ62L"
      },
      "source": [
        "$idf(t,D) = \\log \\frac{|D|}{|\\{d_i \\in D| t \\in d_i \\}|}$,\n",
        "\n",
        "where $|D|$ -- the total number of documents in the collection, $|\\{d_i \\in D| t \\in d_i \\}|$ -- the number of document from the collection $D$, where the word $t$ occures."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Oz4yuqH2m3m"
      },
      "source": [
        "1. Calculate DF for all words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K4Hbj8U92uN0"
      },
      "outputs": [],
      "source": [
        "# We want to save here the structure\n",
        "# where the keys are the tokens\n",
        "# and the values are the number of documents\n",
        "# where this token occures\n",
        "DF = {}\n",
        "\n",
        "for index, row in reviews_pr.iterrows():\n",
        "\n",
        "    tokens = row['Processed Review'].split(' ')\n",
        "    for token in tokens:\n",
        "        try:\n",
        "            DF[token].add(index)\n",
        "        except:\n",
        "            DF[token] = {index}\n",
        "\n",
        "for token in DF:\n",
        "    DF[token] = len(DF[token])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LqvofdMeYzUm",
        "outputId": "d0adcc57-557d-4eff-936b-1861de73c7de"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2529"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(DF.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E2KFVgmuQg44"
      },
      "outputs": [],
      "source": [
        "total_vocab = list(DF.keys())  # just saving the whole set of tokens in the collection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ty_h494CIoxt"
      },
      "outputs": [],
      "source": [
        "def doc_freq(token):\n",
        "    \"\"\"\n",
        "    Returns the number of documents where the given token occures.\n",
        "    \"\"\"\n",
        "\n",
        "    result = 0\n",
        "    try:\n",
        "        result = DF[token]\n",
        "    except KeyError as e:\n",
        "        pass\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQvbMcnI2ukp"
      },
      "source": [
        "2. Calculate TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kg3n4kloVKS2"
      },
      "outputs": [],
      "source": [
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NM3pzSi5aGLX",
        "outputId": "4c63d90b-8a78-48af-8d51-01959b9cf264"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Counter({'text': 2,\n",
              "         'the': 2,\n",
              "         'Some': 1,\n",
              "         'sample': 1,\n",
              "         'for': 1,\n",
              "         'Counter': 1,\n",
              "         'application': 1,\n",
              "         'illustration': 1,\n",
              "         'using': 1})"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text = \"Some sample text for the Counter application illustration using the text\"\n",
        "tokens = text.split(' ')\n",
        "Counter(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cC5xwg5e2voU"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "tf_idf = {} # We want to save here the structure where the keys are the tuple (doc, token) and the values are tf-idf.\n",
        "# Hint: you can use Counter for number of token occuranes calculation.\n",
        "\n",
        "for index, row in reviews_pr.iterrows():\n",
        "\n",
        "    tokens = row['Processed Review'].split(' ')\n",
        "\n",
        "    counter = Counter(tokens)\n",
        "    tokens_count = len(tokens) # the total number of words in this document\n",
        "\n",
        "    for token in np.unique(tokens):\n",
        "        tf = counter[token] / tokens_count\n",
        "        df = doc_freq(token)\n",
        "        idf = np.log((reviews_pr.shape[0]+1) / (df+1)) # we add +1 to avoid possible division by zero\n",
        "\n",
        "        tf_idf[index, token] = tf * idf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kt6BTh8VVWTr",
        "outputId": "0421d713-ba03-444e-e0aa-e93480130ef9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "25688"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(tf_idf.keys()) # check the obtained length of the structure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KXbRY7DucSv8",
        "outputId": "242dd8eb-07aa-4a9b-a48f-fe34257b8983"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.010038179740060304"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf_idf[(17, 'dress')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IoZgSPSJZFaT"
      },
      "outputs": [],
      "source": [
        "D = np.zeros((reviews_pr.shape[0], len(total_vocab))) # Matrix documents*words\n",
        "# Here we want to transform our dict into the matrix to compare the results.\n",
        "\n",
        "for key in tf_idf:\n",
        "    try:\n",
        "        token_idx = total_vocab.index(key[1])\n",
        "        D[key[0]][token_idx] = tf_idf[key]\n",
        "    except:\n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "nMPTD0rzTuo_",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "6599d296-067f-4408-c99b-f89d7f1def8a",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{(0, 'ala'): 0.250426742573999,\n",
              " (0, 'beautiful'): 0.09218855669510387,\n",
              " (0, 'breast'): 0.250426742573999,\n",
              " (0, 'fabric'): 0.06508413148737535,\n",
              " (0, 'fell'): 0.1689831303363601,\n",
              " (0, 'fit'): 0.0788549252288336,\n",
              " (0, 'love'): 0.046143168697598526,\n",
              " (0, 'minute'): 0.2189200525485469,\n",
              " (0, 'pocket'): 0.15315100786962302,\n",
              " (0, 'really'): 0.08753951809872124,\n",
              " (0, 'shoulder'): 0.1251158168798334,\n",
              " (0, 'sit'): 0.18465769789507505,\n",
              " (0, 'stand'): 0.19348297127875497,\n",
              " (0, 'stay'): 0.20444488295224986,\n",
              " (0, 'strange'): 0.1772704738269944,\n",
              " (0, 'strap'): 0.16712758513089396,\n",
              " (0, 'want'): 0.10741287293611873,\n",
              " (0, 'weird'): 0.19348297127875497,\n",
              " (0, 'work'): 0.17829170587428875,\n",
              " (0, 'would'): 0.07104381384011357,\n",
              " (1, 'although'): 0.11289267767375506,\n",
              " (1, 'book'): 0.17721530049108347,\n",
              " (1, 'bust'): 0.07864422775303813,\n",
              " (1, 'c'): 0.09543813246452724,\n",
              " (1, 'curvy'): 0.09162294981811232,\n",
              " (1, 'cute'): 0.05929717520408088,\n",
              " (1, 'design'): 0.07646214264490744,\n",
              " (1, 'difficult'): 0.13123136013582348,\n",
              " (1, 'dress'): 0.00975137460463001,\n",
              " (1, 'especially'): 0.10505162493941907,\n",
              " (1, 'fit'): 0.02478297650049056,\n",
              " (1, 'flat'): 0.04278628560657471,\n",
              " (1, 'foot'): 0.12602217279885336,\n",
              " (1, 'france'): 0.17721530049108347,\n",
              " (1, 'get'): 0.044656111556642814,\n",
              " (1, 'give'): 0.0830485328909598,\n",
              " (1, 'italy'): 0.17721530049108347,\n",
              " (1, 'linen'): 0.13123136013582348,\n",
              " (1, 'little'): 0.05603453613191931,\n",
              " (1, 'love'): 0.029004277467061926,\n",
              " (1, 'make'): 0.09420906431927895,\n",
              " (1, 'material'): 0.0629809947291064,\n",
              " (1, 'one'): 0.05385849724718891,\n",
              " (1, 'perfect'): 0.05028240744850303,\n",
              " (1, 'quite'): 0.09308847251489948,\n",
              " (1, 'size'): 0.03081632965099039,\n",
              " (1, 'summer'): 0.06942213083123669,\n",
              " (1, 'ticket'): 0.1656305831165645,\n",
              " (1, 'unique'): 0.09543813246452724,\n",
              " (1, 'wear'): 0.030061093734757374,\n",
              " (1, 'well'): 0.11952352302940634,\n",
              " (1, 'zip'): 0.12161786766093169,\n",
              " (2, 'adjust'): 0.21144979141255069,\n",
              " (2, 'bust'): 0.1101019188542534,\n",
              " (2, 'dress'): 0.013651924446482014,\n",
              " (2, 'fabric'): 0.05727403570889031,\n",
              " (2, 'find'): 0.10207509103576737,\n",
              " (2, 'front'): 0.11553398050061589,\n",
              " (2, 'go'): 0.07675795821309174,\n",
              " (2, 'hit'): 0.11553398050061589,\n",
              " (2, 'knee'): 0.09955853801934458,\n",
              " (2, 'linen'): 0.1837239041901529,\n",
              " (2, 'lovely'): 0.12928484206472884,\n",
              " (2, 'might'): 0.14707227491518668,\n",
              " (2, 'nice'): 0.08708735305811093,\n",
              " (2, 'perfect'): 0.07039537042790424,\n",
              " (2, 'quality'): 0.09955853801934458,\n",
              " (2, 'right'): 0.0953929276492407,\n",
              " (2, 'run'): 0.08205982445157106,\n",
              " (2, 'size'): 0.0862857230227731,\n",
              " (2, 'small'): 0.07063135931299178,\n",
              " (2, 'summer'): 0.09719098316373137,\n",
              " (2, 'tie'): 0.13719787179792564,\n",
              " (2, 'true'): 0.10704699970287043,\n",
              " (2, 'want'): 0.09452332818378448,\n",
              " (3, 'accessorize'): 0.28985352045398793,\n",
              " (3, 'boot'): 0.13095082893659063,\n",
              " (3, 'booty'): 0.16560818796458787,\n",
              " (3, 'clingy'): 0.21653666701431656,\n",
              " (3, 'color'): 0.1327338193986771,\n",
              " (3, 'fit'): 0.08674041775171697,\n",
              " (3, 'flare'): 0.17999229158717694,\n",
              " (3, 'get'): 0.07814819522412493,\n",
              " (3, 'grey'): 0.22488937124747485,\n",
              " (3, 'large'): 0.10102426872733582,\n",
              " (3, 'lot'): 0.14819285325117712,\n",
              " (3, 'nice'): 0.10885919132263866,\n",
              " (3, 'option'): 0.22965488023769112,\n",
              " (3, 'perfect'): 0.08799421303488031,\n",
              " (3, 'petite'): 0.10976011659777259,\n",
              " (3, 'style'): 0.12265157206287756,\n",
              " (3, 'tights'): 0.16846610865658532,\n",
              " (3, 'wear'): 0.0526069140358254,\n",
              " (4, 'adorable'): 0.08354093687234568,\n",
              " (4, 'already'): 0.10572035834636119,\n",
              " (4, 'baby'): 0.11777173345522621,\n",
              " (4, 'bad'): 0.11104444462272643,\n",
              " (4, 'construct'): 0.15903937223558773,\n",
              " (4, 'dress'): 0.008751233619539752,\n",
              " (4, 'easily'): 0.09230373927547535,\n",
              " (4, 'every'): 0.10131394150208788,\n",
              " (4, 'figure'): 0.1607426965156054,\n",
              " (4, 'first'): 0.07359823094904407,\n",
              " (4, 'flat'): 0.038397948621285,\n",
              " (4, 'get'): 0.0400759975508333,\n",
              " (4, 'good'): 0.04992109762486408,\n",
              " (4, 'hem'): 0.21144071669272238,\n",
              " (4, 'hide'): 0.09874769897498575,\n",
              " (4, 'hourglass'): 0.10737519222168353,\n",
              " (4, 'iron'): 0.11777173345522621,\n",
              " (4, 'like'): 0.032514399591211045,\n",
              " (4, 'notice'): 0.12047328513876021,\n",
              " (4, 'open'): 0.10416588086388849,\n",
              " (4, 'package'): 0.12047328513876021,\n",
              " (4, 'problem'): 0.1846074785509507,\n",
              " (4, 'properly'): 0.12349336297610339,\n",
              " (4, 'recent'): 0.1486428310020451,\n",
              " (4, 'return'): 0.07098841827443016,\n",
              " (4, 'roll'): 0.11777173345522621,\n",
              " (4, 'solve'): 0.15903937223558773,\n",
              " (4, 'take'): 0.0740602439106512,\n",
              " (4, 'think'): 0.051807317296069647,\n",
              " (4, 'time'): 0.07453073464573316,\n",
              " (4, 'try'): 0.04380248440787469,\n",
              " (4, 'wash'): 0.09755487806127056,\n",
              " (4, 'weight'): 0.09137123557878624,\n",
              " (4, 'well'): 0.05363235007729772,\n",
              " (4, 'would'): 0.0400759975508333,\n",
              " (5, 'although'): 0.09188938880421924,\n",
              " (5, 'buy'): 0.042629945691183745,\n",
              " (5, 'color'): 0.0308683300927156,\n",
              " (5, 'compliment'): 0.06593580667910345,\n",
              " (5, 'dress'): 0.01587433075172327,\n",
              " (5, 'every'): 0.09188938880421924,\n",
              " (5, 'fall'): 0.056775241895217675,\n",
              " (5, 'fit'): 0.020172190174817896,\n",
              " (5, 'flare'): 0.08371734492426834,\n",
              " (5, 'flat'): 0.03482604642395616,\n",
              " (5, 'fun'): 0.07236030380999084,\n",
              " (5, 'get'): 0.03634799777866276,\n",
              " (5, 'good'): 0.045277274589993005,\n",
              " (5, 'heavy'): 0.08645648528837029,\n",
              " (5, 'hip'): 0.06847532509689395,\n",
              " (5, 'hit'): 0.06717091889570691,\n",
              " (5, 'knee'): 0.057882870941479404,\n",
              " (5, 'like'): 0.029489804280400714,\n",
              " (5, 'look'): 0.026217713998932454,\n",
              " (5, 'love'): 0.02360813282202715,\n",
              " (5, 'make'): 0.03834089826947399,\n",
              " (5, 'material'): 0.05126360036090055,\n",
              " (5, 'mention'): 0.087446243763226,\n",
              " (5, 'navy'): 0.08645648528837029,\n",
              " (5, 'pattern'): 0.062236627734226994,\n",
              " (5, 'review'): 0.06328594018261001,\n",
              " (5, 'season'): 0.09188938880421924,\n",
              " (5, 'short'): 0.051477941177294144,\n",
              " (5, 'size'): 0.02508305901824799,\n",
              " (5, 'skirt'): 0.0698572651078428,\n",
              " (5, 'spring'): 0.07457681961939376,\n",
              " (5, 'sweater'): 0.08459502697038106,\n",
              " (5, 'time'): 0.06759764305078124,\n",
              " (5, 'wear'): 0.04893666421937247,\n",
              " (5, 'well'): 0.04864329425615375,\n",
              " (5, 'winter'): 0.07905058456468343,\n",
              " (5, 'x'): 0.06027017684985344,\n",
              " (5, 'young'): 0.10926646791654995,\n",
              " (5, 'youthful'): 0.13481559090883158,\n",
              " (6, 'choice'): 0.5351379062297813,\n",
              " (6, 'day'): 0.3383927884486454,\n",
              " (6, 'dress'): 0.01896100617566946,\n",
              " (6, 'easy'): 0.3457214515366229,\n",
              " (6, 'even'): 0.2637660134109808,\n",
              " (6, 'extremely'): 0.4450345488724114,\n",
              " (6, 'flat'): 0.16639111069223497,\n",
              " (6, 'good'): 0.21632475637441104,\n",
              " (6, 'wear'): 0.11690425341294533,\n",
              " (7, 'cheerful'): 0.1442450120276261,\n",
              " (7, 'color'): 0.0308683300927156,\n",
              " (7, 'combination'): 0.11200560828065191,\n",
              " (7, 'come'): 0.06717091889570691,\n",
              " (7, 'comfortable'): 0.0849664416524482,\n",
              " (7, 'conscious'): 0.13481559090883158,\n",
              " (7, 'deal'): 0.10926646791654995,\n",
              " (7, 'dress'): 0.011905748063792453,\n",
              " (7, 'everything'): 0.08956186651219639,\n",
              " (7, 'feel'): 0.0535014615724018,\n",
              " (7, 'grey'): 0.10459970755696504,\n",
              " (7, 'hop'): 0.08956186651219639,\n",
              " (7, 'knee'): 0.057882870941479404,\n",
              " (7, 'length'): 0.052133077850938236,\n",
              " (7, 'love'): 0.02360813282202715,\n",
              " (7, 'mean'): 0.09447603148120119,\n",
              " (7, 'mid'): 0.10926646791654995,\n",
              " (7, 'model'): 0.06593580667910345,\n",
              " (7, 'order'): 0.03896109006208239,\n",
              " (7, 'photo'): 0.07400257281496651,\n",
              " (7, 'place'): 0.08550713657859692,\n",
              " (7, 'proportion'): 0.128125310154139,\n",
              " (7, 'red'): 0.07638987872334055,\n",
              " (7, 'return'): 0.06438484448145991,\n",
              " (7, 'saw'): 0.06634026581193761,\n",
              " (7, 'self'): 0.1442450120276261,\n",
              " (7, 'short'): 0.10295588235458829,\n",
              " (7, 'size'): 0.02508305901824799,\n",
              " (7, 'stripe'): 0.08848000568347794,\n",
              " (7, 'tall'): 0.07516560585158653,\n",
              " (7, 'thigh'): 0.11869588903534448,\n",
              " (7, 'unfortunately'): 0.087446243763226,\n",
              " (7, 'want'): 0.054955423362665394,\n",
              " (7, 'wear'): 0.024468332109686235,\n",
              " (7, 'work'): 0.04560950615388781,\n",
              " (7, 'would'): 0.07269599555732552,\n",
              " (7, 'xl'): 0.10459970755696504,\n",
              " (7, 'yellow'): 0.12293592523985504,\n",
              " (8, 'adorable'): 0.09873019812186308,\n",
              " (8, 'ask'): 0.142377518800353,\n",
              " (8, 'butt'): 0.15466434025817616,\n",
              " (8, 'come'): 0.08752574280349688,\n",
              " (8, 'consider'): 0.12137305878338493,\n",
              " (8, 'couple'): 0.13365988024120812,\n",
              " (8, 'dress'): 0.015513550507365925,\n",
              " (8, 'haha'): 0.18795562173296734,\n",
              " (8, 'husband'): 0.12898864751917,\n",
              " (8, 'inch'): 0.22045976725614458,\n",
              " (8, 'look'): 0.03416247581679078,\n",
              " (8, 'love'): 0.03076211246506568,\n",
              " (8, 'low'): 0.09498432066831229,\n",
              " (8, 'pull'): 0.1069208141745877,\n",
              " (8, 'really'): 0.11671935746496165,\n",
              " (8, 'shirt'): 0.2462102638601001,\n",
              " (8, 'short'): 0.26830926916650283,\n",
              " (8, 'someone'): 0.23636063176932587,\n",
              " (8, 'tall'): 0.09794306217024913,\n",
              " (8, 'think'): 0.06122682953171867,\n",
              " (8, 'want'): 0.07160858195741249,\n",
              " (8, 'way'): 0.07033247634074197,\n",
              " (8, 'would'): 0.047362542560075716,\n",
              " (8, 'young'): 0.142377518800353,\n",
              " (9, 'aesthetic'): 0.480567707755797,\n",
              " (9, 'bill'): 0.480567707755797,\n",
              " (9, 'comfort'): 0.4175543277048929,\n",
              " (9, 'comfortable'): 0.1660707723206942,\n",
              " (9, 'cute'): 0.1886728301948028,\n",
              " (9, 'dress'): 0.015513550507365925,\n",
              " (9, 'fit'): 0.0788549252288336,\n",
              " (9, 'go'): 0.17444990502975394,\n",
              " (9, 'hand'): 1.0540128016508652,\n",
              " (9, 'must'): 0.36411917635015484,\n",
              " (10, 'become'): 0.3109555756066922,\n",
              " (10, 'bite'): 0.12651473937556573,\n",
              " (10, 'color'): 0.07807871729333946,\n",
              " (10, 'draw'): 0.2833083032981195,\n",
              " (10, 'either'): 0.21397565645449326,\n",
              " (10, 'feel'): 0.13532722633019278,\n",
              " (10, 'fine'): 0.20176157617342008,\n",
              " (10, 'fit'): 0.0510237751480688,\n",
              " (10, 'fun'): 0.18302900375468273,\n",
              " (10, 'great'): 0.08523207800479753,\n",
              " (10, 'like'): 0.07459185788571945,\n",
              " (10, 'material'): 0.12966675385404258,\n",
              " (10, 'sure'): 0.1817070710575028,\n",
              " (10, 'tent'): 0.20755216869184667,\n",
              " (10, 'top'): 0.13473603010351626,\n",
              " (10, 'waist'): 0.13357116967432922,\n",
              " (10, 'weird'): 0.25038972753721234,\n",
              " (11, 'comfortable'): 0.3653556991055273,\n",
              " (11, 'compliment'): 0.5670479374402897,\n",
              " (11, 'get'): 0.3125927808964997,\n",
              " (11, 'lot'): 0.5927714130047085,\n",
              " (11, 'versatile'): 0.7199691663487078,\n",
              " (12, 'adorable'): 0.08354093687234568,\n",
              " (12, 'also'): 0.05514745049704148,\n",
              " (12, 'comfortable'): 0.046840474244298366,\n",
              " (12, 'couple'): 0.1130968217425607,\n",
              " (12, 'cute'): 0.053215413644687966,\n",
              " (12, 'dramatically'): 0.15903937223558773,\n",
              " (12, 'dress'): 0.008751233619539752,\n",
              " (12, 'either'): 0.09327143999298425,\n",
              " (12, 'first'): 0.07359823094904407,\n",
              " (12, 'fit'): 0.022241132756850503,\n",
              " (12, 'flare'): 0.09230373927547535,\n",
              " (12, 'foot'): 0.1130968217425607,\n",
              " (12, 'good'): 0.04992109762486408,\n",
              " (12, 'high'): 0.07359823094904407,\n",
              " (12, 'hit'): 0.0740602439106512,\n",
              " (12, 'however'): 0.06787660142816689,\n",
              " (12, 'inch'): 0.1865428799859685,\n",
              " (12, 'knee'): 0.06381957565342601,\n",
              " (12, 'like'): 0.032514399591211045,\n",
              " (12, 'lot'): 0.07599633500060364,\n",
              " (12, 'model'): 0.07269845351798584,\n",
              " (12, 'person'): 0.07017434908687681,\n",
              " (12, 'petit'): 0.15903937223558773,\n",
              " (12, 'pic'): 0.13086982637230288,\n",
              " (12, 'probably'): 0.09047145814772804,\n",
              " (12, 'really'): 0.04938126661979146,\n",
              " (12, 'regular'): 0.07599633500060364,\n",
              " (12, 'short'): 0.22703092006396391,\n",
              " (12, 'thing'): 0.08222572419574183,\n",
              " (12, 'wa'): 0.1486428310020451,\n",
              " (12, 'wayyy'): 0.1486428310020451,\n",
              " (12, 'wear'): 0.026977904633756617,\n",
              " (12, 'would'): 0.0400759975508333,\n",
              " (12, 'x'): 0.06645173344983842,\n",
              " (13, 'along'): 0.13424166058318995,\n",
              " (13, 'appear'): 0.10621796763999777,\n",
              " (13, 'back'): 0.05884002259418256,\n",
              " (13, 'color'): 0.03792394839962202,\n",
              " (13, 'comfortable'): 0.052193671300789606,\n",
              " (13, 'dress'): 0.014627061906945014,\n",
              " (13, 'fabric'): 0.04091002550635022,\n",
              " (13, 'flare'): 0.10285273804981539,\n",
              " (13, 'horizontal'): 0.15103556529467904,\n",
              " (13, 'issue'): 0.09890558552179204,\n",
              " (13, 'knit'): 0.12373523829389517,\n",
              " (13, 'length'): 0.06404920993115269,\n",
              " (13, 'like'): 0.03623033097306373,\n",
              " (13, 'long'): 0.14084947993740307,\n",
              " (13, 'oddly'): 0.1574110953322279,\n",
              " (13, 'opinion'): 0.1285082121414142,\n",
              " (13, 'proportional'): 0.17721530049108347,\n",
              " (13, 'quite'): 0.09308847251489948,\n",
              " (13, 'regrettably'): 0.17721530049108347,\n",
              " (13, 'send'): 0.11780268501451675,\n",
              " (13, 'short'): 0.06324432773210424,\n",
              " (13, 'skirt'): 0.25747391996890634,\n",
              " (13, 'sleeve'): 0.07404621727267709,\n",
              " (13, 'stripe'): 0.21740801396511725,\n",
              " (13, 'sturdy'): 0.1574110953322279,\n",
              " (13, 'use'): 0.1160705529626186,\n",
              " (13, 'various'): 0.1574110953322279,\n",
              " (13, 'work'): 0.05603453613191931,\n",
              " (13, 'would'): 0.044656111556642814,\n",
              " (14, 'amaze'): 0.13588000872819828,\n",
              " (14, 'anything'): 0.14955830345163063,\n",
              " (14, 'compliment'): 0.10125856025719457,\n",
              " (14, 'dress'): 0.018283827383681266,\n",
              " (14, 'else'): 0.1575277159985667,\n",
              " (14, 'ever'): 0.1575277159985667,\n",
              " (14, 'felt'): 0.11543289470065074,\n",
              " (14, 'fit'): 0.12391488250245279,\n",
              " (14, 'flare'): 0.12856592256226923,\n",
              " (14, 'flat'): 0.053482857008218386,\n",
              " (14, 'great'): 0.051748047360055636,\n",
              " (14, 'hubby'): 0.22151912561385434,\n",
              " (14, 'love'): 0.07251069366765482,\n",
              " (14, 'normal'): 0.13588000872819828,\n",
              " (14, 'normally'): 0.12480304700306115,\n",
              " (14, 'own'): 0.18879445661834882,\n",
              " (14, 'pick'): 0.16403920016977935,\n",
              " (14, 'preppy'): 0.22151912561385434,\n",
              " (14, 'style'): 0.1752165315183965,\n",
              " (14, 'super'): 0.09067763825208128,\n",
              " (14, 'tt'): 0.12363198190224005,\n",
              " (15, 'beautiful'): 0.09218855669510387,\n",
              " (15, 'color'): 0.060333554272125944,\n",
              " (15, 'especially'): 0.16712758513089396,\n",
              " (15, 'exchange'): 0.1968515154675605,\n",
              " (15, 'fabric'): 0.06508413148737535,\n",
              " (15, 'get'): 0.07104381384011357,\n",
              " (15, 'good'): 0.08849649124407724,\n",
              " (15, 'hem'): 0.18741336252309485,\n",
              " (15, 'lb'): 0.10233144539120431,\n",
              " (15, 'mind'): 0.2189200525485469,\n",
              " (15, 'petite'): 0.09978192417979326,\n",
              " (15, 'pink'): 0.16038122126188153,\n",
              " (15, 'pretty'): 0.10019703706903291,\n",
              " (15, 'really'): 0.08753951809872124,\n",
              " (15, 'regular'): 0.1347207756828883,\n",
              " (15, 'short'): 0.20123195187487714,\n",
              " (15, 'small'): 0.08026290831021793,\n",
              " (15, 'think'): 0.091840244297578,\n",
              " (15, 'waist'): 0.10321408565743621,\n",
              " (15, 'wise'): 0.2635032004127163,\n",
              " (15, 'x'): 0.11780080020653173,\n",
              " (16, 'dress'): 0.010665565973814073,\n",
              " (16, 'fabric'): 0.08949068079514111,\n",
              " (16, 'fit'): 0.0542127610948231,\n",
              " (16, 'get'): 0.09768524403015616,\n",
              " (16, 'give'): 0.18166866569897458,\n",
              " (16, 'horizontal'): 0.33039029908211043,\n",
              " (16, 'line'): 0.1483683825436767,\n",
              " (16, 'nice'): 0.13607398915329832,\n",
              " (16, 'perfectly'): 0.16113716151322233,\n",
              " (16, 'petite'): 0.13720014574721573,\n",
              " (16, 'short'): 0.13834696691397802,\n",
              " (16, 'skirt'): 0.18774139997732756,\n",
              " (16, 'stretchy'): 0.28111171405934354,\n",
              " (16, 'thick'): 0.23501178011366988,\n",
              " (16, 'top'): 0.14315703198498603,\n",
              " (16, 'wearer'): 0.3623169005674849,\n",
              " (17, 'accommodate'): 0.16204083343023462,\n",
              " (17, 'appropriate'): 0.11621305054651256,\n",
              " (17, 'bonus'): 0.15011538907411215,\n",
              " (17, 'boot'): 0.07702989937446507,\n",
              " (17, 'casually'): 0.170502070855287,\n",
              " (17, 'color'): 0.03903935864666973,\n",
              " (17, 'curve'): 0.1093420255117624,\n",
              " (17, 'dress'): 0.010038179740060304,\n",
              " (17, 'easy'): 0.09151450187734136,\n",
              " (17, 'figure'): 0.0921906641780678,\n",
              " (17, 'generous'): 0.170502070855287,\n",
              " (17, 'glass'): 0.16204083343023462,\n",
              " (17, 'highlight'): 0.15011538907411215,\n",
              " (17, 'hour'): 0.15011538907411215,\n",
              " (17, 'huge'): 0.10480818198743128,\n",
              " (17, 'indeed'): 0.18242751521140946,\n",
              " (17, 'indicate'): 0.18242751521140946,\n",
              " (17, 'legging'): 0.12316566166604875,\n",
              " (17, 'like'): 0.03729592894285973,\n",
              " (17, 'love'): 0.02985734445138728,\n",
              " (17, 'nod'): 0.18242751521140946,\n",
              " (17, 'pair'): 0.10277897988487389,\n",
              " (17, 'photo'): 0.09359148914833999,\n",
              " (17, 'price'): 0.087754696832933,\n",
              " (17, 'sale'): 0.09151450187734136,\n",
              " (17, 'short'): 0.0651044550183426,\n",
              " (17, 'skater'): 0.18242751521140946,\n",
              " (17, 'skirt'): 0.08834889410697767,\n",
              " (17, 'though'): 0.08190614216395754,\n",
              " (17, 'vibrant'): 0.11190118365851623,\n",
              " (17, 'wear'): 0.03094524355048553,\n",
              " (17, 'well'): 0.06151946038278268,\n",
              " (17, 'work'): 0.05768261072403459,\n",
              " (18, 'also'): 0.05974307137179493,\n",
              " (18, 'appeal'): 0.1468401329253824,\n",
              " (18, 'bouncy'): 0.16102973358554884,\n",
              " (18, 'bright'): 0.11125863721810285,\n",
              " (18, 'buy'): 0.0509191017978028,\n",
              " (18, 'color'): 0.07374101077704281,\n",
              " (18, 'colorful'): 0.14177564523666145,\n",
              " (18, 'dress'): 0.014220754631752097,\n",
              " (18, 'flat'): 0.04159777767305874,\n",
              " (18, 'fun'): 0.08643036288415573,\n",
              " (18, 'grey'): 0.12493853958193046,\n",
              " (18, 'hearted'): 0.17229265325522006,\n",
              " (18, 'light'): 0.08519559170163257,\n",
              " (18, 'line'): 0.1318830067054904,\n",
              " (18, 'look'): 0.03131560283205821,\n",
              " (18, 'love'): 0.028198603092976872,\n",
              " (18, 'mood'): 0.17229265325522006,\n",
              " (18, 'navy'): 0.20653493707777343,\n",
              " (18, 'originally'): 0.1374936819081265,\n",
              " (18, 'picture'): 0.07353298488051413,\n",
              " (18, 'playful'): 0.1468401329253824,\n",
              " (18, 'put'): 0.10326746853888671,\n",
              " (18, 'quite'): 0.18100536322341565,\n",
              " (18, 'store'): 0.06253588329462485,\n",
              " (18, 'stripe'): 0.1056844512330431,\n",
              " (18, 'try'): 0.047452691441864245,\n",
              " (18, 'vary'): 0.16102973358554884,\n",
              " (18, 'vibrant'): 0.1056844512330431,\n",
              " (18, 'want'): 0.06564120012762811,\n",
              " (18, 'wear'): 0.029226063353236333,\n",
              " (19, 'comfortable'): 0.18267784955276364,\n",
              " (19, 'dress'): 0.017064905558102517,\n",
              " (19, 'flat'): 0.1497519996230115,\n",
              " (19, 'good'): 0.19469228073696995,\n",
              " (19, 'happen'): 0.5286244785313767,\n",
              " (19, 'look'): 0.11273617019540956,\n",
              " (19, 'navy'): 0.37176288673999225,\n",
              " (19, 'often'): 0.4410776047959868,\n",
              " (19, 'tights'): 0.33693221731317063,\n",
              " (19, 'well'): 0.20916616530146112,\n",
              " (20, 'appropriate'): 0.08780541596847616,\n",
              " (20, 'arm'): 0.06262545008538108,\n",
              " (20, 'bagginess'): 0.2756682452083521,\n",
              " (20, 'base'): 0.09027709674870336,\n",
              " (20, 'c'): 0.0742296585835212,\n",
              " (20, 'colorful'): 0.11342051618932918,\n",
              " (20, 'cute'): 0.04612002515872957,\n",
              " (20, 'decide'): 0.07299477300230318,\n",
              " (20, 'dress'): 0.0037922012351338926,\n",
              " (20, 'enough'): 0.05914613762556907,\n",
              " (20, 'even'): 0.05275320268219617,\n",
              " (20, 'find'): 0.05670838390875965,\n",
              " (20, 'fit'): 0.03855129677854087,\n",
              " (20, 'flat'): 0.033278222138447,\n",
              " (20, 'get'): 0.034732531210722194,\n",
              " (20, 'grey'): 0.09995083166554437,\n",
              " (20, 'hide'): 0.08558133911165433,\n",
              " (20, 'lb'): 0.05002870663569989,\n",
              " (20, 'length'): 0.04981605216867432,\n",
              " (20, 'like'): 0.028179146312382906,\n",
              " (20, 'little'): 0.0435824169914928,\n",
              " (20, 'long'): 0.05477479775343454,\n",
              " (20, 'loose'): 0.06152329583783947,\n",
              " (20, 'material'): 0.04898521812263831,\n",
              " (20, 'one'): 0.041889942303369156,\n",
              " (20, 'option'): 0.10206883566119605,\n",
              " (20, 'perfect'): 0.03910853912661347,\n",
              " (20, 'petite'): 0.048782274043454484,\n",
              " (20, 'problem'): 0.07999657403874531,\n",
              " (20, 'push'): 0.12243085192506617,\n",
              " (20, 'regular'): 0.0658634903338565,\n",
              " (20, 'review'): 0.06047323173004957,\n",
              " (20, 'sleeve'): 0.11518300464638659,\n",
              " (20, 'tho'): 0.13783412260417605,\n",
              " (20, 'tight'): 0.05729321298247905,\n",
              " (20, 'unflattering'): 0.08780541596847616,\n",
              " (20, 'wear'): 0.02338085068258907,\n",
              " (20, 'weight'): 0.07918840416828142,\n",
              " (20, 'work'): 0.0435824169914928,\n",
              " (20, 'would'): 0.034732531210722194,\n",
              " (20, 'x'): 0.11518300464638659,\n",
              " (21, 'adorable'): 0.12531140530851853,\n",
              " (21, 'anyway'): 0.1729918240365191,\n",
              " (21, 'arrive'): 0.14141564895691028,\n",
              " (21, 'blue'): 0.19629825199186032,\n",
              " (21, 'choose'): 0.16964523261384107,\n",
              " (21, 'directly'): 0.23855905835338162,\n",
              " (21, 'dress'): 0.006563425214654814,\n",
              " (21, 'expect'): 0.12958931435121948,\n",
              " (21, 'go'): 0.07380572905104975,\n",
              " (21, 'gray'): 0.18070992770814032,\n",
              " (21, 'like'): 0.04877159938681657,\n",
              " (21, 'local'): 0.1585805375195418,\n",
              " (21, 'love'): 0.03904421966719875,\n",
              " (21, 'one'): 0.1450036464347394,\n",
              " (21, 'online'): 0.09716287866464794,\n",
              " (21, 'order'): 0.06443564894882858,\n",
              " (21, 'quickly'): 0.19630473955845434,\n",
              " (21, 'see'): 0.09967760017475762,\n",
              " (21, 'ship'): 0.17665760018283932,\n",
              " (21, 'stock'): 0.17665760018283932,\n",
              " (21, 'store'): 0.17317629220049963,\n",
              " (21, 'struggle'): 0.20331710712745257,\n",
              " (21, 'try'): 0.06570372661181204,\n",
              " (22, 'almost'): 0.13472541332319946,\n",
              " (22, 'ankle'): 0.17401696742265363,\n",
              " (22, 'belong'): 0.22972353767362672,\n",
              " (22, 'cheerlead'): 0.22972353767362672,\n",
              " (22, 'fit'): 0.032126080648784056,\n",
              " (22, 'inch'): 0.13472541332319946,\n",
              " (22, 'knee'): 0.09218383149939312,\n",
              " (22, 'least'): 0.15270718427807728,\n",
              " (22, 'like'): 0.093930487707943,\n",
              " (22, 'look'): 0.08350827421882188,\n",
              " (22, 'model'): 0.10500887730375734,\n",
              " (22, 'old'): 0.18332490921083533,\n",
              " (22, 'ready'): 0.20405141987511027,\n",
              " (22, 'reference'): 0.1282109441949156,\n",
              " (22, 'regular'): 0.10977248388976081,\n",
              " (22, 'see'): 0.09598583720532214,\n",
              " (22, 'short'): 0.08198338780087586,\n",
              " (22, 'size'): 0.03994709399202458,\n",
              " (22, 'small'): 0.06539940677128868,\n",
              " (22, 'sock'): 0.21470631144739843,\n",
              " (22, 'style'): 0.09085301634287225,\n",
              " (22, 'think'): 0.07483279164987837,\n",
              " (22, 'true'): 0.09911759231747262,\n",
              " (22, 'try'): 0.06327025525581899,\n",
              " (22, 'year'): 0.14091260164405747,\n",
              " (23, 'also'): 0.05245733096060043,\n",
              " (23, 'arrive'): 0.08967821641169921,\n",
              " (23, 'big'): 0.06130868446521918,\n",
              " (23, 'cage'): 0.1413919611970673,\n",
              " (23, 'disappoint'): 0.08147157649410863,\n",
              " (23, 'dress'): 0.01248651626202623,\n",
              " (23, 'easy'): 0.07589007472755138,\n",
              " (23, 'fit'): 0.021156199451638283,\n",
              " (23, 'high'): 0.07000807334177363,\n",
              " (23, 'hit'): 0.0704475490857414,\n",
              " (23, 'however'): 0.06456554769996363,\n",
              " (23, 'lb'): 0.05490955606357305,\n",
              " (23, 'look'): 0.02749662687692916,\n",
              " (23, 'love'): 0.02475974905724799,\n",
              " (23, 'material'): 0.05376426379313961,\n",
              " (23, 'neither'): 0.12448593240292227,\n",
              " (23, 'perfect'): 0.04292400635847819,\n",
              " (23, 'petite'): 0.05354152029159638,\n",
              " (23, 'pretty'): 0.05376426379313961,\n",
              " (23, 'return'): 0.06752556860250673,\n",
              " (23, 'rib'): 0.1413919611970673,\n",
              " (23, 'right'): 0.05816641929831751,\n",
              " (23, 'saw'): 0.06957637633934921,\n",
              " (23, 'school'): 0.1413919611970673,\n",
              " (23, 'short'): 0.053989060259113375,\n",
              " (23, 'size'): 0.05261324574559335,\n",
              " (23, 'small'): 0.043067902020116934,\n",
              " (23, 'sure'): 0.07534195629213532,\n",
              " (23, 'throw'): 0.10562764244600807,\n",
              " (23, 'unfortunately'): 0.1834238283814009,\n",
              " (23, 'waist'): 0.11076633582749253,\n",
              " (23, 'way'): 0.16982719896910864,\n",
              " (23, 'would'): 0.03812107084103655,\n",
              " (23, 'x'): 0.06321018547667556,\n",
              " (24, 'absolutely'): 0.06876853301315364,\n",
              " (24, 'already'): 0.08772540373421461,\n",
              " (24, 'ankle'): 0.09996719405131166,\n",
              " (24, 'bite'): 0.04576065041243867,\n",
              " (24, 'booty'): 0.07047156934663314,\n",
              " (24, 'broad'): 0.08000401025146209,\n",
              " (24, 'busty'): 0.08297766859986971,\n",
              " (24, 'comfortable'): 0.03886762756441779,\n",
              " (24, 'complement'): 0.10531430954665008,\n",
              " (24, 'dress'): 0.007261661939618092,\n",
              " (24, 'enough'): 0.05662928070533209,\n",
              " (24, 'fine'): 0.07297759138187535,\n",
              " (24, 'first'): 0.06107087248963231,\n",
              " (24, 'fit'): 0.018455408032280202,\n",
              " (24, 'flat'): 0.031862127579364144,\n",
              " (24, 'frame'): 0.07739545020694437,\n",
              " (24, 'get'): 0.033254551159202096,\n",
              " (24, 'hem'): 0.08772540373421461,\n",
              " (24, 'hold'): 0.0852193816989724,\n",
              " (24, 'intarsia'): 0.1319688407912324,\n",
              " (24, 'large'): 0.042989050522270554,\n",
              " (24, 'lucky'): 0.12334192359744166,\n",
              " (24, 'maxi'): 0.09214326255928364,\n",
              " (24, 'own'): 0.11247329330454822,\n",
              " (24, 'perfectly'): 0.054855203919394836,\n",
              " (24, 'purchase'): 0.050976021859949,\n",
              " (24, 'regular'): 0.06306078861752216,\n",
              " (24, 'round'): 0.1085941112451024,\n",
              " (24, 'run'): 0.04364884279338886,\n",
              " (24, 'sale'): 0.06620198008148098,\n",
              " (24, 'shoulder'): 0.058564850454390104,\n",
              " (24, 'size'): 0.022948330591163055,\n",
              " (24, 'small'): 0.037569871974995624,\n",
              " (24, 'stay'): 0.0956976047861595,\n",
              " (24, 'stun'): 0.0852193816989724,\n",
              " (24, 'sweater'): 0.15479090041388874,\n",
              " (24, 'taupe'): 0.23444205687778627,\n",
              " (24, 'think'): 0.042989050522270554,\n",
              " (24, 'time'): 0.061844652152842405,\n",
              " (24, 'tt'): 0.0736530956013345,\n",
              " (24, 'unique'): 0.07107094970762667,\n",
              " (24, 'usual'): 0.07232287524002952,\n",
              " (24, 'wish'): 0.07232287524002952,\n",
              " (24, 'would'): 0.033254551159202096,\n",
              " (25, 'addition'): 0.268627538343148,\n",
              " (25, 'beautiful'): 0.10674464459433079,\n",
              " (25, 'black'): 0.16376279283313716,\n",
              " (25, 'comfortable'): 0.0961462366067177,\n",
              " (25, 'dress'): 0.017963058482213176,\n",
              " (25, 'embroidery'): 0.193516151204193,\n",
              " (25, 'fabric'): 0.07536057330117145,\n",
              " (25, 'fall'): 0.1284913369207558,\n",
              " (25, 'happy'): 0.19790465693782724,\n",
              " (25, 'lovely'): 0.3402232685913917,\n",
              " (25, 'nice'): 0.1145886224448828,\n",
              " (25, 'perfectly'): 0.13569445180060827,\n",
              " (25, 'size'): 0.05676692304129808,\n",
              " (25, 'slimming'): 0.2472872694953499,\n",
              " (25, 'soft'): 0.12270181612000164,\n",
              " (25, 'wardrobe'): 0.28996780719094617,\n",
              " (25, 'winter'): 0.17890395454112565,\n",
              " (26, 'add'): 0.06917631806616434,\n",
              " (26, 'arm'): 0.06126402725743801,\n",
              " (26, 'become'): 0.11491836489812536,\n",
              " (26, 'black'): 0.06764115356151318,\n",
              " (26, 'comfortable'): 0.03971257598973122,\n",
              " (26, 'decide'): 0.07140793011094877,\n",
              " (26, 'dress'): 0.0037097620778483733,\n",
              " (26, 'eh'): 0.13483772863452004,\n",
              " (26, 'embroidery'): 0.07993058419303624,\n",
              " (26, 'fabric'): 0.031127193320049082,\n",
              " (26, 'fine'): 0.0745640607597422,\n",
              " (26, 'flat'): 0.03255478252674163,\n",
              " (26, 'keep'): 0.0631891011126868,\n",
              " (26, 'lace'): 0.07670406234263899,\n",
              " (26, 'li'): 0.12602326976260345,\n",
              " (26, 'like'): 0.027566556175157186,\n",
              " (26, 'likely'): 0.10760375105853377,\n",
              " (26, 'little'): 0.0852699462877033,\n",
              " (26, 'loose'): 0.06018583288484296,\n",
              " (26, 'many'): 0.0631891011126868,\n",
              " (26, 'neck'): 0.09253533408983933,\n",
              " (26, 'nly'): 0.13483772863452004,\n",
              " (26, 'order'): 0.03642014940585963,\n",
              " (26, 'otherwise'): 0.08270957053020764,\n",
              " (26, 'p'): 0.15050849970707483,\n",
              " (26, 'pick'): 0.09984994792943092,\n",
              " (26, 'plain'): 0.11976931166582559,\n",
              " (26, 'problem'): 0.07825751808138127,\n",
              " (26, 'retailer'): 0.05332677046212068,\n",
              " (26, 'sleeve'): 0.056339513142254306,\n",
              " (26, 'snug'): 0.15986116838607248,\n",
              " (26, 'soft'): 0.050681184919131116,\n",
              " (26, 'theo'): 0.13483772863452004,\n",
              " (26, 'thing'): 0.06971311399204198,\n",
              " (26, 'trend'): 0.11976931166582559,\n",
              " (26, 'tunic'): 0.0883145511672098,\n",
              " (26, 'way'): 0.050455906940097495,\n",
              " (26, 'wear'): 0.02287257131992409,\n",
              " (26, 'wish'): 0.07389511165829103,\n",
              " (26, 'workout'): 0.13483772863452004,\n",
              " (26, 'would'): 0.03397747618440214,\n",
              " (26, 'x'): 0.056339513142254306,\n",
              " (26, 'xx'): 0.08963247772843666,\n",
              " (27, 'back'): 0.07627410336282925,\n",
              " (27, 'black'): 0.11524048384554098,\n",
              " (27, 'collar'): 0.17837930207659378,\n",
              " (27, 'come'): 0.10697590787094062,\n",
              " (27, 'comfortable'): 0.06765846279731985,\n",
              " (27, 'design'): 0.09911759231747262,\n",
              " (27, 'ever'): 0.16336207585036544,\n",
              " (27, 'fit'): 0.032126080648784056,\n",
              " (27, 'go'): 0.07107218353064049,\n",
              " (27, 'keeper'): 0.18332490921083533,\n",
              " (27, 'knee'): 0.09218383149939312,\n",
              " (27, 'lace'): 0.13068099510227382,\n",
              " (27, 'lb'): 0.08338117772616647,\n",
              " (27, 'length'): 0.08302675361445719,\n",
              " (27, 'likely'): 0.18332490921083533,\n",
              " (27, 'love'): 0.075196274914605,\n",
              " (27, 'one'): 0.06981657050561525,\n",
              " (27, 'perfect'): 0.06518089854435577,\n",
              " (27, 'pocket'): 0.12478971011598912,\n",
              " (27, 'pop'): 0.18332490921083533,\n",
              " (27, 'shirtdress'): 0.19578684390050988,\n",
              " (27, 'skinny'): 0.17837930207659378,\n",
              " (27, 'super'): 0.09403606929845466,\n",
              " (27, 'tights'): 0.12478971011598912,\n",
              " (27, 'underneath'): 0.1294253820772486,\n",
              " (27, 'wear'): 0.038968084470981774,\n",
              " (28, 'also'): 0.05245733096060043,\n",
              " (28, 'appear'): 0.09067387481463225,\n",
              " (28, 'aspect'): 0.1512813540777542,\n",
              " (28, 'awesome'): 0.10970213231584139,\n",
              " (28, 'certainly'): 0.12448593240292227,\n",
              " (28, 'character'): 0.1413919611970673,\n",
              " (28, 'color'): 0.03237410229236026,\n",
              " (28, 'come'): 0.0704475490857414,\n",
              " (28, 'dress'): 0.004162172087342078,\n",
              " (28, 'embroidery'): 0.08967821641169921,\n",
              " (28, 'fan'): 0.12072615972420864,\n",
              " (28, 'fit'): 0.021156199451638283,\n",
              " (28, 'flat'): 0.03652487795683207,\n",
              " (28, 'give'): 0.07089508905325838,\n",
              " (28, 'iron'): 0.11202677084765421,\n",
              " (28, 'issue'): 0.08443159739665175,\n",
              " (28, 'lace'): 0.08605821628686326,\n",
              " (28, 'may'): 0.08217858958857821,\n",
              " (28, 'neckline'): 0.08443159739665175,\n",
              " (28, 'negative'): 0.12893279964179918,\n",
              " (28, 'one'): 0.09195353188544449,\n",
              " (28, 'order'): 0.08172326208144112,\n",
              " (28, 'perfectly'): 0.06288279473686725,\n",
              " (28, 'petite'): 0.05354152029159638,\n",
              " (28, 'potential'): 0.1343753252836092,\n",
              " (28, 'potentially'): 0.1512813540777542,\n",
              " (28, 'pound'): 0.09393073804937671,\n",
              " (28, 'really'): 0.046972424345655295,\n",
              " (28, 'roll'): 0.11202677084765421,\n",
              " (28, 'say'): 0.06957637633934921,\n",
              " (28, 'sleeve'): 0.06321018547667556,\n",
              " (28, 'something'): 0.08443159739665175,\n",
              " (28, 'sure'): 0.07534195629213532,\n",
              " (28, 'thing'): 0.07821471325936419,\n",
              " (28, 'wash'): 0.09279610352169639,\n",
              " (28, 'wear'): 0.02566190928576849,\n",
              " (28, 'wish'): 0.08290671064100946,\n",
              " (28, 'would'): 0.03812107084103655,\n",
              " (28, 'yet'): 0.09279610352169639,\n",
              " (29, 'absolutely'): 0.07883222077117613,\n",
              " (29, 'adorable'): 0.07946576922003615,\n",
              " (29, 'also'): 0.05245733096060043,\n",
              " (29, 'baggy'): 0.09171191419070045,\n",
              " (29, 'beautiful'): 0.04946703042176306,\n",
              " (29, 'boot'): 0.06387845313980031,\n",
              " (29, 'booty'): 0.0807844819339453,\n",
              " (29, 'comfortable'): 0.044555573061649666,\n",
              " (29, 'cowboy'): 0.1413919611970673,\n",
              " (29, 'criss'): 0.1413919611970673,\n",
              " (29, 'cross'): 0.11459653952223532,\n",
              " (29, 'dress'): 0.008324344174684155,\n",
              " (29, 'embroidery'): 0.08967821641169921,\n",
              " (29, 'event'): 0.11459653952223532,\n",
              " (29, 'fabric'): 0.03492319250542092,\n",
              " (29, 'fall'): 0.05954476589010634,\n",
              " (29, 'favorite'): 0.09393073804937671,\n",
              " (29, 'feature'): 0.11459653952223532,\n",
              " (29, 'feel'): 0.0561112889661775,\n",
              " (29, 'flat'): 0.03652487795683207,\n",
              " (29, 'frumpy'): 0.12072615972420864,\n",
              " (29, 'great'): 0.035340129904428245,\n",
              " (29, 'heel'): 0.09279610352169639,\n",
              " (29, 'lay'): 0.10970213231584139,\n",
              " (29, 'look'): 0.02749662687692916,\n",
              " (29, 'love'): 0.04951949811449598,\n",
              " (29, 'neckline'): 0.08443159739665175,\n",
              " (29, 'nicely'): 0.08147157649410863,\n",
              " (29, 'october'): 0.1512813540777542,\n",
              " (29, 'online'): 0.061615484031240154,\n",
              " (29, 'order'): 0.04086163104072056,\n",
              " (29, 'pair'): 0.08523134917282225,\n",
              " (29, 'soft'): 0.056861817226342225,\n",
              " (29, 'sure'): 0.07534195629213532,\n",
              " (29, 'totally'): 0.11202677084765421,\n",
              " (29, 'unbelievably'): 0.1413919611970673,\n",
              " (29, 'wear'): 0.02566190928576849,\n",
              " (29, 'without'): 0.07228919670789127,\n",
              " (29, 'would'): 0.03812107084103655,\n",
              " (30, 'amazingly'): 0.13117591277685658,\n",
              " (30, 'basic'): 0.1178517273498227,\n",
              " (30, 'chesty'): 0.1476794170759029,\n",
              " (30, 'cling'): 0.10311269857824597,\n",
              " (30, 'come'): 0.06877022648846183,\n",
              " (30, 'curve'): 0.08851497303333147,\n",
              " (30, 'dress'): 0.00812614550385834,\n",
              " (30, 'embroidery'): 0.08754302078284922,\n",
              " (30, 'extremely'): 0.0953645461869453,\n",
              " (30, 'feel'): 0.054775305895554224,\n",
              " (30, 'find'): 0.060758982759385335,\n",
              " (30, 'fit'): 0.020652480417075465,\n",
              " (30, 'flat'): 0.03565523800547892,\n",
              " (30, 'follow'): 0.12152198163142411,\n",
              " (30, 'ha'): 0.1476794170759029,\n",
              " (30, 'high'): 0.06834121445268378,\n",
              " (30, 'home'): 0.10134822305077641,\n",
              " (30, 'lb'): 0.053602185681107015,\n",
              " (30, 'look'): 0.026841945284621322,\n",
              " (30, 'material'): 0.10496832454851066,\n",
              " (30, 'perfectly'): 0.06138558533837041,\n",
              " (30, 'person'): 0.06516189558067133,\n",
              " (30, 'pick'): 0.1093594667798529,\n",
              " (30, 'purchase'): 0.0570445958908953,\n",
              " (30, 'quality'): 0.05926103453532415,\n",
              " (30, 'sell'): 0.08851497303333147,\n",
              " (30, 'shirtdress'): 0.1258629710788992,\n",
              " (30, 'shop'): 0.1258629710788992,\n",
              " (30, 'size'): 0.025680274709158655,\n",
              " (30, 'slightly'): 0.08400921113717603,\n",
              " (30, 'small'): 0.04204247578154272,\n",
              " (30, 'soft'): 0.05550796443523884,\n",
              " (30, 'somehow'): 0.12152198163142411,\n",
              " (30, 'sometimes'): 0.10501847733237779,\n",
              " (30, 'stun'): 0.0953645461869453,\n",
              " (30, 'top'): 0.05453601218475658,\n",
              " (30, 'try'): 0.04067373552159792,\n",
              " (30, 'usually'): 0.0570445958908953,\n",
              " (30, 'wear'): 0.02505091144563114,\n",
              " (30, 'without'): 0.07056802535770337,\n",
              " (31, 'beautiful'): 0.3380247078820475,\n",
              " (31, 'dress'): 0.028441509263504194,\n",
              " (31, 'embroidery'): 0.6128011454799445,\n",
              " (31, 'flat'): 0.24958666603835247,\n",
              " (31, 'love'): 0.16919161855786125,\n",
              " (31, 'super'): 0.423162311843046,\n",
              " (32, 'alteration'): 0.2936802658507648,\n",
              " (32, 'belt'): 0.1795622806454567,\n",
              " (32, 'bite'): 0.11948614274358986,\n",
              " (32, 'consider'): 0.2225172744362057,\n",
              " (32, 'could'): 0.141054103947682,\n",
              " (32, 'cute'): 0.11530006289682393,\n",
              " (32, 'great'): 0.08049696256008655,\n",
              " (32, 'half'): 0.2450431137755482,\n",
              " (32, 'loose'): 0.15380823959459866,\n",
              " (32, 'low'): 0.1741379212252392,\n",
              " (32, 'material'): 0.12246304530659577,\n",
              " (32, 'middle'): 0.274987363816253,\n",
              " (32, 'model'): 0.157513315955636,\n",
              " (32, 'short'): 0.24595016340262757,\n",
              " (32, 'well'): 0.11620342516747839,\n",
              " (32, 'would'): 0.08683132802680547,\n",
              " (32, 'yeah'): 0.3445853065104401,\n",
              " (33, 'another'): 0.10684399223521798,\n",
              " (33, 'booty'): 0.10684399223521798,\n",
              " (33, 'buy'): 0.05913186015228712,\n",
              " (33, 'clingy'): 0.13970107549310745,\n",
              " (33, 'color'): 0.04281736109634744,\n",
              " (33, 'come'): 0.09317256491985151,\n",
              " (33, 'cute'): 0.06694842361751066,\n",
              " (33, 'dress'): 0.0055048082445491985,\n",
              " (33, 'great'): 0.04674017180908251,\n",
              " (33, 'jacket'): 0.11495090927653753,\n",
              " (33, 'jean'): 0.1330030314680028,\n",
              " (33, 'lightweight'): 0.1373104957462132,\n",
              " (33, 'like'): 0.04090521238894292,\n",
              " (33, 'long'): 0.07951180319046948,\n",
              " (33, 'maybe'): 0.11612405908850125,\n",
              " (33, 'need'): 0.08983254301853408,\n",
              " (33, 'one'): 0.12161596152591045,\n",
              " (33, 'perfect'): 0.05677046002250342,\n",
              " (33, 'previous'): 0.14508991693385473,\n",
              " (33, 'reviewer'): 0.09090791141426285,\n",
              " (33, 'sandal'): 0.12745947479294925,\n",
              " (33, 'scarf'): 0.1515631651745693,\n",
              " (33, 'size'): 0.06958526050223636,\n",
              " (33, 'small'): 0.05696077363950949,\n",
              " (33, 'think'): 0.0651769475660231,\n",
              " (33, 'unlike'): 0.15536261793767844,\n",
              " (33, 'versital'): 0.20008179087702974,\n",
              " (33, 'wish'): 0.10965081084778669,\n",
              " (33, 'would'): 0.050418190467177375,\n",
              " (34, 'beautifully'): 0.10282811471323114,\n",
              " (34, 'color'): 0.0717480104857714,\n",
              " (34, 'drape'): 0.09937315872647749,\n",
              " (34, 'dress'): 0.00922427327465001,\n",
              " (34, 'early'): 0.13377763645115012,\n",
              " (34, 'fabric'): 0.03869867277627724,\n",
              " (34, 'fit'): 0.023443356149112693,\n",
              " (34, 'good'): 0.0526195353343162,\n",
              " (34, 'gray'): 0.12698535460572022,\n",
              " (34, 'hip'): 0.07957943186936325,\n",
              " (34, 'hug'): 0.12698535460572022,\n",
              " (34, 'length'): 0.06058709047541471,\n",
              " (34, 'like'): 0.03427193470424948,\n",
              " (34, 'look'): 0.03046923518794853,\n",
              " (34, 'make'): 0.044558341232091396,\n",
              " (34, 'medium'): 0.07526510361012315,\n",
              " (34, 'model'): 0.0766280996540932,\n",
              " (34, 'much'): 0.05697813391799518,\n",
              " (34, 'perfect'): 0.04756443947831368,\n",
              " (34, 'perfectly'): 0.06968093470842047,\n",
              " (34, 'picture'): 0.14309121382154102,\n",
              " (34, 'place'): 0.09937315872647749,\n",
              " (34, 'pretty'): 0.05957661663564119,\n",
              " (34, 'quality'): 0.06726928244550309,\n",
              " (34, 'retailer'): 0.0662981470610149,\n",
              " (34, 'right'): 0.06445468084408155,\n",
              " (34, 'skim'): 0.11704684703476571,\n",
              " (34, 'small'): 0.09544778285539429,\n",
              " (34, 'spring'): 0.08667035793605221,\n",
              " (34, 'summer'): 0.0656695832187374,\n",
              " (34, 'wear'): 0.028436169749094815,\n",
              " (34, 'weight'): 0.09631022128574766,\n",
              " (34, 'well'): 0.056531396027421923,\n",
              " (35, 'base'): 0.0846347782019094,\n",
              " (35, 'big'): 0.05236783464737471,\n",
              " (35, 'buttery'): 0.12077230018916163,\n",
              " (35, 'button'): 0.07350805974502903,\n",
              " (35, 'clean'): 0.0956895334323713,\n",
              " (35, 'cut'): 0.05371238717107411,\n",
              " (35, 'day'): 0.06344864783412102,\n",
              " (35, 'different'): 0.06900341165191161,\n",
              " (35, 'dress'): 0.007110377315876049,\n",
              " (35, 'eat'): 0.12077230018916163,\n",
              " (35, 'ever'): 0.09189116766583057,\n",
              " (35, 'fabric'): 0.0596604538634274,\n",
              " (35, 'fit'): 0.036141840729882066,\n",
              " (35, 'flat'): 0.03119833325479406,\n",
              " (35, 'front'): 0.0601739481774041,\n",
              " (35, 'lay'): 0.09370390468644785,\n",
              " (35, 'meal'): 0.12921948994141502,\n",
              " (35, 'medium'): 0.05801685069946992,\n",
              " (35, 'mother'): 0.11013009969403681,\n",
              " (35, 'number'): 0.10312026143109487,\n",
              " (35, 'online'): 0.05262989261001763,\n",
              " (35, 'order'): 0.06980528636123096,\n",
              " (35, 'pass'): 0.11013009969403681,\n",
              " (35, 'perfectly'): 0.05371238717107411,\n",
              " (35, 'placket'): 0.12077230018916163,\n",
              " (35, 'pleat'): 0.0956895334323713,\n",
              " (35, 'probably'): 0.14701611949005805,\n",
              " (35, 'promo'): 0.12921948994141502,\n",
              " (35, 'regular'): 0.061747022187990455,\n",
              " (35, 'review'): 0.056693654746921465,\n",
              " (35, 'show'): 0.0590674934833635,\n",
              " (35, 'side'): 0.12268495746526834,\n",
              " (35, 'size'): 0.022470240370513823,\n",
              " (35, 'soft'): 0.04856946888083398,\n",
              " (35, 'think'): 0.04209344530305659,\n",
              " (35, 'though'): 0.05801685069946992,\n",
              " (35, 'tight'): 0.05371238717107411,\n",
              " (35, 'time'): 0.06055622189965819,\n",
              " (35, 'trim'): 0.10633173392749609,\n",
              " (35, 'two'): 0.06389669377622442,\n",
              " (35, 'whim'): 0.10633173392749609,\n",
              " (35, 'would'): 0.03256174801005205,\n",
              " (36, 'back'): 0.06435627471238718,\n",
              " (36, 'bump'): 0.14353430014855695,\n",
              " (36, 'decide'): 0.10264889953448886,\n",
              " (36, 'dress'): 0.010665565973814073,\n",
              " (36, 'enjoy'): 0.19382923491212256,\n",
              " (36, 'even'): 0.07418419127183835,\n",
              " (36, 'every'): 0.1234763662056696,\n",
              " (36, 'frabic'): 0.19382923491212256,\n",
              " (36, 'full'): 0.10622422300879336,\n",
              " (36, 'help'): 0.1288466867346277,\n",
              " (36, 'hop'): 0.1203487581257639,\n",
              " (36, 'length'): 0.07005382336219826,\n",
              " (36, 'lump'): 0.16519514954105521,\n",
              " (36, 'maxi'): 0.13533541688394785,\n",
              " (36, 'much'): 0.06588096734268192,\n",
              " (36, 'new'): 0.1234763662056696,\n",
              " (36, 'put'): 0.11617590210624756,\n",
              " (36, 'recently'): 0.1721683855196243,\n",
              " (36, 'sad'): 0.14353430014855695,\n",
              " (36, 'show'): 0.17720248045009052,\n",
              " (36, 'slip'): 0.07855175197106207,\n",
              " (36, 'spanx'): 0.16519514954105521,\n",
              " (36, 'still'): 0.08651713477196175,\n",
              " (36, 'thin'): 0.10350511747786742,\n",
              " (36, 'try'): 0.10676855574419455,\n",
              " (36, 'unfortunately'): 0.11750589005683494,\n",
              " (36, 'wear'): 0.03287932127239088,\n",
              " (36, 'would'): 0.09768524403015616,\n",
              " (37, 'absolutely'): 0.1901247677422483,\n",
              " (37, 'casually'): 0.341004141710574,\n",
              " (37, 'color'): 0.1561574345866789,\n",
              " (37, 'come'): 0.1699029125009057,\n",
              " (37, 'comfortable'): 0.1074575585604492,\n",
              " (37, 'dress'): 0.02007635948012061,\n",
              " (37, 'fall'): 0.14360796479378587,\n",
              " (37, 'get'): 0.09193905320485285,\n",
              " (37, 'great'): 0.08523207800479753,\n",
              " (37, 'love'): 0.11942937780554912,\n",
              " ...}"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf_idf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JYAxzWrwbMD2",
        "outputId": "0341a6d7-6cbc-417b-be4d-8eb5a009ebd1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.08753952, 0.10741287, 0.17829171, ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.        , 0.09452333, 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       ...,\n",
              "       [0.        , 0.        , 0.        , ..., 0.29535883, 0.29535883,\n",
              "        0.        ],\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.15128135],\n",
              "       [0.        , 0.        , 0.25580984, ..., 0.        , 0.        ,\n",
              "        0.        ]])"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JWCmQ4k2eNLd",
        "outputId": "98310610-2f53-41b4-c178-b96f368faac3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(987, 2529)"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "D.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3gDFAP7Te9gb",
        "outputId": "ddaa1931-048a-4248-ee1b-80c9d9954b48"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2496123"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "D.shape[0] * D.shape[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sax912jgcqVi"
      },
      "source": [
        "Let's check memory usage:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2DfBik7gcpzc"
      },
      "outputs": [],
      "source": [
        "from sys import getsizeof # Return the size of an object in bytes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "odJV7MChdAIU",
        "outputId": "e4af18a6-7dce-479a-811a-c6039cf7b2f8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1310808"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "getsizeof(tf_idf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u2qo6ryHdGsb",
        "outputId": "4f8ae23b-0e9f-43b4-ec7e-a6201ec1317f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "19969112"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "getsizeof(D)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2IZJc5RX25OU"
      },
      "source": [
        "3. TF-IDF Matching Score Ranking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YL1pb-K92-Le"
      },
      "outputs": [],
      "source": [
        "def matching_similarity_search(collection, k, query):\n",
        "    \"\"\"\n",
        "    Search of the top-k similar texts from documents collection to the query based on matching score.\n",
        "    collection: list of texts;\n",
        "    k: int, length of the result;\n",
        "    query: str, your text.\n",
        "\n",
        "    Return: list of most similar texts to the query;\n",
        "            each element of the list is prepresented as a tuple: (text_idx, sim_score)\n",
        "    \"\"\"\n",
        "\n",
        "    # 1. Preprocess text and split into tokens.\n",
        "    preprocessed_query = preprocess(query)\n",
        "    tokens = preprocessed_query.split(' ')\n",
        "\n",
        "    query_weights = {}\n",
        "\n",
        "    # 2. The score for each text from dataset in respect of the query is\n",
        "    #    the sum of tf_idf of words that are presented both in the query and in the text.\n",
        "\n",
        "    for key in tf_idf:\n",
        "        if key[1] in tokens:\n",
        "            try:\n",
        "                query_weights[key[0]] += tf_idf[key]\n",
        "            except:\n",
        "                query_weights[key[0]] = tf_idf[key]\n",
        "\n",
        "    query_weights = sorted(query_weights.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    return query_weights[:k]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8lwDG6ipWCUW",
        "outputId": "0b915dcd-52a2-4069-807e-e31cda080ca9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Query:  I really wanted this to work. alas, it had a strange fit for me. the straps would not stay up, and it had a weird fit under the breast. it worked standing up, but the minute i sat down it fell off my shoulders. the fabric was beautiful! and i loved that it had pockets. \n",
            "\n",
            "Index:  0  Similarity:  3.014048768003238  Text:  I really wanted this to work. alas, it had a strange fit for me. the straps would not stay up, and it had a weird fit under the breast. it worked standing up, but the minute i sat down it fell off my shoulders. the fabric was beautiful! and i loved that it had pockets.\n",
            "Index:  860  Similarity:  0.8866572257470782  Text:  The print on this is gorgeous, and it's incredibly comfortable. ultimately, i didn't buy it because the length was weird for me (i'm 5'7\"); it just looked strange, like it was cutting me off at a weird point.\n",
            "Index:  177  Similarity:  0.7550558721114813  Text:  Too tight in strange ways. beautiful dress i was so excited to receive it, however it just did not fit.\n",
            "Index:  671  Similarity:  0.7458581418936183  Text:  Love! color and fabric are beautiful! new fav\n",
            "Index:  122  Similarity:  0.6406271089135855  Text:  The sleeves are fitted which i love. works with a belt or without.\n",
            "Index:  824  Similarity:  0.6033340249875192  Text:  This dress is beautiful. very vibrant and rich looking...however, after wearing it to work the back of the dress was completely stretched out from sitting in my office chair. when i stood up a little bubble remained around my butt. not attractive. i wanted to love it but it's going back.\n",
            "Index:  955  Similarity:  0.6023564338479688  Text:  Beautiful color; however, the fabric did not work for me. tight on top, large on bottom.\n",
            "Index:  500  Similarity:  0.5602676271051534  Text:  Dress is true to size. has a built in liner with thin straps so it is not see through. really cute on.\n",
            "Index:  302  Similarity:  0.5493553201099435  Text:  I just received this dress tried it on. i totally fell in love with it . the pink is just beautiful.it's a little big so i will definitely will be exchanging it for a size 14 . you would absolutely love this dress.\n",
            "Index:  451  Similarity:  0.515941958226266  Text:  The colors and fabric on this dress are really pretty. the lace is a soft blue instead of white. i have other dresses like this from this brand and really wanted to keep it, but it runs larger than the others i have. also, it doesn't have pockets. if it fits you properly, i think you will love it!\n"
          ]
        }
      ],
      "source": [
        "query = reviews_pr.iloc[0]['Review Text']\n",
        "print(\"Query: \", query, \"\\n\")\n",
        "\n",
        "result = matching_similarity_search(reviews_pr, 10, query)\n",
        "\n",
        "for (text_idx, sim_score) in result:\n",
        "    print(\"Index: \", text_idx, \" Similarity: \", sim_score, \" Text: \", reviews_pr.iloc[text_idx][\"Review Text\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LnOAzUKA2-tX"
      },
      "source": [
        "4. TF-IDF Cosine Similarity Ranking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vka3HLm6X9MG"
      },
      "outputs": [],
      "source": [
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t38OaDK13CCj"
      },
      "outputs": [],
      "source": [
        "def cosine_sim(a, b):\n",
        "    cos_sim = np.dot(a, b)/(np.linalg.norm(a)*np.linalg.norm(b))\n",
        "    return cos_sim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XFRpv0Q3XU32"
      },
      "outputs": [],
      "source": [
        "def gen_vector(tokens, total_vocab, collection_len):\n",
        "    \"\"\"\n",
        "    Transform the tokens into the vector representation.\n",
        "    The idea is based on tf-idf as well: we fill the vector with the tf-idfs of the tokens.\n",
        "    \"\"\"\n",
        "\n",
        "    vector = np.zeros((len(total_vocab)))\n",
        "\n",
        "    counter = Counter(tokens)\n",
        "    tokens_count = len(tokens)\n",
        "\n",
        "    for token in np.unique(tokens):\n",
        "\n",
        "        tf = counter[token]/tokens_count\n",
        "        df = doc_freq(token)\n",
        "        idf = math.log((collection_len+1)/(df+1))\n",
        "\n",
        "        try:\n",
        "            ind = total_vocab.index(token)\n",
        "            vector[ind] = tf*idf\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    return vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wxf29zvrXgRU"
      },
      "outputs": [],
      "source": [
        "def cosine_similarity_search(df, k, query):\n",
        "    \"\"\"\n",
        "    Search of the top-k similar texts from documents collection to the query based on cosine similarity.\n",
        "    collection: list of texts;\n",
        "    k: int, length of the result;\n",
        "    query: str, your text.\n",
        "\n",
        "    Return: list of most similar texts to the query;\n",
        "            each element of the list is prepresented as a tuple: (text_idx, sim_score)\n",
        "    \"\"\"\n",
        "\n",
        "    # 1. Preprocess text and split into tokens.\n",
        "    preprocessed_query = preprocess(query)\n",
        "    tokens = preprocessed_query.split(' ')\n",
        "\n",
        "    # 1.1 Transform obtained tokens into vector representation.\n",
        "    query_vector = gen_vector(tokens, total_vocab, df.shape[0])\n",
        "\n",
        "    # 2. The score for each text from dataset in respect of the query is\n",
        "    #    the cosine similarity between tf-idf vectors of these texts.\n",
        "\n",
        "    # Hint: remember structure D that we calculated before?\n",
        "\n",
        "    d_cosines = []\n",
        "\n",
        "    for doc_idx, d in enumerate(D):\n",
        "        d_cosines.append((doc_idx, cosine_sim(query_vector, d)))\n",
        "\n",
        "    d_cosines.sort(key=lambda tup: tup[1], reverse=True)\n",
        "    result = d_cosines[:k]\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v4JBuYtZXxH-",
        "outputId": "9b4576b6-ef5d-4c7e-a4e3-9dd625371bac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Query:  I really wanted this to work. alas, it had a strange fit for me. the straps would not stay up, and it had a weird fit under the breast. it worked standing up, but the minute i sat down it fell off my shoulders. the fabric was beautiful! and i loved that it had pockets. \n",
            "\n",
            "Index:  0  Similarity:  1.0  Text:  I really wanted this to work. alas, it had a strange fit for me. the straps would not stay up, and it had a weird fit under the breast. it worked standing up, but the minute i sat down it fell off my shoulders. the fabric was beautiful! and i loved that it had pockets.\n",
            "Index:  860  Similarity:  0.233098  Text:  The print on this is gorgeous, and it's incredibly comfortable. ultimately, i didn't buy it because the length was weird for me (i'm 5'7\"); it just looked strange, like it was cutting me off at a weird point.\n",
            "Index:  824  Similarity:  0.177983  Text:  This dress is beautiful. very vibrant and rich looking...however, after wearing it to work the back of the dress was completely stretched out from sitting in my office chair. when i stood up a little bubble remained around my butt. not attractive. i wanted to love it but it's going back.\n",
            "Index:  281  Similarity:  0.165314  Text:  Thought this would be a great dress for warm days, but alas it fit like a sack. love floreat and have a few of their well made dresses. shame this did nothing for my curves. ordered an 8, usually wear a 10 and it was a tad narrow in the shoulders. if you can sport a loose swingy shape, this is a great dress with nice detailing, but sadly the shape did not work for me.\n",
            "Index:  177  Similarity:  0.164929  Text:  Too tight in strange ways. beautiful dress i was so excited to receive it, however it just did not fit.\n",
            "Index:  681  Similarity:  0.136296  Text:  I wanted to love this dress, especially because it's been given good reviews. i ordered the blue and tried it on. the fit was pretty good and the color is pretty and deep. i did not like the seam that ran around the drop waist. it created a weird allusion that the two pockets in front was actually a continuous pouch around the dress. i also did not like the neckline - there is fabric added on the shoulders that's in a different fabric and makes it look like you're wearing a t-shirt underneath th\n",
            "Index:  853  Similarity:  0.136163  Text:  Wanted to love this dress, bit it wasn't to be. strange fit, and doesn't drape nicely, as in the photo. also, the blue color was much darker in person. wouldn't recommend.\n",
            "Index:  580  Similarity:  0.135983  Text:  I love this dress and will be purchasing it in other patterns. the fit is incredibly flattering and the fabric is lovely. doesn't wrinkle, easy to wash and wear. i am 5'7, 190lbs, bottom heavy with a 38c bra size. i purchased the size large and it fits me perfectly (though perhaps a little bit snug in the waist). if i wanted a looser fit, an xl would probably work though might be a bit loose on the top. the low back hits just above my bra strap, but does in fact cover all straps. for reference,\n",
            "Index:  926  Similarity:  0.134693  Text:  I tried this on in store in blue, and it's so comfortable. it's just the right level of loose to be flattering. for me, the cap sleeves were a little strange. they just didn't sit in a way that was flattering or seemed purposeful--not sure if that was the design or my body.\n",
            "Index:  451  Similarity:  0.13279  Text:  The colors and fabric on this dress are really pretty. the lace is a soft blue instead of white. i have other dresses like this from this brand and really wanted to keep it, but it runs larger than the others i have. also, it doesn't have pockets. if it fits you properly, i think you will love it!\n"
          ]
        }
      ],
      "source": [
        "query = reviews_pr.iloc[0]['Review Text']\n",
        "print(\"Query: \", query, \"\\n\")\n",
        "\n",
        "result = cosine_similarity_search(reviews_pr, 10, query)\n",
        "\n",
        "for (text_idx, sim_score) in result:\n",
        "    print(\"Index: \", text_idx, \" Similarity: \", round(sim_score, 6), \" Text: \", reviews_pr.iloc[text_idx][\"Review Text\"], end='\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3EJeh6OFpHEq"
      },
      "source": [
        "Compare the results! What is about the time and the memory?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTytV05QtZB9"
      },
      "source": [
        "## TF-IDF with LSA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fX4bWl_1qNFa"
      },
      "source": [
        "And now, after the spent time on coding of your own tf-idf implementation, we will show you that you can use already implemented ```TfidfVectorizer``` :)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MTRswaGItZao"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sys import getsizeof"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_Z1271m1Nb6"
      },
      "source": [
        "1. Create TF_IDF matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-1HHK8qyZuf",
        "outputId": "6bcddb53-6036-4b9a-c95d-deb952389767"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocabulary Size :  2513\n",
            "Shape of Matrix :  (2513, 987)\n",
            "Memory usage:  48\n",
            "CPU times: user 44.6 ms, sys: 839 µs, total: 45.5 ms\n",
            "Wall time: 44.6 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "TF_IDF_matrix = vectorizer.fit_transform(reviews_pr['Processed Review'])\n",
        "TF_IDF_matrix = TF_IDF_matrix.T\n",
        "\n",
        "print('Vocabulary Size : ', len(vectorizer.get_feature_names_out()))\n",
        "print('Shape of Matrix : ', TF_IDF_matrix.shape)\n",
        "print('Memory usage: ', getsizeof(TF_IDF_matrix))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xPRdooCq6UV"
      },
      "source": [
        "Why so less memory?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yLOE4h32q0my",
        "outputId": "a857ac27-31eb-4f29-c388-1f49fe385c89"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<2513x987 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 25475 stored elements in Compressed Sparse Column format>"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "TF_IDF_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJzhe5ic1SKS"
      },
      "source": [
        "2. Get SVD decomposition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0q6r7Fjr-j5"
      },
      "source": [
        "<img src=\"https://github.com/dardem/word2vec_seminar/raw/master/img/svd.png\" style=\"width:100%\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UIL3RUkVQCjY"
      },
      "source": [
        "where, $C$ is the matrix of *Terms* x *Documents*, $U$ -  semi-unitary matrix of *Terms* x *Dimension*, $\\sigma$ - diagonal matrix of singular values,  *V* - semi-unitary matrix of *Documents* x *Dimension*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RSift0I61XS8"
      },
      "outputs": [],
      "source": [
        "K = 10 # number of most important components"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-Gz30oJ1UTR",
        "outputId": "d9270597-4e32-4e93-f7b1-1115308cc79a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 8 s, sys: 13.2 s, total: 21.2 s\n",
            "Wall time: 914 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "# Applying SVD\n",
        "U, s, VT = np.linalg.svd(TF_IDF_matrix.toarray()) # .toarray() is used to convert sparse matrix to normal matrix\n",
        "\n",
        "TF_IDF_matrix_reduced = np.dot(U[:,:K], np.dot(np.diag(s[:K]), VT[:K, :]))\n",
        "\n",
        "# Getting document and term representation\n",
        "terms_rep = np.dot(U[:,:K], np.diag(s[:K])) # TODO: M X N matrix where M = Vocabulary Size and N = Number of documents\n",
        "docs_rep = np.dot(np.diag(s[:K]), VT[:K, :]).T # TODO: N x K matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hizv5gpXsnDU",
        "outputId": "c6861244-68c9-42e4-e76f-a777adbbfedb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "50521480"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "getsizeof(U)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-g9sAJOtssxn",
        "outputId": "42a2e8ee-9a8a-4edd-a890-03dff463cfc0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "8008"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "getsizeof(s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1PoyIiefsuVm",
        "outputId": "445aceac-ce1b-4796-e0e2-dfe6bdc38a41"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "7793480"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "getsizeof(VT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xrg1GP2_k_cj",
        "outputId": "651d49e1-2f26-49c3-f58a-e437cbf404a8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "19842776"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "getsizeof(TF_IDF_matrix_reduced)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NRIjvwcT1jAL"
      },
      "source": [
        "3. Find most similar to the query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qEkYvZxV1rX9"
      },
      "outputs": [],
      "source": [
        "from scipy.spatial.distance import cosine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1anZWJwq1nH9"
      },
      "outputs": [],
      "source": [
        "def lsa_query_rep(query):\n",
        "    query_rep = [vectorizer.vocabulary_[x] for x in preprocess(query).split()]\n",
        "    query_rep = np.mean(terms_rep[query_rep],axis=0)\n",
        "    return query_rep"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_ZHUL9I1uP7",
        "outputId": "dbcd5b16-07c7-4d98-ba03-e799314f9890"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Query:  I really wanted this to work. alas, it had a strange fit for me. the straps would not stay up, and it had a weird fit under the breast. it worked standing up, but the minute i sat down it fell off my shoulders. the fabric was beautiful! and i loved that it had pockets. \n",
            "\n",
            "Rank :  0  Cosine sim:  0.95473  Review :  I really wanted to love this dress, but it just didn't fit in anyway. i ordered an xs petite, and it was very large. the lacing in the back is completely useless, and that's what i liked about the dress. i was thinking it would be unlaced more at the top (because of chest) and then lace more tightly near the waist. it was completely closed off and the dress was still very loose and unflattering. beautiful fabric, great color combo, bad fit.\n",
            "Rank :  1  Cosine sim:  0.94549  Review :  I wanted to love this dress as it seemed perfect for spring and summer, but it just didn't work for me. it made me feel a bit frumpy, honestly. i purchased the neutral color. maybe the \"red\" would have been less... grandmotherly. something about the elastic waist just didn't work for me either. i tried this with boots, booties, heels, clogs, flats, sandals and i just couldn't make this dress work. sadly sending this one back. i'm 5'7\", 140 lbs and tried the medium.\n",
            "Rank :  2  Cosine sim:  0.930326  Review :  This dress is very cute! i loved it. the quality is excellent. however, the fit is off. i'm 5\"1, 107lbs, 32c. this dress was roomy in the bust and was a little too broad shouldered. it was tight around the waist. this caused creasing and buldging in the back. the color is much more vibrant in person. i would have kept it, if it fit properly.\n",
            "Rank :  3  Cosine sim:  0.927954  Review :  I bought this dress online to wear to work and i did not expect anything too impressive based on the picture of the model. i am really surprised at how beautiful, well-fitting, and soft this dress is. i am in love. it fits snugly, but the fabric is so thick that it is still very office appropriate (i work at a law firm). i ordered the small petite and it comes to the top of my knees.\n",
            "Rank :  4  Cosine sim:  0.917819  Review :  Wow this dress is very flattering! i have a fairly small waist and not-so-small hips and this dress is slimming. it is also soft, light, airy, gorgeous! exactly what you need on a beautiful spring day! i wore this dress yesterday and have not felt that beautiful in a very long time! thank you so much retailer for the brilliant design:)\n",
            "Rank :  5  Cosine sim:  0.915538  Review :  This is an absolutely gorgeous dress. i have the arcata patchwork dress which fits beautifully without looking too full, but this one is just too voluminous. also, the bottom of the front yoke hits at a weird spot on my bust. this would be a great maternity dress or it would be perfect for a thin woman who can carry off the large amount of fabric. so disappointed, the fabric is beautiful and the colors are too. this can be worn year round, with sandals or boots.\n",
            "Rank :  6  Cosine sim:  0.91018  Review :  I tried on the refgular xs and it fit, btu the cut was wring on me, i moved up the dress as though it was cut \"petite\" and what a difference! i will ahve to roder the petite for sure.\n",
            "\n",
            "te material is a thicker knit, very strectchy and warm enough to carry the dress through winter and spring.\n",
            "the shoulders are well covered, in a flattering way. the chest area is crossed over \"open\", not stiched close, so yo ucan adjsut as needed. te \"tie\" jsut falls but is attached to the dress on one side, so it\n",
            "Rank :  7  Cosine sim:  0.903897  Review :  Beautiful, feminine, flowy dress. love the brass button detail at neckline and around waist-gives the otherwise delicate dress a pop of \"edge\". had to detach the slip to get it on, but glad it is included with the dress. i purchased the small and fits like a glove (5'8\", 135lbs, 34d). can't wait to wear it!!\n",
            "Rank :  8  Cosine sim:  0.90242  Review :  I took a risk on this dress despite the multiple reviews about the pouffy skirt and revealing neckline, because i loved the look of the blue motif print. alas, the adorable print, the handy bra-strap holders, and super-soft fabric were the only things that worked for me. i'm 5'3\" and 120 lb, small up top, not especially curvy but not straight either, and i ordered my usual 2p. yup, the pleated skirt was much too full (i felt as though i was wearing a cheerleader's skirt) and the neckline was way\n",
            "Rank :  9  Cosine sim:  0.90055  Review :  I am a petite girl, 5'2\"/105 lbs- i bought size s and it fits me just right. i love the way the fabric feels on my body. i tried this dress with flat shoe and it doesn't make me look short. the colors are vibrant but not too bright which makes it perfect for any time of the year to wear.\n",
            "Rank :  10  Cosine sim:  0.898568  Review :  Great dress - the hardest part was picking which color. the dress is a slim swing silhouette and very flattering. the fabric skims the body without highlighting my problem areas (lower abdomen and hips). the dress is modest enough for work (it ends a few inches above the knee in the middle, comes to my knee on the sides). i am always a xs or s in maeve - i went with the small on this dress. the sleeves aren't as long as the picture shows - they ended where they should. i went with the navy and w\n"
          ]
        }
      ],
      "source": [
        "query = reviews_pr.iloc[0]['Review Text']\n",
        "print(\"Query: \", query, \"\\n\")\n",
        "\n",
        "query_rep = lsa_query_rep(query)\n",
        "\n",
        "query_doc_cos_dist = [cosine(query_rep, doc_rep) for doc_rep in docs_rep]\n",
        "query_doc_sort_index = np.argsort(np.array(query_doc_cos_dist))\n",
        "\n",
        "print_count = 0\n",
        "for rank, sort_index in enumerate(query_doc_sort_index):\n",
        "    print ('Rank : ', rank, ' Cosine sim: ', round(1 - query_doc_cos_dist[sort_index], 6),' Review : ', reviews_pr['Review Text'][sort_index])\n",
        "    if print_count == 10 :\n",
        "        break\n",
        "    else:\n",
        "        print_count += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zLt65TcntF8z"
      },
      "source": [
        "Compare the results!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oigQz8V7M4fV"
      },
      "source": [
        "# Word2Vec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xa1GcKO0SddM"
      },
      "source": [
        "`Word2Vec` is a more recent model that embeds words in a lower-dimensional vector space using a shallow neural network. The result is a set of word-vectors where vectors close together in vector space have similar meanings based on context, and word-vectors distant to each other have differing meanings. For example, `strong` and `powerful` would be close together and `strong` and `Paris` would be relatively far."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0k4mb0f1NO9E"
      },
      "source": [
        "## Main idea"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-bW0Z6ESjF1"
      },
      "source": [
        "<img src=\"https://github.com/dardem/word2vec_seminar/raw/master/img/w2v-example1.png\" style=\"width:100%\">\n",
        "<img src=\"https://github.com/dardem/word2vec_seminar/raw/master/img/w2v-example2.png\" style=\"width:100%\">\n",
        "\n",
        "Source: https://drive.google.com/file/d/1y2GKIKBzie7l8iycBO6gTKGiTTfJc4Dr/view"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d47XoUukNSDG"
      },
      "source": [
        "## Implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-TUtlQsS6IV"
      },
      "source": [
        "### Some additional downloading"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGuaI1dsTBlH"
      },
      "source": [
        "Dataset download:\n",
        "\n",
        "(for more details about the data please see: http://mattmahoney.net/dc/textdata.html, section Relationship of Wikipedia Text to Clean Text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ow_Vx58S9nO",
        "outputId": "3ccbd540-1c8f-4a91-cefe-6a4f8e251cc3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2022-11-21 17:32:23--  http://mattmahoney.net/dc/text8.zip\n",
            "Resolving mattmahoney.net (mattmahoney.net)... 67.195.197.24\n",
            "Connecting to mattmahoney.net (mattmahoney.net)|67.195.197.24|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 31344016 (30M) [application/zip]\n",
            "Saving to: ‘text8.zip’\n",
            "\n",
            "text8.zip           100%[===================>]  29.89M   724KB/s    in 43s     \n",
            "\n",
            "2022-11-21 17:33:07 (710 KB/s) - ‘text8.zip’ saved [31344016/31344016]\n",
            "\n",
            "Archive:  text8.zip\n",
            "  inflating: text8                   \n"
          ]
        }
      ],
      "source": [
        "# !wget http://mattmahoney.net/dc/text8.zip\n",
        "# !unzip text8.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mU3XHo_HT63X"
      },
      "source": [
        "Supplementary functions for dataset preprocessing download:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CSL-pCgHT-In",
        "outputId": "b3d8ea90-4d96-4615-ec3a-c019df9f5780"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2022-11-21 17:08:53--  https://github.com/blackredscarf/pytorch-SkipGram/raw/master/data_utils.py\n",
            "Resolving github.com (github.com)... 140.82.121.4\n",
            "Connecting to github.com (github.com)|140.82.121.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/blackredscarf/pytorch-SkipGram/master/data_utils.py [following]\n",
            "--2022-11-21 17:08:53--  https://raw.githubusercontent.com/blackredscarf/pytorch-SkipGram/master/data_utils.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5323 (5.2K) [text/plain]\n",
            "Saving to: ‘data_utils.py’\n",
            "\n",
            "data_utils.py       100%[===================>]   5.20K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-11-21 17:08:53 (72.1 MB/s) - ‘data_utils.py’ saved [5323/5323]\n",
            "\n",
            "--2022-11-21 17:08:54--  https://github.com/blackredscarf/pytorch-SkipGram/raw/master/vector_handle.py\n",
            "Resolving github.com (github.com)... 140.82.121.4\n",
            "Connecting to github.com (github.com)|140.82.121.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/blackredscarf/pytorch-SkipGram/master/vector_handle.py [following]\n",
            "--2022-11-21 17:08:54--  https://raw.githubusercontent.com/blackredscarf/pytorch-SkipGram/master/vector_handle.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1568 (1.5K) [text/plain]\n",
            "Saving to: ‘vector_handle.py’\n",
            "\n",
            "vector_handle.py    100%[===================>]   1.53K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-11-21 17:08:54 (28.0 MB/s) - ‘vector_handle.py’ saved [1568/1568]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# !wget https://github.com/blackredscarf/pytorch-SkipGram/raw/master/data_utils.py\n",
        "# !wget https://github.com/blackredscarf/pytorch-SkipGram/raw/master/vector_handle.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RWfhhHshUF_j"
      },
      "source": [
        "Supplementary functions for model evaluation download:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_Xs32EdUITR",
        "outputId": "bbe4cb03-4e78-4b80-a194-50ce6461994a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2022-11-21 17:08:54--  https://github.com/dardem/word2vec_seminar/raw/master/eval.zip\n",
            "Resolving github.com (github.com)... 140.82.121.4\n",
            "Connecting to github.com (github.com)|140.82.121.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/dardem/word2vec_seminar/master/eval.zip [following]\n",
            "--2022-11-21 17:08:54--  https://raw.githubusercontent.com/dardem/word2vec_seminar/master/eval.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7054 (6.9K) [application/zip]\n",
            "Saving to: ‘eval.zip’\n",
            "\n",
            "eval.zip            100%[===================>]   6.89K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-11-21 17:08:55 (75.3 MB/s) - ‘eval.zip’ saved [7054/7054]\n",
            "\n",
            "Archive:  eval.zip\n",
            "   creating: eval/\n",
            "  inflating: eval/wordsim.py         \n",
            "  inflating: eval/read_write.py      \n",
            "  inflating: eval/ranking.py         \n",
            "  inflating: eval/all_wordsim.py     \n",
            "   creating: eval/data/\n",
            "  inflating: eval/data/EN-MTurk-287.txt  \n",
            "  inflating: eval/data/EN-MC-30.txt  \n"
          ]
        }
      ],
      "source": [
        "# !wget https://github.com/dardem/word2vec_seminar/raw/master/eval.zip\n",
        "# !unzip eval.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4oQfSRyURSr"
      },
      "source": [
        "Check the installed files:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MPzHYw6lUPyk",
        "outputId": "0f8df7b5-2d8f-46a5-c559-edab5071bb87"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 214.zip\t\t    glove.6B.zip\n",
            " 214.zip.1\t\t    out\n",
            " data_utils.py\t\t    __pycache__\n",
            " embeddings\t\t    quora.txt\n",
            " eval\t\t\t    ru_fasttext_model\n",
            " eval.zip\t\t    text8\n",
            " gensim_glove_vectors.txt   text8.zip\n",
            " glove.6B.100d.txt\t    vector_handle.py\n",
            " glove.6B.200d.txt\t   'Womens Clothing E-Commerce Reviews.csv'\n",
            " glove.6B.300d.txt\t   'Womens Clothing E-Commerce Reviews.csv.1'\n",
            " glove.6B.50d.txt\t    Word_embeddings.ipynb\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymRqG5rNVW_c"
      },
      "source": [
        "### SkipGram model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZUr19qJVeXt"
      },
      "source": [
        "<img src=\"https://raw.githubusercontent.com/dardem/word2vec_seminar/master/img/word2vec_diagram-1.jpg\" style=\"width:100%\">\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/dardem/word2vec_seminar/master/img/Skip-gram-architecture-2.jpg\" style=\"width:30%\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yR5wgHuJ7d-Z"
      },
      "source": [
        "<img src=\"https://raw.githubusercontent.com/dardem/word2vec_seminar/master/img/w2v-loss.png\" style=\"width:100%\">\n",
        "\n",
        "source: https://drive.google.com/file/d/1y2GKIKBzie7l8iycBO6gTKGiTTfJc4Dr/view"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxqWGt62Smvw"
      },
      "source": [
        "<img src=\"https://raw.githubusercontent.com/dardem/word2vec_seminar/master/img/w2v-objective.png\" style=\"width:100%\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aH-O9UdEVhur"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "\n",
        "class SkipGramNeg(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim):\n",
        "        super(SkipGramNeg, self).__init__()\n",
        "        self.input_emb = nn.Embedding(vocab_size, emb_dim)\n",
        "        self.output_emb = nn.Embedding(vocab_size, emb_dim)\n",
        "        self.log_sigmoid = nn.LogSigmoid()\n",
        "\n",
        "        initrange = (2.0 / (vocab_size + emb_dim)) ** 0.5  # Xavier init\n",
        "        self.input_emb.weight.data.uniform_(-initrange, initrange)\n",
        "        self.output_emb.weight.data.uniform_(-0, 0)\n",
        "\n",
        "\n",
        "    def forward(self, target_input, context, neg):\n",
        "        \"\"\"\n",
        "        :param target_input: [batch_size]\n",
        "        :param context: [batch_size]\n",
        "        :param neg: [batch_size, neg_size]\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        # u,v: [batch_size, emb_dim]\n",
        "        v = self.input_emb(target_input)\n",
        "        u = self.output_emb(context)\n",
        "        # positive_val: [batch_size]\n",
        "        positive_val = self.log_sigmoid(torch.sum(u * v, dim=1)).squeeze()\n",
        "\n",
        "        # u_hat: [batch_size, neg_size, emb_dim]\n",
        "        u_hat = self.output_emb(neg)\n",
        "        # [batch_size, neg_size, emb_dim] x [batch_size, emb_dim, 1] = [batch_size, neg_size, 1]\n",
        "        # neg_vals: [batch_size, neg_size]\n",
        "        neg_vals = torch.bmm(u_hat, v.unsqueeze(2)).squeeze(2) # batch matrix-matrix product of matrices\n",
        "        # neg_val: [batch_size]\n",
        "        neg_val = self.log_sigmoid(-torch.sum(neg_vals, dim=1)).squeeze()\n",
        "\n",
        "        loss = positive_val + neg_val\n",
        "        return -loss.mean()\n",
        "\n",
        "    def predict(self, inputs):\n",
        "        return self.input_emb(inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e22iPlSLVnpQ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import torch\n",
        "from torch.optim import SGD\n",
        "from data_utils import read_own_data, build_dataset, DataPipeline\n",
        "from vector_handle import nearest\n",
        "\n",
        "\n",
        "class Word2Vec:\n",
        "    def __init__(self, data_path, vocabulary_size, embedding_size, learning_rate=1.0):\n",
        "        self.corpus = read_own_data(data_path)\n",
        "\n",
        "        self.data, self.word_count, self.word2index, self.index2word = build_dataset(\n",
        "            self.corpus, vocabulary_size\n",
        "        )\n",
        "        self.vocabs = list(set(self.data))\n",
        "\n",
        "        self.model: SkipGramNeg = SkipGramNeg(vocabulary_size, embedding_size).cuda()\n",
        "        self.model_optim = SGD(self.model.parameters(), lr=learning_rate)\n",
        "\n",
        "    def train(\n",
        "        self,\n",
        "        train_steps,\n",
        "        skip_window=1,\n",
        "        num_skips=2,\n",
        "        num_neg=20,\n",
        "        batch_size=128,\n",
        "        data_offest=0,\n",
        "        vali_size=3,\n",
        "        output_dir=\"out\",\n",
        "    ):\n",
        "        if not os.path.exists(output_dir):\n",
        "            os.mkdir(output_dir)\n",
        "        self.outputdir = output_dir\n",
        "\n",
        "        avg_loss = 0\n",
        "        pipeline = DataPipeline(self.data, self.vocabs, self.word_count, data_offest)\n",
        "        vali_examples = random.sample(self.vocabs, vali_size)\n",
        "\n",
        "        for step in range(train_steps):\n",
        "            batch_inputs, batch_labels = pipeline.generate_batch(\n",
        "                batch_size, num_skips, skip_window\n",
        "            )\n",
        "            batch_neg = pipeline.get_neg_data(batch_size, num_neg, batch_inputs)\n",
        "\n",
        "            batch_inputs = torch.tensor(batch_inputs, dtype=torch.long).cuda()\n",
        "            batch_labels = torch.tensor(batch_labels, dtype=torch.long).cuda()\n",
        "            batch_neg = torch.tensor(batch_neg, dtype=torch.long).cuda()\n",
        "\n",
        "            loss = self.model(batch_inputs, batch_labels, batch_neg)\n",
        "            self.model_optim.zero_grad()\n",
        "            loss.backward()\n",
        "            self.model_optim.step()\n",
        "\n",
        "            avg_loss += loss.item()\n",
        "\n",
        "            if step % 2000 == 0 and step > 0:\n",
        "                avg_loss /= 2000\n",
        "                print(\"Average loss at step \", step, \": \", avg_loss)\n",
        "                avg_loss = 0\n",
        "            if step % 10000 == 0 and vali_size > 0:\n",
        "                nearest(self.model, vali_examples, vali_size, self.index2word, top_k=8)\n",
        "            # checkpoint\n",
        "            if step % 100000 == 0 and step > 0:\n",
        "                torch.save(\n",
        "                    self.model.state_dict(), self.outputdir + \"/model_step%d.pt\" % step\n",
        "                )\n",
        "        # save model at last\n",
        "        torch.save(\n",
        "            self.model.state_dict(), self.outputdir + \"/model_step%d.pt\" % train_steps\n",
        "        )\n",
        "\n",
        "    def save_model(self, out_path):\n",
        "        torch.save(self.model.state_dict(), out_path + \"/model.pt\")\n",
        "\n",
        "    def get_list_vector(self):\n",
        "        sd = self.model.state_dict()\n",
        "        return sd[\"input_emb.weight\"].tolist()\n",
        "\n",
        "    def save_vector_txt(self, path_dir):\n",
        "        embeddings = self.get_list_vector()\n",
        "        fo = open(path_dir + \"/vector.txt\", \"w\")\n",
        "        for idx in range(len(embeddings)):\n",
        "            word = self.index2word[idx]\n",
        "            embed = embeddings[idx]\n",
        "            embed_list = [str(i) for i in embed]\n",
        "            line_str = \" \".join(embed_list)\n",
        "            fo.write(word + \" \" + line_str + \"\\n\")\n",
        "        fo.close()\n",
        "\n",
        "    def load_model(self, model_path):\n",
        "        self.model.load_state_dict(torch.load(model_path))\n",
        "\n",
        "    def vector(self, index):\n",
        "        self.model.predict(index)\n",
        "\n",
        "    def most_similar(self, word, top_k=8):\n",
        "        index = self.word2index[word]\n",
        "        index = torch.tensor(index, dtype=torch.long).cuda().unsqueeze(0)\n",
        "        emb = self.model.predict(index)\n",
        "        sim = torch.mm(emb, self.model.input_emb.weight.transpose(0, 1))\n",
        "        nearest = (-sim[0]).sort()[1][1 : top_k + 1]\n",
        "        top_list = []\n",
        "        for k in range(top_k):\n",
        "            close_word = self.index2word[nearest[k].item()]\n",
        "            top_list.append(close_word)\n",
        "        return top_list\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eaAdpescVxBL"
      },
      "source": [
        "### Run the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHOO_kUEVt4G"
      },
      "source": [
        "So, let's finally build your own Word2Vec model!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CG45BLvwVrZg",
        "outputId": "05195bb2-bb6a-4778-ac24-a1dc20371617"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "reading data...\n",
            "corpus size 17005207\n"
          ]
        }
      ],
      "source": [
        "# init dataset and model\n",
        "word2vec = Word2Vec(data_path='text8',\n",
        "                    vocabulary_size=50000,\n",
        "                    embedding_size=300)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eqW-_gajWCSO"
      },
      "outputs": [],
      "source": [
        "# additional check for output folder\n",
        "if not os.path.exists('out'):\n",
        "  os.mkdir('out')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pIpAYhWsWF6d",
        "outputId": "680ac473-2764-463e-a939-c5ea4386f5e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "vocabulary size 50000\n",
            "unigram_table size: 2870\n",
            "Nearest to contributing: ade, borne, gog, ounces, balder, neurotransmitter, zebra, coupling,\n",
            "Nearest to polka: tulsa, undeniably, dg, primo, scattering, decoder, isothermal, schama,\n",
            "Nearest to gao: archipelago, rejuvenation, riders, fostered, dickinson, menstrual, ganga, ideologue,\n",
            "Average loss at step  2000 :  0.9115511239767075\n",
            "Average loss at step  4000 :  0.8026582121625543\n",
            "Average loss at step  6000 :  0.7826968179345131\n",
            "Average loss at step  8000 :  0.767112163439393\n",
            "Average loss at step  10000 :  0.7428255868703126\n",
            "Nearest to contributing: eight, five, one, seven, archie, agave, zero, four,\n",
            "Nearest to polka: zero, two, five, polka, four, to, and, gland,\n",
            "Nearest to gao: a, agave, as, UNK, is, or, an, that,\n",
            "Average loss at step  12000 :  0.7416164618730545\n",
            "Average loss at step  14000 :  0.7296159547418356\n",
            "Average loss at step  16000 :  0.6954028851240873\n",
            "Average loss at step  18000 :  0.6853225033283233\n",
            "Average loss at step  20000 :  0.7150298338383436\n",
            "Nearest to contributing: dasyprocta, circ, nine, seven, one, eight, operatorname, d,\n",
            "Nearest to polka: dasyprocta, circ, operatorname, d, seven, nine, six, eight,\n",
            "Nearest to gao: a, is, as, UNK, his, agave, an, that,\n",
            "Average loss at step  22000 :  0.7000395747795701\n",
            "Average loss at step  24000 :  0.689040553510189\n",
            "Average loss at step  26000 :  0.6876442180424929\n",
            "Average loss at step  28000 :  0.6876258237361907\n",
            "Average loss at step  30000 :  0.6716510652378201\n",
            "Nearest to contributing: nine, zero, seven, agouti, dasyprocta, one, six, two,\n",
            "Nearest to polka: dasyprocta, circ, operatorname, eight, zero, seven, nine, b,\n",
            "Nearest to gao: of, as, is, or, that, not, such, be,\n",
            "Average loss at step  32000 :  0.6822793262265623\n",
            "Average loss at step  34000 :  0.6771023217588663\n",
            "Average loss at step  36000 :  0.6758318468481302\n",
            "Average loss at step  38000 :  0.6656752575784922\n",
            "Average loss at step  40000 :  0.646909723713994\n",
            "Nearest to contributing: zero, two, three, nine, seven, eight, four, five,\n",
            "Nearest to polka: dasyprocta, circ, operatorname, zero, d, seven, three, one,\n",
            "Nearest to gao: as, of, or, is, such, not, be, that,\n",
            "Average loss at step  42000 :  0.6592630975842476\n",
            "Average loss at step  44000 :  0.6541650699153543\n",
            "Average loss at step  46000 :  0.6594553129673004\n",
            "Average loss at step  48000 :  0.6516501318365335\n",
            "Average loss at step  50000 :  0.639111416734755\n",
            "Nearest to contributing: eight, one, zero, seven, two, six, five, three,\n",
            "Nearest to polka: nine, agouti, seven, dasyprocta, zero, six, one, five,\n",
            "Nearest to gao: be, of, are, as, or, such, also, can,\n",
            "Average loss at step  52000 :  0.6362782229781151\n",
            "Average loss at step  54000 :  0.6416539785712957\n",
            "Average loss at step  56000 :  0.6464099845439195\n",
            "Average loss at step  58000 :  0.6430844138264656\n",
            "Average loss at step  60000 :  0.6384173508957028\n",
            "Nearest to contributing: eight, one, five, six, seven, zero, two, four,\n",
            "Nearest to polka: nine, agouti, six, seven, five, dasyprocta, one, ursus,\n",
            "Nearest to gao: or, are, be, can, but, as, of, not,\n",
            "Average loss at step  62000 :  0.6375896634608507\n",
            "Average loss at step  64000 :  0.6315439459905028\n",
            "Average loss at step  66000 :  0.5949935305230319\n",
            "Average loss at step  68000 :  0.6410312387496233\n",
            "Average loss at step  70000 :  0.6278608986437321\n",
            "Nearest to contributing: zero, eight, be, that, five, three, one, nine,\n",
            "Nearest to polka: six, seven, zero, nine, five, agouti, three, one,\n",
            "Nearest to gao: be, are, or, of, can, have, as, such,\n",
            "Average loss at step  72000 :  0.6217309175655246\n",
            "Average loss at step  74000 :  0.6137005557119847\n",
            "Average loss at step  76000 :  0.6219853782951832\n",
            "Average loss at step  78000 :  0.616521083779633\n",
            "Average loss at step  80000 :  0.6040953777134418\n",
            "Nearest to contributing: nine, zero, seven, five, are, four, is, one,\n",
            "Nearest to polka: seven, five, zero, four, six, eight, agouti, two,\n",
            "Nearest to gao: be, are, or, can, have, more, of, number,\n",
            "Average loss at step  82000 :  0.6071873800978065\n",
            "Average loss at step  84000 :  0.6155319580808282\n",
            "Average loss at step  86000 :  0.618344651773572\n",
            "Average loss at step  88000 :  0.6113301831185818\n",
            "Average loss at step  90000 :  0.6104638551156968\n",
            "Nearest to contributing: are, that, seven, to, can, is, nine, three,\n",
            "Nearest to polka: nine, agouti, three, eight, five, dasyprocta, ursus, zero,\n",
            "Nearest to gao: can, a, are, have, or, number, may, more,\n",
            "Average loss at step  92000 :  0.6109143235236406\n",
            "Average loss at step  94000 :  0.607557950079441\n",
            "Average loss at step  96000 :  0.6100482121109962\n",
            "Average loss at step  98000 :  0.5920555360540748\n",
            "CPU times: user 12min 11s, sys: 3.51 s, total: 12min 14s\n",
            "Wall time: 12min 17s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "# train model\n",
        "word2vec.train(train_steps=10000, #100000, 200000,\n",
        "               skip_window=5,\n",
        "               num_skips=2,\n",
        "               num_neg=20,\n",
        "               output_dir='out/run-1')\n",
        "\n",
        "\n",
        "# save vector txt file\n",
        "word2vec.save_vector_txt(path_dir='out/run-1')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U4JAAO_AWWlz",
        "outputId": "c68834f1-3cf4-4774-966f-99d38101da19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model_step100000.pt  model_step10000.pt  vector.txt\n"
          ]
        }
      ],
      "source": [
        " !ls ./out/run-1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aCbFHd4uWcz2",
        "outputId": "cb2a9ecb-bd32-4e87-c00d-230d7b463a8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.02993914671242237, -0.03296276554465294, 0.05721461772918701, 0.0032790484838187695, -0.045988406985998154, -0.02553842030465603, -0.005984775256365538, 0.02494504302740097, -0.048611342906951904, -0.01586763933300972, 0.0045379698276519775, 0.009204240515828133, 0.024623500183224678, -0.017930280417203903, 0.011793102137744427, 0.0014372544828802347, 0.022291338071227074, 0.0182212982326746, -0.03774702548980713, -0.037110645323991776, 0.010638721287250519, -0.03145379200577736, -0.024130264297127724, 0.054582662880420685, -0.003392234444618225, 0.03257051482796669, 0.05203283205628395, -0.035986557602882385, -0.022964324802160263, -0.04559066891670227, -0.10107764601707458, -0.022228572517633438, -0.06592140346765518, -0.08699414134025574, -0.00477756280452013, 0.08182952553033829, -0.0010690552880987525, -0.0001771818206179887, -0.006366613786667585, 0.02718970738351345, -0.010745959356427193, 0.009019610472023487, 0.08704546838998795, -0.07676339894533157, -0.02311559207737446, -0.06545279175043106, -0.03252769634127617, -0.011970827355980873, 0.015294567681849003, 0.024303972721099854, 0.04052061587572098, 0.024687854573130608, 0.011023103259503841, 0.019140250980854034, -0.014361118897795677, -0.08497340977191925, -0.00046733435010537505, 0.02550317719578743, 0.030319977551698685, -0.007338459603488445, -0.09407369792461395, 0.049274858087301254, -0.016036685556173325, -0.07503712922334671, 0.05266809090971947, -0.033617373555898666, -0.023820139467716217, 0.04500625282526016, 0.010444399900734425, -0.022765664383769035, 0.04531474411487579, 0.04737688973546028, 0.005916851107031107, 0.017101680859923363, -0.0004048519767820835, 0.0019408516818657517, 0.0167611762881279, -0.054014623165130615, 0.02547389641404152, 5.3533498430624604e-05, -0.002278914675116539, -0.0524008683860302, -0.010048450902104378, 0.011196674779057503, -0.02004239335656166, 0.004529926925897598, 0.05586019530892372, 0.03533518686890602, -0.01791287027299404, 0.010555231012403965, 0.0014073241036385298, 0.05793895199894905, 0.05150927975773811, -0.017944568768143654, 0.021233009174466133, 0.014384733512997627, -0.009512374177575111, -0.021486908197402954, -0.06329809129238129, 0.027989588677883148, -0.030947860330343246, 0.024956336244940758, 0.0013646672014147043, -0.01706288568675518, 0.013887877576053143, -0.01024160347878933, 0.0370674692094326, 0.03701665997505188, -0.00010473084694240242, 0.020804645493626595, 0.0031087128445506096, 0.026249654591083527, -0.018025852739810944, 0.02793056145310402, 0.024499690160155296, -0.06262389570474625, 0.013025451451539993, -0.021883154287934303, -0.0037625322584062815, -0.042098063975572586, 0.050037138164043427, 0.048216257244348526, -0.03314671665430069, 0.0542789064347744, 0.0049730627797544, -0.082093246281147, -0.017195621505379677, -0.0352821871638298, 0.013306623324751854, 0.031233714893460274, -0.04038010910153389, -0.003782382234930992, -0.06287340819835663, 0.020387765020132065, 0.01747186854481697, 0.022358281537890434, -0.011173645965754986, -0.00449761189520359, -0.01288867648690939, -0.005478404462337494, -0.026812797412276268, 0.024596264585852623, 0.05348636209964752, 0.011925701051950455, -0.0696968138217926, 0.050096940249204636, -0.00346544967032969, -0.014337803237140179, 0.010759999975562096, 0.06326619535684586, 0.003436074359342456, 0.040578968822956085, 0.05152237415313721, 0.010513147339224815, 0.015827864408493042, 0.01126131135970354, 0.04534772038459778, 0.0782928466796875, 0.024411644786596298, -0.0792936235666275, 0.012163939885795116, -0.04175696521997452, -0.07432354241609573, -0.016133546829223633, -0.05493881553411484, 0.025247802957892418, -0.0234697125852108, 0.01074889861047268, -0.02848479337990284, -0.04667612537741661, -0.015066954307258129, -0.021087754517793655, -0.05391540005803108, -0.015421434305608273, -0.021359574049711227, -0.04921936243772507, -0.051030710339546204, -0.003216373734176159, 0.033098429441452026, -0.024553747847676277, -0.036202508956193924, -0.04705200716853142, -0.0014943946152925491, 0.042268842458724976, 0.004609847906976938, 0.0568242147564888, 0.0006603863439522684, -0.018725581467151642, -0.001687059411779046, -0.04117315262556076, -0.03826462849974632, 0.046212825924158096, 0.05851675197482109, -0.02210254967212677, -0.02197573333978653, 0.0418783538043499, 0.040839195251464844, 0.002148762810975313, 0.008771569468080997, 0.03916405886411667, 0.036301787942647934, -0.04544258490204811, 0.07320164144039154, -0.01409661304205656, 0.0773497223854065, -0.024958938360214233, 0.0014123322907835245, -0.012709574773907661, 0.00903094932436943, 0.06547468900680542, 0.009397880174219608, -0.00551449554041028, 0.008174777962267399, -0.0306220892816782, -0.0032309992238879204, -0.05785287171602249, -0.015829917043447495, 0.014600075781345367, 0.05140221491456032, -0.06146242842078209, 0.01723734475672245, 0.05246834084391594, 0.03896833211183548, -0.030590549111366272, -0.019003553315997124, 0.041932471096515656, -0.037021905183792114, -0.006531603168696165, -0.03801769018173218, -0.060565296560525894, -0.010612535290420055, 0.027251720428466797, 0.03934133052825928, -0.005283306818455458, 0.007672029081732035, 0.03895602747797966, 0.08974892646074295, 0.040890831500291824, -0.06164230778813362, -0.03793943300843239, 0.062001921236515045, 0.03722032159566879, 0.021650677546858788, 0.0051016369834542274, 0.005488208960741758, -0.07086265087127686, 0.04006935656070709, 0.017998673021793365, 0.043849918991327286, -0.040730103850364685, -0.020695172250270844, -0.04362815245985985, -0.014976153150200844, 0.01201457716524601, -0.01655111089348793, -0.03847147151827812, -0.014094951562583447, 0.016664594411849976, 0.02795020304620266, 0.04394505172967911, 0.030119314789772034, 0.055049970746040344, -0.004155679605901241, -0.011446843855082989, 0.02632295899093151, 0.048575133085250854, 0.006586586590856314, -0.030720630660653114, 0.08538071066141129, -0.04225112870335579, -0.04025566950440407, -0.0390346422791481, 0.01574287749826908, 0.05299836024641991, 0.03472647815942764, -0.010456197895109653, 0.01722976751625538, -0.06858962774276733, -0.03419627621769905, -0.07670767605304718, 0.036948926746845245, -0.03871805965900421, 0.0006922895554453135, 0.001264769583940506, 0.01780344545841217, 0.005266611929982901, 0.008679204620420933, 0.008539858274161816, 0.0546698234975338, -0.024792276322841644, 0.06221386790275574, 0.008797876536846161, 0.010941644199192524, -0.00424666004255414, 0.013232370838522911, 0.013709132559597492, 0.023990202695131302, 0.00572171900421381, 0.07171045988798141, 0.05514003708958626]\n",
            "[0.0011091858614236116, 0.012240719050168991, 0.0012626382522284985, 0.003517525503411889, -0.01004927046597004, -0.003719050670042634, -0.003032906446605921, 0.008359597064554691, -0.006774410605430603, -0.004228235688060522, 0.00659265648573637, -0.0021087524946779013, -0.001456038560718298, -0.002892362419515848, 0.009247279725968838, 0.006493213586509228, 0.008659766986966133, -7.08997540641576e-05, -0.0004797095898538828, -0.019228357821702957, -0.00604970520362258, -0.007456351071596146, -0.0036837703082710505, 0.00048669311217963696, 0.006976174656301737, -0.00517849437892437, 0.009974660351872444, -0.003365614451467991, -0.007556363940238953, 0.0012181662023067474, 0.0030898908153176308, -0.004284675698727369, -0.014145661145448685, 0.001341331284493208, 0.007148928940296173, 0.00481468066573143, -0.013891005888581276, 0.0067071616649627686, -0.0015060496516525745, 2.4985289201140404e-05, 0.005791695788502693, 0.007210747338831425, 0.01006773766130209, -0.0029837898910045624, -0.003896568901836872, -0.0016604731790721416, -0.006626491900533438, -0.0021269768476486206, 0.0010948090348392725, 0.0010582825634628534, 0.013058146461844444, -0.0022228388115763664, 0.009990392252802849, 0.002100852085277438, 0.006489946506917477, -0.013812078163027763, 0.01865154318511486, 0.006642023101449013, 0.024304131045937538, -0.014752732589840889, -0.004337111487984657, 0.002356854500249028, 0.0025557484477758408, -0.010102538391947746, 0.015463599003851414, -0.0013870056718587875, 0.003930651117116213, 0.001709692645817995, -0.0005665812641382217, -0.007764192298054695, -0.001364034367725253, 0.02370523102581501, 0.0033404482528567314, -0.004116318188607693, 0.003922000527381897, -0.0048748888075351715, 0.002533623483031988, -0.00557188643142581, -0.008088481612503529, -0.010736176744103432, 0.0031970918644219637, -0.006756423972547054, 0.007971021346747875, -0.000430042389780283, -0.0036827311851084232, -0.00481040682643652, 0.0048143588937819, 0.007195068057626486, 0.0033607929944992065, 0.003089897334575653, -0.01129008736461401, -0.002253764308989048, 0.0029332153499126434, -0.012765945866703987, -0.0011693701380863786, 0.0003531400579959154, -0.0010399892926216125, 0.000722276046872139, -0.016689591109752655, -0.009635835886001587, 0.00019771751249209046, 0.010478160344064236, -0.0037407344207167625, -0.0040184929966926575, 0.0072278473526239395, -0.011536184698343277, 0.012066243216395378, 0.0010376221034675837, 0.007434999570250511, -0.004893876612186432, -0.004017948638647795, 0.003701396519318223, 0.0026462473906576633, 0.009891081601381302, 0.011266063898801804, -0.002671612426638603, 0.00632870988920331, -0.007434654515236616, 0.009400388225913048, 0.0026852849405258894, 0.00960627757012844, 0.02067417837679386, 0.0018331252504140139, 0.006918006110936403, -0.013216691091656685, -0.008175193332135677, -0.005195313598960638, -0.013653107918798923, 0.016988206654787064, 0.004427230916917324, -0.009430107660591602, 0.005333432462066412, 3.826245665550232e-05, -0.0011608167551457882, 0.008653989061713219, -0.00386758241802454, 0.008600765839219093, 0.01541739609092474, 0.00019136397168040276, 0.007007678970694542, 0.0008189138025045395, 0.010506129823625088, 0.0025139101780951023, 0.011872190050780773, -0.0043978700414299965, -0.016047745943069458, -0.007649115286767483, -0.006111886352300644, -0.0010752540547400713, 0.00398681964725256, 0.010374253615736961, -0.00013003498315811157, 0.009954826906323433, 0.009008605033159256, 0.011183427646756172, -0.00171571783721447, 0.008870474062860012, 0.002637268276885152, 0.0060579814016819, -0.0009388716425746679, 0.005483428481966257, 0.00200247997418046, -0.0021469644270837307, -0.010968003422021866, -0.017469557002186775, 0.013454413041472435, -0.010344395413994789, 0.0042987242341041565, 0.004826097749173641, 0.006032346747815609, -0.003654227592051029, 0.004670427646487951, -0.01486702635884285, -0.00593061838299036, -0.005534861236810684, -0.009154606610536575, -0.01158997230231762, -0.009278872050344944, 0.004188300110399723, -0.012629019096493721, 0.0006123699713498354, 0.00624562194570899, 0.0018605878576636314, 0.0005743042565882206, -0.0018977813888341188, 0.019589321687817574, -0.0061609442345798016, -0.004184923134744167, -0.01168881542980671, 0.0031302254647016525, -0.010121522471308708, 0.00011857680510729551, 0.00806466769427061, 0.0053034452721476555, 0.0009397468529641628, 0.013504513539373875, -0.0036855179350823164, -0.006136855110526085, -0.006626633461564779, 0.00816011056303978, 0.004962878301739693, -0.001929140416905284, 0.010666667483747005, -0.007121266331523657, 0.01638985238969326, -7.573515176773071e-05, 0.0029921724926680326, -0.0027883315924555063, 0.0033909440971910954, 0.00969100371003151, 0.003768739989027381, 0.008421778678894043, 0.000239513348788023, -0.005617436021566391, 0.008679465390741825, -0.016437936574220657, -0.010229813866317272, -0.005987341981381178, 0.0012686289846897125, -0.013429844751954079, -0.013888688758015633, 0.009013107977807522, -0.0009150884579867125, -0.007188163232058287, 0.004534116014838219, 0.009863490238785744, -0.011716820299625397, -0.003825595136731863, -0.003642768133431673, -0.006997112184762955, 0.0003757108934223652, 0.005981968715786934, 0.0014602881856262684, -0.013560852035880089, 0.0016818648437038064, 0.008332095108926296, 0.009760810062289238, 0.01114894449710846, -0.00814612302929163, -0.004003765061497688, 0.0004963476676493883, 0.007007413078099489, 0.003681192407384515, -0.0018420986598357558, -0.001380488509312272, -0.01631559245288372, 0.0017058933153748512, 0.007172243669629097, 0.00865183025598526, -0.009557157754898071, -0.002130337990820408, -0.004702769685536623, -0.006891629658639431, -0.004712759517133236, 0.0057373191229999065, 0.0055427635088562965, -0.0024944045580923557, -0.003057511756196618, -0.00909520871937275, -0.0012874804669991136, -0.003645231481641531, 0.00929545983672142, -0.012391176074743271, -0.008914781734347343, 0.008061891421675682, 0.00023983605206012726, 0.0059153190813958645, -0.006297782529145479, 0.008542703464627266, -0.0074205221608281136, -0.014563193544745445, -0.0003514024429023266, 0.008225750178098679, 0.004303810186684132, 0.015408094972372055, -0.0025021221954375505, -0.0022778159473091364, -0.010307122953236103, -0.010841915383934975, 0.0017566794995218515, 0.013926522806286812, -0.010570242069661617, -0.00448946375399828, 0.0003580620978027582, -0.0006339922547340393, 0.0010476738680154085, 0.008576717227697372, 0.0031879807356745005, 0.00854464340955019, 0.0038936221972107887, 0.018728923052549362, 0.005805268418043852, 0.004126276820898056, -0.00907578133046627, -0.015917150303721428, -0.00982200913131237, 0.007105167955160141, -0.011535681784152985, 0.01666589267551899, -0.001988863805308938]\n"
          ]
        }
      ],
      "source": [
        "# Example of extracting word's representation\n",
        "vector = word2vec.get_list_vector()\n",
        "print(vector[123])\n",
        "print(vector[word2vec.word2index['hello']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KUbVkE91Wfh9",
        "outputId": "f01bb402-2f47-46c5-c512-56be5ea02410"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['nine', 'eight', 'six', 'seven', 'two', 'zero', 'four', 'three']\n"
          ]
        }
      ],
      "source": [
        "# get top k similar word\n",
        "sim_list = word2vec.most_similar('one', top_k=8)\n",
        "print(sim_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VzSnMhN6WmEJ"
      },
      "outputs": [],
      "source": [
        "# try also for random validation samples and check if the model became better\n",
        "# sim_list = word2vec.most_similar(<some random sample>, top_k=8)\n",
        "# print(sim_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m7jM8NXTWrPy"
      },
      "outputs": [],
      "source": [
        "# load pre-train model\n",
        "# word2vec.load_model('out/run-1/model_step200000.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GVjAsFpkWtcg",
        "outputId": "c3960ce3-b1ba-4630-9604-4345f0bb9726"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.03364092]])"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#some magic for the famous trick\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "mystery_word = (np.array(vector[word2vec.word2index['king']]) - np.array(vector[word2vec.word2index['man']])).reshape(1, -1)\n",
        "\n",
        "# try with othe random words, e.g. kitty :)\n",
        "cosine_similarity(mystery_word, np.array(vector[word2vec.word2index['queen']]).reshape(1, -1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M721qJzrZBbq"
      },
      "source": [
        "## Pretrained models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BdDZclVRi4gm"
      },
      "source": [
        "__Word vectors:__ as the saying goes, there's more than one way to train word embeddings. There's Word2Vec and GloVe with different objective functions. Then there's fasttext that uses character-level models to train word embeddings.\n",
        "\n",
        "The choice is huge, so let's start someplace small: __gensim__ is another nlp library that features many vector-based models incuding word2vec."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tU7tKCntEC5l"
      },
      "source": [
        "### Predefined architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOba8CcKEXBf"
      },
      "source": [
        "Train data downloading:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-2R7JtPCXhTy",
        "outputId": "4f46c9fe-ae5c-45e7-850f-770a2b6ffcb1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2022-11-22 10:22:10--  https://www.dropbox.com/s/obaitrix9jyu84r/quora.txt?dl=1\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.5.18, 2620:100:601d:18::a27d:512\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.5.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /s/dl/obaitrix9jyu84r/quora.txt [following]\n",
            "--2022-11-22 10:22:10--  https://www.dropbox.com/s/dl/obaitrix9jyu84r/quora.txt\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uca7e8d79db091c573fd54ba17fc.dl.dropboxusercontent.com/cd/0/get/BxODsyf4Pa0owtQUVHBNj54DHeVkk8ojdMuspoMXT7xF3AS6Ul39BMrQTETnXcY1VsnC643jC1ZvOqO38pyDo78fiLMTQu96d-pUbVJI1SSNSHrQHJItAilYZZ4jwTsYlRBEbRfR9Cq3cD5X9LlnNfrTFzehdw1NTlB8DkXRarEZFA/file?dl=1# [following]\n",
            "--2022-11-22 10:22:11--  https://uca7e8d79db091c573fd54ba17fc.dl.dropboxusercontent.com/cd/0/get/BxODsyf4Pa0owtQUVHBNj54DHeVkk8ojdMuspoMXT7xF3AS6Ul39BMrQTETnXcY1VsnC643jC1ZvOqO38pyDo78fiLMTQu96d-pUbVJI1SSNSHrQHJItAilYZZ4jwTsYlRBEbRfR9Cq3cD5X9LlnNfrTFzehdw1NTlB8DkXRarEZFA/file?dl=1\n",
            "Resolving uca7e8d79db091c573fd54ba17fc.dl.dropboxusercontent.com (uca7e8d79db091c573fd54ba17fc.dl.dropboxusercontent.com)... 162.125.5.15, 2620:100:601d:15::a27d:50f\n",
            "Connecting to uca7e8d79db091c573fd54ba17fc.dl.dropboxusercontent.com (uca7e8d79db091c573fd54ba17fc.dl.dropboxusercontent.com)|162.125.5.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 33813903 (32M) [application/binary]\n",
            "Saving to: ‘./quora.txt’\n",
            "\n",
            "./quora.txt         100%[===================>]  32.25M  59.6MB/s    in 0.5s    \n",
            "\n",
            "2022-11-22 10:22:12 (59.6 MB/s) - ‘./quora.txt’ saved [33813903/33813903]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# download the data:\n",
        "# !wget https://www.dropbox.com/s/obaitrix9jyu84r/quora.txt?dl=1 -O ./quora.txt\n",
        "# alternative download link: https://yadi.sk/i/BPQrUu1NaTduEw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "A9MgSB6gXiY_",
        "outputId": "8f929032-204c-4bf2-e0da-b1c6ebd181de"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Who discovered plate tectonics and how?\\n',\n",
              " 'Is the Earth the only planet that has life on it?\\n']"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "data = list(open(\"./quora.txt\", encoding=\"utf-8\"))\n",
        "data[42]\n",
        "data[20:22]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MpvM9hNoXrfQ"
      },
      "source": [
        "__Tokenization:__ a typical first step for an nlp task is to split raw data into words.\n",
        "The text we're working with is in raw format: with all the punctuation and smiles attached to some words, so a simple str.split won't do.\n",
        "\n",
        "Let's use __`nltk`__ - a library that handles many nlp tasks like tokenization, stemming or part-of-speech tagging."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5DDKqTBwXw-p",
        "outputId": "d035a7b6-05eb-48f9-b442-4962ad278759"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['How', 'does', 'the', 'finance', 'credit', 'score', 'work', '?']\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[Parse(word=\"can i get back with my ex even though she is pregnant with another guy's baby?\\n\", tag=OpencorporaTag('LATN'), normal_form=\"can i get back with my ex even though she is pregnant with another guy's baby?\\n\", score=1.0, methods_stack=((LatinAnalyzer(score=0.9), \"Can I get back with my ex even though she is pregnant with another guy's baby?\\n\"),))]"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from nltk.tokenize import WordPunctTokenizer\n",
        "# !pip install pymorphy2\n",
        "import pymorphy2\n",
        "morph = pymorphy2.MorphAnalyzer()\n",
        "tokenizer = WordPunctTokenizer()\n",
        "# data = ['я тебя люблю очень сильно', 'ты здание банка китая']\n",
        "print(tokenizer.tokenize(data[42]))\n",
        "morph.parse(data[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8C9ykLRQX3c8"
      },
      "outputs": [],
      "source": [
        "data_tok = [tokenizer.tokenize(sent.lower()) for sent in data]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cAqpOdWb562t",
        "outputId": "d89cc5fd-24ee-487c-e5fb-c6b8e8bdb9bc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Parse(word='ways', tag=OpencorporaTag('LATN'), normal_form='ways', score=1.0, methods_stack=((LatinAnalyzer(score=0.9), 'ways'),))]"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_tok[0]\n",
        "morph.parse(data_tok[1][3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "192uoWrjiyUx",
        "outputId": "3faace6c-9cfd-4d9c-8068-34daff8f3025"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[\"can i get back with my ex even though she is pregnant with another guy ' s baby ?\", 'what are some ways to overcome a fast food addiction ?']\n"
          ]
        }
      ],
      "source": [
        "print([' '.join(row) for row in data_tok[:2]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dL0vIPPRFCo_"
      },
      "source": [
        "Load the model architecture:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YtddW2bSi9wx"
      },
      "outputs": [],
      "source": [
        "from gensim.models import Word2Vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x6k1Wdgji-2s",
        "outputId": "a2bede55-1cd0-41c3-8759-b31db1db580c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 1.25 ms, sys: 44 µs, total: 1.29 ms\n",
            "Wall time: 1.04 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "en_w2v_model = Word2Vec(vector_size=32,      # embedding vector size\n",
        "                 min_count=5,  # consider words that occured at least 5 times\n",
        "                 window=5)  # define context as a 5-word window around the target word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MuAYKJITDvPV"
      },
      "outputs": [],
      "source": [
        "en_w2v_model.build_vocab(data_tok)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xc88yuU6DvPV",
        "outputId": "2096597a-7104-48ad-ad9f-9dbd720b062c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(478995204, 713134500)"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "en_w2v_model.train(data_tok, epochs=100, total_words=10e5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hc4w1jd9jFRu",
        "outputId": "fae25e27-aa07-4a54-d5ff-5732a6804bf7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([-4.336226  , -3.8685353 ,  3.3240254 , -0.11518155,  2.360612  ,\n",
              "       -1.0111531 ,  3.9578047 , -2.6149962 , -1.1785423 ,  8.675043  ,\n",
              "       -1.3252401 ,  0.11825431,  5.074105  , -6.042519  , -0.9434248 ,\n",
              "        1.7335101 , -0.19674218,  0.3741732 ,  5.030587  , -2.0936818 ,\n",
              "        3.6172826 , -1.9526972 ,  4.2750626 , -1.7522057 ,  2.4683518 ,\n",
              "        1.8074629 , -2.3640206 ,  0.77915543,  7.5844936 , -1.872772  ,\n",
              "       -1.9331567 ,  0.8436681 ], dtype=float32)"
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# now you can get word vectors !\n",
        "en_w2v_model.wv.get_vector('anything')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nXgl55j-jHHV",
        "outputId": "ebb46f91-6942-4f36-bd0b-7955d1834d29"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('hey', 0.8107662796974182),\n",
              " ('however', 0.6886940002441406),\n",
              " ('knw', 0.648284912109375),\n",
              " ('d', 0.6446653604507446),\n",
              " ('here', 0.6443655490875244),\n",
              " ('josh', 0.6431625485420227),\n",
              " ('hello', 0.6381719708442688),\n",
              " ('rahman', 0.6322135925292969),\n",
              " ('sorry', 0.6321156024932861),\n",
              " ('guess', 0.6250742077827454)]"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# or query similar words directly. Go play with it!\n",
        "en_w2v_model.wv.most_similar('hi')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IdxpXq-YjKRp",
        "outputId": "7daf6352-834e-412c-963f-20790880869b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('stephanie', 0.7667716145515442),\n",
              " ('impaler', 0.7640563249588013),\n",
              " ('vlad', 0.761570394039154),\n",
              " ('wick', 0.7601789832115173),\n",
              " ('emperor', 0.7565460205078125),\n",
              " ('percy', 0.7528669238090515),\n",
              " ('paul', 0.7515218257904053),\n",
              " ('prince', 0.7456627488136292),\n",
              " ('queen', 0.7442420721054077),\n",
              " ('patton', 0.7438921332359314)]"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "en_w2v_model.wv.most_similar(positive=['king', 'man'], negative=['woman'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8T5lKWj4EO2j"
      },
      "source": [
        "### Pretrained weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PlWAT_sbYlyg"
      },
      "source": [
        "Download model based on Wikipedia 2014 + Gigaword 5 (6B tokens, 400K vocab, uncased, 300d vectors, 822 MB download)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9_bEdF4YPaB",
        "outputId": "b1d51625-cd17-4d88-e8d4-7bbe269e6ef4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2022-11-21 19:30:09--  http://nlp.stanford.edu/data/wordvecs/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/wordvecs/glove.6B.zip [following]\n",
            "--2022-11-21 19:30:09--  https://nlp.stanford.edu/data/wordvecs/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.cs.stanford.edu/nlp/data/wordvecs/glove.6B.zip [following]\n",
            "--2022-11-21 19:30:10--  https://downloads.cs.stanford.edu/nlp/data/wordvecs/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182753 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.04MB/s    in 2m 40s  \n",
            "\n",
            "2022-11-21 19:32:51 (5.13 MB/s) - ‘glove.6B.zip’ saved [862182753/862182753]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ! wget nlp.stanford.edu/data/wordvecs/glove.6B.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H_aayRQaZT-Y",
        "outputId": "37468d02-ee5c-4b6e-c18c-9fd89028a8c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n",
            "  inflating: glove.6B.50d.txt        \n"
          ]
        }
      ],
      "source": [
        "# ! unzip glove.6B.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BuqxSc31kDS0"
      },
      "source": [
        "More about different pretrained corpuses:\n",
        "[GloVe: Global Vectors for Word Representation](https://nlp.stanford.edu/projects/glove/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "haDLWPzhhQLL",
        "outputId": "635fae7d-4615-4ee4-b71d-6e6baae89d41"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_442678/3248711926.py:2: DeprecationWarning: Call to deprecated `glove2word2vec` (KeyedVectors.load_word2vec_format(.., binary=False, no_header=True) loads GLoVE text vectors.).\n",
            "  glove2word2vec(glove_input_file=\"glove.6B.300d.txt\", word2vec_output_file=\"gensim_glove_vectors.txt\")\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(400001, 300)"
            ]
          },
          "execution_count": 80,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from gensim.scripts.glove2word2vec import glove2word2vec\n",
        "glove2word2vec(glove_input_file=\"glove.6B.300d.txt\", word2vec_output_file=\"gensim_glove_vectors.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1cWtuq61aSKp",
        "outputId": "32b44395-45c7-40fb-8a4c-e782955d7771"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 48.7 s, sys: 758 ms, total: 49.4 s\n",
            "Wall time: 49 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "from gensim.models.keyedvectors import KeyedVectors\n",
        "en_w2v_model = KeyedVectors.load_word2vec_format(\"gensim_glove_vectors.txt\", binary=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ja9-KuKJkEJy"
      },
      "outputs": [],
      "source": [
        "# %%time\n",
        "# Alternative method for glove model download\n",
        "\n",
        "# import gensim.downloader as api\n",
        "\n",
        "# model = api.load('glove-twitter-100')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qVS2FtiNnJyy",
        "outputId": "9ac44dd3-8915-4332-a582-42f6aaceee8d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([-6.7832e-01, -2.8658e-01, -2.8904e-01,  1.5099e-01, -4.6720e-01,\n",
              "       -1.7424e-01, -7.7790e-01,  3.5469e-01,  6.9431e-02, -1.7409e+00,\n",
              "       -4.8699e-03,  3.2813e-01, -5.5443e-01,  5.1388e-01,  5.3065e-01,\n",
              "        2.3718e-02,  2.2542e-01,  7.6866e-01,  1.8348e-01,  1.6765e-01,\n",
              "       -1.5293e-01, -2.7201e-01, -5.3389e-02,  1.0727e+00, -4.6678e-01,\n",
              "       -2.4596e-01,  1.9205e-01, -7.6138e-02,  3.9775e-02,  1.6546e-01,\n",
              "        6.4188e-02,  4.1207e-01, -4.1290e-01,  8.8176e-01, -6.5510e-01,\n",
              "       -1.9994e-01,  2.8036e-01, -8.3058e-01,  1.0374e-02,  2.5017e-01,\n",
              "       -2.7072e-01, -5.8058e-02,  4.0706e-01, -2.3871e-01,  1.8965e-01,\n",
              "       -4.7930e-02, -2.0027e-01,  8.7983e-01, -1.5852e-01, -2.8104e-01,\n",
              "        1.5497e-01, -4.3207e-02,  4.2794e-01, -8.6033e-01, -2.6242e-01,\n",
              "       -1.0455e-02,  2.3501e-01, -6.6707e-01,  9.1331e-01,  5.2429e-01,\n",
              "        5.8939e-01,  5.7586e-01,  5.5180e-01,  7.6329e-03, -8.5204e-03,\n",
              "        3.0554e-01,  7.6697e-01,  5.9108e-01,  7.0538e-01,  1.1238e-01,\n",
              "       -9.0403e-01, -1.6447e-02, -2.3331e-01,  1.1001e-01,  4.2131e-01,\n",
              "        1.3606e-01,  7.4933e-01,  2.1881e-01,  9.1022e-02,  1.0485e-03,\n",
              "       -5.9029e-02, -8.7691e-01, -1.7981e-01, -7.0328e-01, -4.3474e-01,\n",
              "        5.1056e-02, -3.4611e-01, -3.5496e-02,  2.0899e-01,  9.7815e-01,\n",
              "       -1.1824e+00,  2.2588e-01, -3.1996e-01,  3.8422e-01,  5.3247e-01,\n",
              "       -2.2620e-03,  1.5448e-01, -5.0967e-01, -2.5917e-01, -5.9710e-01,\n",
              "        3.9107e-01, -1.4222e-01,  2.7077e-01, -3.5628e-01,  4.3577e-01,\n",
              "       -8.8991e-02, -5.5458e-01, -1.7143e-01,  5.8984e-01,  8.0713e-01,\n",
              "        2.8028e-01,  2.2328e-01,  2.1526e-02,  2.7553e-01, -2.9532e-01,\n",
              "        5.2237e-01, -7.2729e-01,  1.1545e-01,  2.2929e-01,  7.5072e-02,\n",
              "        5.4481e-01,  1.9021e-01, -4.0298e-01,  5.5573e-02, -4.9142e-01,\n",
              "       -4.7031e-01, -2.5173e-01,  3.5656e-01,  1.1060e-01, -5.6907e-01,\n",
              "       -1.3531e-01, -3.6373e-01,  4.1751e-01, -5.3124e-01,  2.7847e-01,\n",
              "        4.3066e-01,  7.9628e-02, -2.5931e-01,  3.6937e-01,  3.4245e-01,\n",
              "        1.0407e-01, -2.4097e-01, -2.6858e-01, -7.6618e-01,  2.8394e-01,\n",
              "        7.7548e-02,  4.0936e-01, -3.2688e-01,  7.3876e-02, -9.1736e-02,\n",
              "        3.6128e-01,  1.8135e-01,  5.6811e-03,  2.8969e-01, -2.6299e-01,\n",
              "       -6.4381e-02, -2.4225e-01,  3.4060e-01,  2.9908e-01, -1.4234e-01,\n",
              "        4.9909e-01,  2.5458e-01,  3.5177e-01, -1.9589e-01, -3.4086e-01,\n",
              "        2.3373e-01, -2.5709e-01, -1.3877e-01, -2.6277e-01, -5.2706e-02,\n",
              "       -1.1595e-01, -4.8156e-01, -9.0607e-01,  4.6636e-01,  5.1595e-02,\n",
              "       -3.4741e-02, -1.4946e-01, -5.1309e-01, -2.7204e-01,  3.2716e-01,\n",
              "       -7.4073e-02, -3.4105e-01, -4.6576e-01, -1.5427e-01,  1.4188e-01,\n",
              "       -7.4312e-01, -2.3913e-01, -5.4185e-02,  1.1740e-01, -2.2640e-03,\n",
              "       -1.9828e-01, -1.0785e-01,  7.4878e-01,  2.2633e-01,  2.8089e-02,\n",
              "       -4.7786e-01, -5.5061e-01,  3.8334e-01, -6.2191e-01, -2.5123e-01,\n",
              "        3.8423e-01,  6.2201e-02, -2.9053e-01, -1.3212e-01,  2.6334e-01,\n",
              "       -1.2940e-01, -4.8455e-01,  4.3410e-01, -3.5046e-01,  2.3182e-01,\n",
              "       -2.4127e-01, -4.3299e-02, -1.9837e-01,  3.0301e-01,  3.0141e-01,\n",
              "        2.5875e-01, -2.9343e-01, -1.6192e-01,  5.4568e-02, -1.1934e-01,\n",
              "       -4.2876e-01,  8.4863e-01, -5.9459e-01, -9.7473e-02, -5.8616e-02,\n",
              "       -4.3642e-01,  5.1889e-01,  1.3969e-01,  1.6807e-02, -1.6591e-01,\n",
              "       -4.6360e-02,  3.0513e-01, -9.7903e-01,  2.1439e-01, -3.0293e-01,\n",
              "        3.5319e-01,  4.1856e-01, -2.1809e-01, -3.1039e-02,  6.7093e-02,\n",
              "        3.0627e-01,  4.4614e-01,  5.2404e-01, -2.7002e-01, -3.0012e-01,\n",
              "        4.0193e-01, -3.6158e-01,  3.3633e-01, -4.6169e-01,  2.0490e-01,\n",
              "       -9.8852e-03,  5.4703e-01, -8.7479e-02,  1.3277e-02, -3.0094e-01,\n",
              "        1.1301e-01,  4.1901e-01,  1.4966e-01,  2.8868e-01, -1.1724e-01,\n",
              "       -5.2644e-01, -6.0630e-02, -6.8909e-01, -1.5775e-01, -2.0760e-01,\n",
              "       -1.2078e-01,  2.8747e-01, -4.6810e-02,  2.4905e-01,  2.5454e-01,\n",
              "        2.0358e-01, -3.8940e-01, -1.0326e-01, -5.4677e-01, -1.0668e-01,\n",
              "       -8.7698e-02, -1.7634e+00,  1.3899e-01,  7.2607e-01, -2.1184e-01,\n",
              "        4.4955e-03, -8.6272e-01, -1.7118e-01, -2.7742e-01,  1.0553e-02,\n",
              "       -3.0210e-01,  4.3939e-02, -1.8756e-01,  3.7060e-01,  6.3767e-01,\n",
              "       -1.6007e-01, -9.6833e-02, -2.0280e-01, -1.7306e-01,  8.2309e-02,\n",
              "        3.7477e-01, -2.3171e-01, -1.7050e-01, -5.2997e-01,  2.9491e-01],\n",
              "      dtype=float32)"
            ]
          },
          "execution_count": 82,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "en_w2v_model.get_vector(\"language\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XDwgfENQkKV4",
        "outputId": "05082dc5-0500-4199-b195-c4d25d4b9d62"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('king', 0.6552621126174927),\n",
              " ('ii', 0.5050469040870667),\n",
              " ('prince', 0.491478830575943),\n",
              " ('majesty', 0.48908838629722595),\n",
              " ('monarch', 0.47834306955337524),\n",
              " ('royal', 0.46305179595947266),\n",
              " ('elizabeth', 0.45092126727104187),\n",
              " ('vi', 0.44612547755241394),\n",
              " ('crown', 0.4368758201599121),\n",
              " ('brother', 0.43661490082740784)]"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "en_w2v_model.most_similar(positive=[\"queen\", \"man\"], negative=[\"woman\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ja5MyLLOkMlR",
        "outputId": "4e76e073-2f3e-4099-d646-3f65ecf1cdbb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('neuroscientist', 0.524850070476532),\n",
              " ('mathematician', 0.4939815104007721),\n",
              " ('biologist', 0.4928779602050781),\n",
              " ('geneticist', 0.4879351854324341),\n",
              " ('biochemist', 0.47275030612945557),\n",
              " ('scientist', 0.4704717993736267),\n",
              " ('chemist', 0.46199890971183777),\n",
              " ('astrophysicist', 0.45520147681236267),\n",
              " ('physics', 0.45381951332092285),\n",
              " ('neurologist', 0.45040658116340637)]"
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# try with your own example\n",
        "en_w2v_model.most_similar(positive=[\"physicist\", \"brain\"], negative=[\"money\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "if7UlQN0bmJX",
        "outputId": "72bdaf13-b003-4c39-e80b-3664405fbade"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('monty', 0.6837382316589355),\n",
              " ('perl', 0.519283652305603),\n",
              " ('cleese', 0.5092198252677917),\n",
              " ('pythons', 0.5007115006446838),\n",
              " ('php', 0.4942314326763153),\n",
              " ('grail', 0.4683017134666443),\n",
              " ('scripting', 0.46761268377304077),\n",
              " ('skit', 0.4474538266658783),\n",
              " ('javascript', 0.4312553107738495),\n",
              " ('spamalot', 0.43117913603782654)]"
            ]
          },
          "execution_count": 86,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "en_w2v_model.most_similar(positive=[\"python\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zw9n7rL5cnN1",
        "outputId": "c050e375-2272-4d71-d051-e946fe391d5d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('ph.d.', 0.8992077708244324),\n",
              " ('ph.d', 0.8668009638786316),\n",
              " ('doctoral', 0.8411757349967957),\n",
              " ('doctorate', 0.8270341157913208),\n",
              " ('dissertation', 0.7371240854263306),\n",
              " ('thesis', 0.7319737672805786),\n",
              " ('graduate', 0.6834654808044434),\n",
              " ('postgraduate', 0.6737526059150696),\n",
              " ('b.a.', 0.6614392399787903),\n",
              " ('post-graduate', 0.6560631990432739)]"
            ]
          },
          "execution_count": 87,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "en_w2v_model.most_similar(positive=[\"phd\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrc5XjWacDVw",
        "outputId": "d9f2c112-8157-47ed-e77f-12ab4102a4f6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('step-sister', 0.42128294706344604),\n",
              " ('edmore', 0.4122830927371979),\n",
              " ('kalwa', 0.4101993143558502),\n",
              " ('grammia', 0.4099090099334717),\n",
              " ('thất', 0.4093276560306549),\n",
              " ('cw96', 0.4002326428890228),\n",
              " ('rw96', 0.39980965852737427),\n",
              " ('pangle', 0.39888158440589905),\n",
              " ('iliyan', 0.39772501587867737),\n",
              " ('3.6730', 0.392292320728302)]"
            ]
          },
          "execution_count": 88,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "en_w2v_model.most_similar(positive=[\"phd\"], negative=[\"panini\", \"coffee\", \"code\", \"experiments\", \"paper\", \"conference\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-HFA7eah4vf"
      },
      "source": [
        "**Have fun**: how good are you at word vectors algebra now?\n",
        "\n",
        "\n",
        "Let's check it: play [Semantic Space Surfer](https://lena-voita.github.io/nlp_course/word_embeddings.html#have_fun)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1pMAWjrEDvPX"
      },
      "source": [
        "### Flair - yet another NLP framework, that supports word embeddings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OS5iqydbDvPX"
      },
      "source": [
        "![image.png](attachment:c5531b8f-f8b5-4de9-a409-1528ce12870a.png)\n",
        "\n",
        "Flair embeddings are powerful embeddings that capture latent syntactic-semantic information that goes beyond standard word embeddings. Key differences are:\n",
        "\n",
        "    -they are trained without any explicit notion of words and thus fundamentally model words as sequences of characters\n",
        "    -they are contextualized by their surrounding text, meaning that the same word will have different embeddings depending on its contextual use.\n",
        "\n",
        "Source: http://aclanthology.lst.uni-saarland.de/C18-1139.pdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MuUNn3YTDvPY",
        "outputId": "f85e175f-f502-4468-bb14-db31c21fa8b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-11-14 14:00:22,435 https://flair.informatik.hu-berlin.de/resources/embeddings/flair/news-backward-0.4.1.pt not found in cache, downloading to /tmp/tmpinwcvmzo\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████████████████████████████████████████████████████| 69.7M/69.7M [00:10<00:00, 7.28MB/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-11-14 14:00:32,655 copying /tmp/tmpinwcvmzo to cache at /home/moskovskii/.flair/embeddings/news-backward-0.4.1.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-11-14 14:00:32,730 removing temp file /tmp/tmpinwcvmzo\n"
          ]
        }
      ],
      "source": [
        "from flair.embeddings import WordEmbeddings, FlairEmbeddings, StackedEmbeddings\n",
        "\n",
        "stacked_embeddings = StackedEmbeddings([\n",
        "                                        WordEmbeddings('glove'),\n",
        "                                        FlairEmbeddings('news-forward'),\n",
        "                                        FlairEmbeddings('news-backward'),\n",
        "                                       ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jGLu-L_YDvPY",
        "outputId": "1db41507-87b7-4026-93b1-838b86b72235"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Token[0]: \"The\"\n",
            "tensor([-0.0382, -0.2449,  0.7281,  ..., -0.0065, -0.0053,  0.0091],\n",
            "       device='cuda:0')\n",
            "Token[1]: \"grass\"\n",
            "tensor([-0.8135,  0.9404, -0.2405,  ...,  0.0354, -0.0255, -0.0143],\n",
            "       device='cuda:0')\n",
            "Token[2]: \"is\"\n",
            "tensor([-5.4264e-01,  4.1476e-01,  1.0322e+00,  ..., -5.3687e-04,\n",
            "        -9.6725e-03, -2.7530e-02], device='cuda:0')\n",
            "Token[3]: \"green\"\n",
            "tensor([-0.6791,  0.3491, -0.2398,  ..., -0.0007, -0.1333,  0.0161],\n",
            "       device='cuda:0')\n",
            "Token[4]: \".\"\n",
            "tensor([-0.3398,  0.2094,  0.4635,  ...,  0.0005, -0.0177,  0.0032],\n",
            "       device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "sentence = Sentence('The grass is green .')\n",
        "\n",
        "# just embed a sentence using the StackedEmbedding as you would with any single embedding.\n",
        "stacked_embeddings.embed(sentence)\n",
        "\n",
        "# now check out the embedded tokens.\n",
        "for token in sentence:\n",
        "    print(token)\n",
        "    print(token.embedding)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H58EnLopiWON",
        "tags": []
      },
      "source": [
        "### Pre-trained weights for Russian"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33iVc4j6kIlg"
      },
      "source": [
        "One of the main hubs of pretrained models for Russian language is [**RusVectores**](https://rusvectores.org/ru/). The whole list of models is presented [here](https://rusvectores.org/ru/models/). We will also try some examples of usage."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lGcytS7hkmPl"
      },
      "outputs": [],
      "source": [
        "import gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eBqFRB9yl39R",
        "outputId": "5ebac0f0-806c-45c3-9095-37f60244dcee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2022-11-21 19:42:00--  http://vectors.nlpl.eu/repository/20/214.zip\n",
            "Resolving vectors.nlpl.eu (vectors.nlpl.eu)... 129.240.189.181\n",
            "Connecting to vectors.nlpl.eu (vectors.nlpl.eu)|129.240.189.181|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1920218982 (1.8G) [application/zip]\n",
            "Saving to: ‘214.zip’\n",
            "\n",
            "214.zip             100%[===================>]   1.79G   105MB/s    in 18s     \n",
            "\n",
            "2022-11-21 19:42:19 (99.8 MB/s) - ‘214.zip’ saved [1920218982/1920218982]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# model download. For this example we will use fasttex pretrained model.\n",
        "# !wget http://vectors.nlpl.eu/repository/20/214.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-Kp50oOmI9l",
        "outputId": "04ec31ff-db95-41a7-fe21-eff61d6baebf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  214.zip\n",
            "  inflating: ru_fasttext_model/meta.json  \n",
            "  inflating: ru_fasttext_model/model.model  \n",
            "  inflating: ru_fasttext_model/model.model.vectors_ngrams.npy  \n",
            "  inflating: ru_fasttext_model/model.model.vectors.npy  \n",
            "  inflating: ru_fasttext_model/model.model.vectors_vocab.npy  \n",
            "  inflating: ru_fasttext_model/README  \n"
          ]
        }
      ],
      "source": [
        "# !unzip 214.zip -d ru_fasttext_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7V61JWEvlxDj"
      },
      "outputs": [],
      "source": [
        "ru_fasttext_model = gensim.models.KeyedVectors.load('ru_fasttext_model/model.model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sIxryncMm7_V",
        "outputId": "a167db32-c9a0-4d28-e43b-8a1b693a935d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([-3.32608342e-01, -1.26286536e-01, -1.79735586e-01,  2.79385895e-01,\n",
              "       -3.69018912e-01,  3.44438046e-01, -2.34145205e-02,  5.60232043e-01,\n",
              "       -3.31771702e-01,  7.50510246e-02, -3.97710502e-02,  9.58546773e-02,\n",
              "        6.02775812e-01,  2.64807463e-01,  4.67248619e-01,  2.27449253e-01,\n",
              "       -1.75586492e-02,  3.64083916e-01,  2.85187215e-01,  1.60460010e-01,\n",
              "       -1.00663744e-01, -2.84378797e-01, -3.49444419e-01,  3.71782854e-02,\n",
              "       -2.86672674e-02, -2.15512160e-02, -1.13702953e-01, -1.83207437e-01,\n",
              "       -1.48359165e-01, -3.76394279e-02,  1.14443544e-02,  2.52620071e-01,\n",
              "       -1.51189208e-01, -2.27908477e-01,  2.39898071e-01, -3.15357924e-01,\n",
              "        2.69230425e-01, -3.75274599e-01, -1.18599355e-01, -1.66700840e-01,\n",
              "        1.93800889e-02, -2.19127648e-02,  7.95794204e-02,  2.42556125e-01,\n",
              "       -3.45300317e-01,  2.60304689e-01, -2.70207196e-01, -1.52698100e-01,\n",
              "        3.82836431e-01,  2.37352714e-01, -4.83656645e-01, -3.28339636e-02,\n",
              "        3.38784158e-02,  4.95496430e-02,  1.31492659e-01, -2.32890829e-01,\n",
              "       -1.44338354e-01, -3.64635497e-01,  2.17371449e-01, -9.76377055e-02,\n",
              "        1.64212547e-02, -2.36263394e-01, -6.10803440e-02, -3.42781305e-01,\n",
              "       -4.80702072e-01,  2.38256812e-01,  4.47838642e-02, -2.14032203e-01,\n",
              "        5.41082956e-02,  6.37289360e-02, -4.24359627e-02,  9.54636410e-02,\n",
              "       -6.59939572e-02,  3.32997411e-01,  2.90004045e-01, -4.41064000e-01,\n",
              "        2.56932210e-02,  2.20724553e-01,  2.48504043e-01,  2.56617993e-01,\n",
              "        1.68708369e-01, -5.17290942e-02,  3.70982051e-01, -3.73372436e-02,\n",
              "       -8.12342167e-02,  1.62774175e-02, -8.98792893e-02,  5.14508709e-02,\n",
              "        9.24901739e-02, -8.60874280e-02, -1.79235265e-01, -2.89011784e-02,\n",
              "        9.42934945e-04, -2.97117561e-01,  2.55878177e-03,  2.29687795e-01,\n",
              "       -9.46543217e-02, -2.71229088e-01,  6.13748329e-03, -2.35460564e-01,\n",
              "        1.64052233e-01, -1.84224397e-01,  1.67906031e-01, -4.45749760e-02,\n",
              "       -4.79039460e-01, -5.15403263e-02,  1.75401997e-02,  6.12078570e-02,\n",
              "       -1.65435582e-01, -1.80229917e-01, -7.93859661e-02,  8.80598873e-02,\n",
              "        1.00455128e-01,  1.51575401e-01,  3.60373175e-04,  1.09009713e-01,\n",
              "       -2.71746546e-01,  2.10354730e-01, -1.05921045e-01, -2.59822428e-01,\n",
              "       -1.03486940e-01,  7.33930916e-02, -3.07188153e-01,  1.79023862e-01,\n",
              "        2.05528229e-01, -1.42307699e-01,  5.06123453e-02, -1.20027922e-02,\n",
              "       -1.03778675e-01, -5.62940687e-02, -1.26098067e-01,  8.72057527e-02,\n",
              "       -1.20942228e-01,  2.09919468e-01,  9.03659314e-02,  1.95489764e-01,\n",
              "       -8.93502217e-03, -2.39573479e-01, -2.26933897e-01,  2.17766643e-01,\n",
              "       -1.48918599e-01, -6.29986301e-02, -2.83398151e-01,  4.71978009e-01,\n",
              "       -9.72954258e-02,  1.73477665e-01, -2.45810673e-01,  7.67103881e-02,\n",
              "        6.71552792e-02, -1.27932549e-01, -1.66132674e-01,  3.95483255e-01,\n",
              "       -3.44800174e-01,  1.66170791e-01, -2.76732922e-01,  3.89827549e-01,\n",
              "       -3.66086721e-01, -7.37017691e-02,  1.99339062e-01, -2.99092047e-02,\n",
              "        2.73473591e-01,  2.22396761e-01, -3.36888045e-01,  2.97983915e-01,\n",
              "        6.16354235e-02, -2.48471454e-01,  1.61731720e-01,  3.51869255e-01,\n",
              "       -1.29691154e-01,  2.66458839e-01,  6.57518357e-02, -1.04333669e-01,\n",
              "       -7.94079527e-02,  3.45651299e-01,  3.93716432e-02,  4.43825960e-01,\n",
              "        2.36830097e-02,  4.15126562e-01,  1.79770626e-02, -2.17521101e-01,\n",
              "       -1.38165921e-01, -1.00194477e-01, -2.60571092e-01,  2.16017500e-01,\n",
              "       -5.85577413e-02,  3.82968724e-01,  1.68010533e-01, -5.70053458e-01,\n",
              "       -3.04599013e-02, -3.17446053e-01,  5.84194064e-01,  8.35535452e-02,\n",
              "       -2.21752636e-02,  1.89037710e-01,  1.96264818e-01, -2.34494776e-01,\n",
              "       -3.16725582e-01, -2.28672162e-01, -1.96788624e-01,  3.46307340e-03,\n",
              "       -1.69336032e-02,  2.41721272e-01, -2.76404053e-01, -4.07178067e-02,\n",
              "        3.66314277e-02, -5.07096052e-01,  5.95286191e-02,  2.85353422e-01,\n",
              "       -1.81105971e-01, -2.55861014e-01, -4.60007757e-01,  1.48158357e-01,\n",
              "       -2.10425869e-01,  5.62949836e-01,  1.85897902e-01,  4.27709240e-03,\n",
              "       -4.92802933e-02, -3.09149381e-02,  2.76273519e-01,  2.54099220e-01,\n",
              "        2.22797081e-01, -1.04551181e-01,  3.84438634e-02, -1.79254413e-01,\n",
              "       -2.42076620e-01, -1.39413610e-01, -5.04435360e-01, -1.23134442e-01,\n",
              "       -2.85596162e-01, -4.17352408e-01, -3.88211548e-01, -1.05580539e-01,\n",
              "       -4.98731434e-02,  2.57668257e-01,  3.05452377e-01, -7.19147027e-02,\n",
              "       -2.79255629e-01, -4.44024317e-02,  6.20433176e-03,  1.44703105e-01,\n",
              "        1.92124054e-01,  1.30490482e-01,  8.34550858e-02, -1.29118323e-01,\n",
              "       -1.40179470e-01,  3.62882540e-02,  7.30847567e-02,  2.57446226e-02,\n",
              "        5.60927354e-02,  1.81478143e-01, -1.08222783e-01,  2.35812306e-01,\n",
              "        2.99400657e-01, -8.34370777e-02,  1.03976056e-02, -1.62497491e-01,\n",
              "        2.86757320e-01, -1.21200278e-01, -1.22831710e-01,  1.10294245e-01,\n",
              "       -2.13333249e-01,  8.46664459e-02, -1.19541392e-01,  4.80958760e-01,\n",
              "        4.72879633e-02, -1.24889359e-01,  8.37687850e-02, -3.82677287e-01,\n",
              "       -1.27408668e-01, -4.96568114e-01,  2.97301054e-01,  2.22949371e-01,\n",
              "        2.79746085e-01, -1.69715658e-01, -3.71487528e-01, -9.51535627e-02,\n",
              "        2.07706362e-01, -8.76652077e-02, -6.88644275e-02, -4.25455719e-01,\n",
              "        7.38848373e-02,  2.34965771e-01, -2.53818065e-01, -3.58222872e-01,\n",
              "       -8.08361173e-03, -3.42247277e-01, -3.76565248e-01, -1.99646771e-01,\n",
              "        4.77670908e-01, -7.18732402e-02, -2.81397492e-01, -1.42004654e-01,\n",
              "        1.06862292e-01,  1.42833397e-01, -1.95167467e-01,  1.22636855e-01,\n",
              "        7.64999986e-02, -3.34956706e-01,  2.58346289e-01,  2.76141576e-02],\n",
              "      dtype=float32)"
            ]
          },
          "execution_count": 91,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ru_fasttext_model.get_vector(\"естественный\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jXdQ6f8HnBE3",
        "outputId": "14004beb-bea3-49cf-c187-a256b36ceb3e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('ягуара', 0.6922987103462219),\n",
              " ('ягуаре', 0.658053457736969),\n",
              " ('джип', 0.6504993438720703),\n",
              " ('ягуары', 0.6424834728240967),\n",
              " ('крайслер', 0.6181568503379822),\n",
              " ('митсубиши', 0.6164671182632446),\n",
              " ('бмв', 0.6137527823448181),\n",
              " ('тигуан', 0.6030640602111816),\n",
              " ('ситроен', 0.6001013517379761),\n",
              " ('хаммер', 0.5977892279624939)]"
            ]
          },
          "execution_count": 92,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ru_fasttext_model.most_similar(\"ягуар\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQtSNRqSndp6",
        "outputId": "bf3c1775-99d0-4be2-b9e3-fb71ea54353f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('время-то', 0.4860388934612274),\n",
              " ('врем', 0.48514583706855774),\n",
              " ('время,а', 0.4616581201553345),\n",
              " ('десятилетие', 0.45002153515815735),\n",
              " ('еда', 0.44088080525398254),\n",
              " ('детство', 0.43911275267601013),\n",
              " ('времяпровождение', 0.43864935636520386),\n",
              " ('продолжительное', 0.4309692084789276),\n",
              " ('готовка', 0.4296607971191406),\n",
              " ('продолжительная', 0.42860114574432373)]"
            ]
          },
          "execution_count": 93,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ru_fasttext_model.most_similar(positive=[\"учеба\", \"время\"], negative=\"экзамен\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BfnHEZrkntH"
      },
      "source": [
        "Again, have fun and check [vectors calculator](https://rusvectores.org/ru/calculator/)!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_GGzhysNvEw"
      },
      "source": [
        "## Visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNKJF76LkUWa"
      },
      "source": [
        "### Single words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzPGLwA5kRWy"
      },
      "source": [
        "One way to see if our vectors are any good is to plot them. Thing is, those vectors are in 30D+ space and we humans are more used to 2-3D.\n",
        "\n",
        "Luckily, we machine learners know about __dimensionality reduction__ methods.\n",
        "\n",
        "Let's use that to plot 1000 most frequent words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mSeQVEfyl5HD",
        "outputId": "9685dc19-ad75-410b-f8d6-19904a4c327d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['the', 'so', 'according', 'man', 'troops', 'working', 'together', 'meet', '40', 'either']\n"
          ]
        }
      ],
      "source": [
        "words = sorted(en_w2v_model.key_to_index.keys(),\n",
        "               key=lambda word: en_w2v_model.get_vecattr(word, \"count\"),\n",
        "               reverse=True)[:1000]\n",
        "\n",
        "print(words[::100])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vpq5eEgvl_N2"
      },
      "outputs": [],
      "source": [
        "# for each word, compute it's vector with model\n",
        "word_vectors = np.array([en_w2v_model[word] for word in words])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLxTfQjomI2e"
      },
      "source": [
        "Linear projection: PCA\n",
        "\n",
        "The simplest linear dimensionality reduction method is __P__rincipial __C__omponent __A__nalysis.\n",
        "\n",
        "In geometric terms, PCA tries to find axes along which most of the variance occurs. The \"natural\" axes, if you wish.\n",
        "\n",
        "<img src=\"https://github.com/yandexdataschool/Practical_RL/raw/master/yet_another_week/_resource/pca_fish.png\" style=\"width:30%\">\n",
        "\n",
        "\n",
        "Under the hood, it attempts to decompose object-feature matrix $X$ into two smaller matrices: $W$ and $\\hat W$ minimizing _mean squared error_:\n",
        "\n",
        "$$\\|(X W) \\hat{W} - X\\|^2_2 \\to_{W, \\hat{W}} \\min$$\n",
        "- $X \\in \\mathbb{R}^{n \\times m}$ - object matrix (**centered**);\n",
        "- $W \\in \\mathbb{R}^{m \\times d}$ - matrix of direct transformation;\n",
        "- $\\hat{W} \\in \\mathbb{R}^{d \\times m}$ - matrix of reverse transformation;\n",
        "- $n$ samples, $m$ original dimensions and $d$ target dimensions;\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "olpgK91TmXWb"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qTzaAWW1mZaH",
        "outputId": "eb8d803d-064c-4d68-8edf-e9ba416405dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 377 ms, sys: 1.23 s, total: 1.61 s\n",
            "Wall time: 57.5 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "# map word vectors onto 2d plane with PCA. Use good old sklearn api (fit, transform)\n",
        "# after that, normalize vectors to make sure they have zero mean and unit variance\n",
        "word_vectors_pca = PCA(n_components=2).fit_transform(word_vectors)\n",
        "word_vectors_pca = StandardScaler().fit_transform(word_vectors_pca)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-GFl0w2DmbbN"
      },
      "source": [
        "Let's draw it!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C9qBWYHTmdjH",
        "tags": [],
        "outputId": "b5dbb3fb-f622-47d6-9d85-0bb045027842"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "    <style>\n",
              "        .bk-notebook-logo {\n",
              "            display: block;\n",
              "            width: 20px;\n",
              "            height: 20px;\n",
              "            background-image: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAABx0RVh0U29mdHdhcmUAQWRvYmUgRmlyZXdvcmtzIENTNui8sowAAAOkSURBVDiNjZRtaJVlGMd/1/08zzln5zjP1LWcU9N0NkN8m2CYjpgQYQXqSs0I84OLIC0hkEKoPtiH3gmKoiJDU7QpLgoLjLIQCpEsNJ1vqUOdO7ppbuec5+V+rj4ctwzd8IIbbi6u+8f1539dt3A78eXC7QizUF7gyV1fD1Yqg4JWz84yffhm0qkFqBogB9rM8tZdtwVsPUhWhGcFJngGeWrPzHm5oaMmkfEg1usvLFyc8jLRqDOMru7AyC8saQr7GG7f5fvDeH7Ej8CM66nIF+8yngt6HWaKh7k49Soy9nXurCi1o3qUbS3zWfrYeQDTB/Qj6kX6Ybhw4B+bOYoLKCC9H3Nu/leUTZ1JdRWkkn2ldcCamzrcf47KKXdAJllSlxAOkRgyHsGC/zRday5Qld9DyoM4/q/rUoy/CXh3jzOu3bHUVZeU+DEn8FInkPBFlu3+nW3Nw0mk6vCDiWg8CeJaxEwuHS3+z5RgY+YBR6V1Z1nxSOfoaPa4LASWxxdNp+VWTk7+4vzaou8v8PN+xo+KY2xsw6une2frhw05CTYOmQvsEhjhWjn0bmXPjpE1+kplmmkP3suftwTubK9Vq22qKmrBhpY4jvd5afdRA3wGjFAgcnTK2s4hY0/GPNIb0nErGMCRxWOOX64Z8RAC4oCXdklmEvcL8o0BfkNK4lUg9HTl+oPlQxdNo3Mg4Nv175e/1LDGzZen30MEjRUtmXSfiTVu1kK8W4txyV6BMKlbgk3lMwYCiusNy9fVfvvwMxv8Ynl6vxoByANLTWplvuj/nF9m2+PDtt1eiHPBr1oIfhCChQMBw6Aw0UulqTKZdfVvfG7VcfIqLG9bcldL/+pdWTLxLUy8Qq38heUIjh4XlzZxzQm19lLFlr8vdQ97rjZVOLf8nclzckbcD4wxXMidpX30sFd37Fv/GtwwhzhxGVAprjbg0gCAEeIgwCZyTV2Z1REEW8O4py0wsjeloKoMr6iCY6dP92H6Vw/oTyICIthibxjm/DfN9lVz8IqtqKYLUXfoKVMVQVVJOElGjrnnUt9T9wbgp8AyYKaGlqingHZU/uG2NTZSVqwHQTWkx9hxjkpWDaCg6Ckj5qebgBVbT3V3NNXMSiWSDdGV3hrtzla7J+duwPOToIg42ChPQOQjspnSlp1V+Gjdged7+8UN5CRAV7a5EdFNwCjEaBR27b3W890TE7g24NAP/mMDXRWrGoFPQI9ls/MWO2dWFAar/xcOIImbbpA3zgAAAABJRU5ErkJggg==);\n",
              "        }\n",
              "    </style>\n",
              "    <div>\n",
              "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-notebook-logo\"></a>\n",
              "        <span id=\"c0e30884-0d5e-4f28-94b8-3065cb551ee4\">Loading BokehJS ...</span>\n",
              "    </div>\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "(function(root) {\n",
              "  function now() {\n",
              "    return new Date();\n",
              "  }\n",
              "\n",
              "  const force = true;\n",
              "\n",
              "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
              "    root._bokeh_onload_callbacks = [];\n",
              "    root._bokeh_is_loading = undefined;\n",
              "  }\n",
              "\n",
              "const JS_MIME_TYPE = 'application/javascript';\n",
              "  const HTML_MIME_TYPE = 'text/html';\n",
              "  const EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
              "  const CLASS_NAME = 'output_bokeh rendered_html';\n",
              "\n",
              "  /**\n",
              "   * Render data to the DOM node\n",
              "   */\n",
              "  function render(props, node) {\n",
              "    const script = document.createElement(\"script\");\n",
              "    node.appendChild(script);\n",
              "  }\n",
              "\n",
              "  /**\n",
              "   * Handle when an output is cleared or removed\n",
              "   */\n",
              "  function handleClearOutput(event, handle) {\n",
              "    function drop(id) {\n",
              "      const view = Bokeh.index.get_by_id(id)\n",
              "      if (view != null) {\n",
              "        view.model.document.clear()\n",
              "        Bokeh.index.delete(view)\n",
              "      }\n",
              "    }\n",
              "\n",
              "    const cell = handle.cell;\n",
              "\n",
              "    const id = cell.output_area._bokeh_element_id;\n",
              "    const server_id = cell.output_area._bokeh_server_id;\n",
              "\n",
              "    // Clean up Bokeh references\n",
              "    if (id != null) {\n",
              "      drop(id)\n",
              "    }\n",
              "\n",
              "    if (server_id !== undefined) {\n",
              "      // Clean up Bokeh references\n",
              "      const cmd_clean = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
              "      cell.notebook.kernel.execute(cmd_clean, {\n",
              "        iopub: {\n",
              "          output: function(msg) {\n",
              "            const id = msg.content.text.trim()\n",
              "            drop(id)\n",
              "          }\n",
              "        }\n",
              "      });\n",
              "      // Destroy server and session\n",
              "      const cmd_destroy = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
              "      cell.notebook.kernel.execute(cmd_destroy);\n",
              "    }\n",
              "  }\n",
              "\n",
              "  /**\n",
              "   * Handle when a new output is added\n",
              "   */\n",
              "  function handleAddOutput(event, handle) {\n",
              "    const output_area = handle.output_area;\n",
              "    const output = handle.output;\n",
              "\n",
              "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
              "    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n",
              "      return\n",
              "    }\n",
              "\n",
              "    const toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
              "\n",
              "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
              "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
              "      // store reference to embed id on output_area\n",
              "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
              "    }\n",
              "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
              "      const bk_div = document.createElement(\"div\");\n",
              "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
              "      const script_attrs = bk_div.children[0].attributes;\n",
              "      for (let i = 0; i < script_attrs.length; i++) {\n",
              "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
              "        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n",
              "      }\n",
              "      // store reference to server id on output_area\n",
              "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
              "    }\n",
              "  }\n",
              "\n",
              "  function register_renderer(events, OutputArea) {\n",
              "\n",
              "    function append_mime(data, metadata, element) {\n",
              "      // create a DOM node to render to\n",
              "      const toinsert = this.create_output_subarea(\n",
              "        metadata,\n",
              "        CLASS_NAME,\n",
              "        EXEC_MIME_TYPE\n",
              "      );\n",
              "      this.keyboard_manager.register_events(toinsert);\n",
              "      // Render to node\n",
              "      const props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
              "      render(props, toinsert[toinsert.length - 1]);\n",
              "      element.append(toinsert);\n",
              "      return toinsert\n",
              "    }\n",
              "\n",
              "    /* Handle when an output is cleared or removed */\n",
              "    events.on('clear_output.CodeCell', handleClearOutput);\n",
              "    events.on('delete.Cell', handleClearOutput);\n",
              "\n",
              "    /* Handle when a new output is added */\n",
              "    events.on('output_added.OutputArea', handleAddOutput);\n",
              "\n",
              "    /**\n",
              "     * Register the mime type and append_mime function with output_area\n",
              "     */\n",
              "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
              "      /* Is output safe? */\n",
              "      safe: true,\n",
              "      /* Index of renderer in `output_area.display_order` */\n",
              "      index: 0\n",
              "    });\n",
              "  }\n",
              "\n",
              "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
              "  if (root.Jupyter !== undefined) {\n",
              "    const events = require('base/js/events');\n",
              "    const OutputArea = require('notebook/js/outputarea').OutputArea;\n",
              "\n",
              "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
              "      register_renderer(events, OutputArea);\n",
              "    }\n",
              "  }\n",
              "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
              "    root._bokeh_timeout = Date.now() + 5000;\n",
              "    root._bokeh_failed_load = false;\n",
              "  }\n",
              "\n",
              "  const NB_LOAD_WARNING = {'data': {'text/html':\n",
              "     \"<div style='background-color: #fdd'>\\n\"+\n",
              "     \"<p>\\n\"+\n",
              "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
              "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
              "     \"</p>\\n\"+\n",
              "     \"<ul>\\n\"+\n",
              "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
              "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
              "     \"</ul>\\n\"+\n",
              "     \"<code>\\n\"+\n",
              "     \"from bokeh.resources import INLINE\\n\"+\n",
              "     \"output_notebook(resources=INLINE)\\n\"+\n",
              "     \"</code>\\n\"+\n",
              "     \"</div>\"}};\n",
              "\n",
              "  function display_loaded() {\n",
              "    const el = document.getElementById(\"c0e30884-0d5e-4f28-94b8-3065cb551ee4\");\n",
              "    if (el != null) {\n",
              "      el.textContent = \"BokehJS is loading...\";\n",
              "    }\n",
              "    if (root.Bokeh !== undefined) {\n",
              "      if (el != null) {\n",
              "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
              "      }\n",
              "    } else if (Date.now() < root._bokeh_timeout) {\n",
              "      setTimeout(display_loaded, 100)\n",
              "    }\n",
              "  }\n",
              "\n",
              "  function run_callbacks() {\n",
              "    try {\n",
              "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
              "        if (callback != null)\n",
              "          callback();\n",
              "      });\n",
              "    } finally {\n",
              "      delete root._bokeh_onload_callbacks\n",
              "    }\n",
              "    console.debug(\"Bokeh: all callbacks have finished\");\n",
              "  }\n",
              "\n",
              "  function load_libs(css_urls, js_urls, callback) {\n",
              "    if (css_urls == null) css_urls = [];\n",
              "    if (js_urls == null) js_urls = [];\n",
              "\n",
              "    root._bokeh_onload_callbacks.push(callback);\n",
              "    if (root._bokeh_is_loading > 0) {\n",
              "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
              "      return null;\n",
              "    }\n",
              "    if (js_urls == null || js_urls.length === 0) {\n",
              "      run_callbacks();\n",
              "      return null;\n",
              "    }\n",
              "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
              "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
              "\n",
              "    function on_load() {\n",
              "      root._bokeh_is_loading--;\n",
              "      if (root._bokeh_is_loading === 0) {\n",
              "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
              "        run_callbacks()\n",
              "      }\n",
              "    }\n",
              "\n",
              "    function on_error(url) {\n",
              "      console.error(\"failed to load \" + url);\n",
              "    }\n",
              "\n",
              "    for (let i = 0; i < css_urls.length; i++) {\n",
              "      const url = css_urls[i];\n",
              "      const element = document.createElement(\"link\");\n",
              "      element.onload = on_load;\n",
              "      element.onerror = on_error.bind(null, url);\n",
              "      element.rel = \"stylesheet\";\n",
              "      element.type = \"text/css\";\n",
              "      element.href = url;\n",
              "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
              "      document.body.appendChild(element);\n",
              "    }\n",
              "\n",
              "    for (let i = 0; i < js_urls.length; i++) {\n",
              "      const url = js_urls[i];\n",
              "      const element = document.createElement('script');\n",
              "      element.onload = on_load;\n",
              "      element.onerror = on_error.bind(null, url);\n",
              "      element.async = false;\n",
              "      element.src = url;\n",
              "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
              "      document.head.appendChild(element);\n",
              "    }\n",
              "  };\n",
              "\n",
              "  function inject_raw_css(css) {\n",
              "    const element = document.createElement(\"style\");\n",
              "    element.appendChild(document.createTextNode(css));\n",
              "    document.body.appendChild(element);\n",
              "  }\n",
              "\n",
              "  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.3.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.3.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.3.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.3.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-3.3.1.min.js\"];\n",
              "  const css_urls = [];\n",
              "\n",
              "  const inline_js = [    function(Bokeh) {\n",
              "      Bokeh.set_log_level(\"info\");\n",
              "    },\n",
              "function(Bokeh) {\n",
              "    }\n",
              "  ];\n",
              "\n",
              "  function run_inline_js() {\n",
              "    if (root.Bokeh !== undefined || force === true) {\n",
              "          for (let i = 0; i < inline_js.length; i++) {\n",
              "      inline_js[i].call(root, root.Bokeh);\n",
              "    }\n",
              "if (force === true) {\n",
              "        display_loaded();\n",
              "      }} else if (Date.now() < root._bokeh_timeout) {\n",
              "      setTimeout(run_inline_js, 100);\n",
              "    } else if (!root._bokeh_failed_load) {\n",
              "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
              "      root._bokeh_failed_load = true;\n",
              "    } else if (force !== true) {\n",
              "      const cell = $(document.getElementById(\"c0e30884-0d5e-4f28-94b8-3065cb551ee4\")).parents('.cell').data().cell;\n",
              "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
              "    }\n",
              "  }\n",
              "\n",
              "  if (root._bokeh_is_loading === 0) {\n",
              "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
              "    run_inline_js();\n",
              "  } else {\n",
              "    load_libs(css_urls, js_urls, function() {\n",
              "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
              "      run_inline_js();\n",
              "    });\n",
              "  }\n",
              "}(window));"
            ],
            "application/vnd.bokehjs_load.v0+json": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  const NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    const el = document.getElementById(\"c0e30884-0d5e-4f28-94b8-3065cb551ee4\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.3.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.3.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.3.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.3.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-3.3.1.min.js\"];\n  const css_urls = [];\n\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {\n    }\n  ];\n\n  function run_inline_js() {\n    if (root.Bokeh !== undefined || force === true) {\n          for (let i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\nif (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      const cell = $(document.getElementById(\"c0e30884-0d5e-4f28-94b8-3065cb551ee4\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import bokeh.models as bm, bokeh.plotting as pl\n",
        "from bokeh.io import output_notebook\n",
        "output_notebook()\n",
        "\n",
        "def draw_vectors(x, y, radius=10, alpha=0.25, color='blue',\n",
        "                 width=600, height=400, show=True, **kwargs):\n",
        "    \"\"\" draws an interactive plot for data points with auxilirary info on hover \"\"\"\n",
        "    if isinstance(color, str): color = [color] * len(x)\n",
        "    data_source = bm.ColumnDataSource({ 'x' : x, 'y' : y, 'color': color, **kwargs })\n",
        "\n",
        "    fig = pl.figure(active_scroll='wheel_zoom', width=width, height=height)\n",
        "    fig.scatter('x', 'y', size=radius, color='color', alpha=alpha, source=data_source)\n",
        "\n",
        "    fig.add_tools(bm.HoverTool(tooltips=[(key, \"@\" + key) for key in kwargs.keys()]))\n",
        "    if show: pl.show(fig)\n",
        "    return fig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "id": "1UnnnIK3mhQU",
        "outputId": "b903a8b2-3c54-4059-b566-ab61901dab5b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"d425cbc4-84d0-427c-a6b3-4d6fa21d6789\" data-root-id=\"p1004\" style=\"display: contents;\"></div>\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "(function(root) {\n",
              "  function embed_document(root) {\n",
              "  const docs_json = {\"1845d609-fdfe-40d1-bebf-f419207aeada\":{\"version\":\"3.3.1\",\"title\":\"Bokeh Application\",\"roots\":[{\"type\":\"object\",\"name\":\"Figure\",\"id\":\"p1004\",\"attributes\":{\"height\":400,\"x_range\":{\"type\":\"object\",\"name\":\"DataRange1d\",\"id\":\"p1005\"},\"y_range\":{\"type\":\"object\",\"name\":\"DataRange1d\",\"id\":\"p1006\"},\"x_scale\":{\"type\":\"object\",\"name\":\"LinearScale\",\"id\":\"p1013\"},\"y_scale\":{\"type\":\"object\",\"name\":\"LinearScale\",\"id\":\"p1014\"},\"title\":{\"type\":\"object\",\"name\":\"Title\",\"id\":\"p1011\"},\"renderers\":[{\"type\":\"object\",\"name\":\"GlyphRenderer\",\"id\":\"p1038\",\"attributes\":{\"data_source\":{\"type\":\"object\",\"name\":\"ColumnDataSource\",\"id\":\"p1001\",\"attributes\":{\"selected\":{\"type\":\"object\",\"name\":\"Selection\",\"id\":\"p1002\",\"attributes\":{\"indices\":[],\"line_indices\":[]}},\"selection_policy\":{\"type\":\"object\",\"name\":\"UnionRenderers\",\"id\":\"p1003\"},\"data\":{\"type\":\"map\",\"entries\":[[\"x\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"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\"},\"shape\":[1000],\"dtype\":\"float32\",\"order\":\"little\"}],[\"y\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"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\"},\"shape\":[1000],\"dtype\":\"float32\",\"order\":\"little\"}],[\"color\",[\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\"]],[\"token\",[\"the\",\",\",\".\",\"of\",\"to\",\"and\",\"in\",\"a\",\"\\\"\",\"'s\",\"for\",\"-\",\"that\",\"on\",\"is\",\"was\",\"said\",\"with\",\"he\",\"as\",\"it\",\"by\",\"at\",\"(\",\")\",\"from\",\"his\",\"''\",\"``\",\"an\",\"be\",\"has\",\"are\",\"have\",\"but\",\"were\",\"not\",\"this\",\"who\",\"they\",\"had\",\"i\",\"which\",\"will\",\"their\",\":\",\"or\",\"its\",\"one\",\"after\",\"new\",\"been\",\"also\",\"we\",\"would\",\"two\",\"more\",\"'\",\"first\",\"about\",\"up\",\"when\",\"year\",\"there\",\"all\",\"--\",\"out\",\"she\",\"other\",\"people\",\"n't\",\"her\",\"percent\",\"than\",\"over\",\"into\",\"last\",\"some\",\"government\",\"time\",\"$\",\"you\",\"years\",\"if\",\"no\",\"world\",\"can\",\"three\",\"do\",\";\",\"president\",\"only\",\"state\",\"million\",\"could\",\"us\",\"most\",\"_\",\"against\",\"u.s.\",\"so\",\"them\",\"what\",\"him\",\"united\",\"during\",\"before\",\"may\",\"since\",\"many\",\"while\",\"where\",\"states\",\"because\",\"now\",\"city\",\"made\",\"like\",\"between\",\"did\",\"just\",\"national\",\"day\",\"country\",\"under\",\"such\",\"second\",\"then\",\"company\",\"group\",\"any\",\"through\",\"china\",\"four\",\"being\",\"down\",\"war\",\"back\",\"off\",\"south\",\"american\",\"minister\",\"police\",\"well\",\"including\",\"team\",\"international\",\"week\",\"officials\",\"still\",\"both\",\"even\",\"high\",\"part\",\"told\",\"those\",\"end\",\"former\",\"these\",\"make\",\"billion\",\"work\",\"our\",\"home\",\"school\",\"party\",\"house\",\"old\",\"later\",\"get\",\"another\",\"tuesday\",\"news\",\"long\",\"five\",\"called\",\"1\",\"wednesday\",\"military\",\"way\",\"used\",\"much\",\"next\",\"monday\",\"thursday\",\"friday\",\"game\",\"here\",\"?\",\"should\",\"take\",\"very\",\"my\",\"north\",\"security\",\"season\",\"york\",\"how\",\"public\",\"early\",\"according\",\"several\",\"court\",\"say\",\"around\",\"foreign\",\"10\",\"until\",\"set\",\"political\",\"says\",\"market\",\"however\",\"family\",\"life\",\"same\",\"general\",\"\\u2013\",\"left\",\"good\",\"top\",\"university\",\"going\",\"number\",\"major\",\"known\",\"points\",\"won\",\"six\",\"month\",\"dollars\",\"bank\",\"2\",\"iraq\",\"use\",\"members\",\"each\",\"area\",\"found\",\"official\",\"sunday\",\"place\",\"go\",\"based\",\"among\",\"third\",\"times\",\"took\",\"right\",\"days\",\"local\",\"economic\",\"countries\",\"see\",\"best\",\"report\",\"killed\",\"held\",\"business\",\"west\",\"does\",\"own\",\"%\",\"came\",\"law\",\"months\",\"women\",\"'re\",\"power\",\"think\",\"service\",\"children\",\"bush\",\"show\",\"/\",\"help\",\"chief\",\"saturday\",\"system\",\"john\",\"support\",\"series\",\"play\",\"office\",\"following\",\"me\",\"meeting\",\"expected\",\"late\",\"washington\",\"games\",\"european\",\"league\",\"reported\",\"final\",\"added\",\"without\",\"british\",\"white\",\"history\",\"man\",\"men\",\"became\",\"want\",\"march\",\"case\",\"few\",\"run\",\"money\",\"began\",\"open\",\"name\",\"trade\",\"center\",\"3\",\"israel\",\"oil\",\"too\",\"al\",\"film\",\"win\",\"led\",\"east\",\"central\",\"20\",\"air\",\"come\",\"chinese\",\"town\",\"leader\",\"army\",\"line\",\"never\",\"little\",\"played\",\"prime\",\"death\",\"companies\",\"least\",\"put\",\"forces\",\"past\",\"de\",\"half\",\"june\",\"saying\",\"know\",\"federal\",\"french\",\"peace\",\"earlier\",\"capital\",\"force\",\"great\",\"union\",\"near\",\"released\",\"small\",\"department\",\"every\",\"health\",\"japan\",\"head\",\"ago\",\"night\",\"big\",\"cup\",\"election\",\"region\",\"director\",\"talks\",\"program\",\"far\",\"today\",\"statement\",\"july\",\"although\",\"district\",\"again\",\"born\",\"development\",\"leaders\",\"council\",\"close\",\"record\",\"along\",\"county\",\"france\",\"went\",\"point\",\"must\",\"spokesman\",\"your\",\"member\",\"plan\",\"financial\",\"april\",\"recent\",\"campaign\",\"become\",\"troops\",\"whether\",\"lost\",\"music\",\"15\",\"got\",\"israeli\",\"30\",\"need\",\"4\",\"lead\",\"already\",\"russia\",\"though\",\"might\",\"free\",\"hit\",\"rights\",\"11\",\"information\",\"away\",\"12\",\"5\",\"others\",\"control\",\"within\",\"large\",\"economy\",\"press\",\"agency\",\"water\",\"died\",\"career\",\"making\",\"...\",\"deal\",\"attack\",\"side\",\"seven\",\"better\",\"less\",\"september\",\"once\",\"clinton\",\"main\",\"due\",\"committee\",\"building\",\"conference\",\"club\",\"january\",\"decision\",\"stock\",\"america\",\"given\",\"give\",\"often\",\"announced\",\"television\",\"industry\",\"order\",\"young\",\"'ve\",\"palestinian\",\"age\",\"start\",\"administration\",\"russian\",\"prices\",\"round\",\"december\",\"nations\",\"'m\",\"human\",\"india\",\"defense\",\"asked\",\"total\",\"october\",\"players\",\"bill\",\"important\",\"southern\",\"move\",\"fire\",\"population\",\"rose\",\"november\",\"include\",\"further\",\"nuclear\",\"street\",\"taken\",\"media\",\"different\",\"issue\",\"received\",\"secretary\",\"return\",\"college\",\"working\",\"community\",\"eight\",\"groups\",\"despite\",\"level\",\"largest\",\"whose\",\"attacks\",\"germany\",\"august\",\"change\",\"church\",\"nation\",\"german\",\"station\",\"london\",\"weeks\",\"having\",\"18\",\"research\",\"black\",\"services\",\"story\",\"6\",\"europe\",\"sales\",\"policy\",\"visit\",\"northern\",\"lot\",\"across\",\"per\",\"current\",\"board\",\"football\",\"ministry\",\"workers\",\"vote\",\"book\",\"fell\",\"seen\",\"role\",\"students\",\"shares\",\"iran\",\"process\",\"agreement\",\"quarter\",\"full\",\"match\",\"started\",\"growth\",\"yet\",\"moved\",\"possible\",\"western\",\"special\",\"100\",\"plans\",\"interest\",\"behind\",\"strong\",\"england\",\"named\",\"food\",\"period\",\"real\",\"authorities\",\"car\",\"term\",\"rate\",\"race\",\"nearly\",\"korea\",\"enough\",\"site\",\"opposition\",\"keep\",\"25\",\"call\",\"future\",\"taking\",\"island\",\"2008\",\"2006\",\"road\",\"outside\",\"really\",\"century\",\"democratic\",\"almost\",\"single\",\"share\",\"leading\",\"trying\",\"find\",\"album\",\"senior\",\"minutes\",\"together\",\"congress\",\"index\",\"australia\",\"results\",\"hard\",\"hours\",\"land\",\"action\",\"higher\",\"field\",\"cut\",\"coach\",\"elections\",\"san\",\"issues\",\"executive\",\"february\",\"production\",\"areas\",\"river\",\"face\",\"using\",\"japanese\",\"province\",\"park\",\"price\",\"commission\",\"california\",\"father\",\"son\",\"education\",\"7\",\"village\",\"energy\",\"shot\",\"short\",\"africa\",\"key\",\"red\",\"association\",\"average\",\"pay\",\"exchange\",\"eu\",\"something\",\"gave\",\"likely\",\"player\",\"george\",\"2007\",\"victory\",\"8\",\"low\",\"things\",\"2010\",\"pakistan\",\"14\",\"post\",\"social\",\"continue\",\"ever\",\"look\",\"chairman\",\"job\",\"2000\",\"soldiers\",\"able\",\"parliament\",\"front\",\"himself\",\"problems\",\"private\",\"lower\",\"list\",\"built\",\"13\",\"efforts\",\"dollar\",\"miles\",\"included\",\"radio\",\"live\",\"form\",\"david\",\"african\",\"increase\",\"reports\",\"sent\",\"fourth\",\"always\",\"king\",\"50\",\"tax\",\"taiwan\",\"britain\",\"16\",\"playing\",\"title\",\"middle\",\"meet\",\"global\",\"wife\",\"2009\",\"position\",\"located\",\"clear\",\"ahead\",\"2004\",\"2005\",\"iraqi\",\"english\",\"result\",\"release\",\"violence\",\"goal\",\"project\",\"closed\",\"border\",\"body\",\"soon\",\"crisis\",\"division\",\"&amp;\",\"served\",\"tour\",\"hospital\",\"kong\",\"test\",\"hong\",\"u.n.\",\"inc.\",\"technology\",\"believe\",\"organization\",\"published\",\"weapons\",\"agreed\",\"why\",\"nine\",\"summer\",\"wanted\",\"republican\",\"act\",\"recently\",\"texas\",\"course\",\"problem\",\"senate\",\"medical\",\"un\",\"done\",\"reached\",\"star\",\"continued\",\"investors\",\"living\",\"care\",\"signed\",\"17\",\"art\",\"provide\",\"worked\",\"presidential\",\"gold\",\"obama\",\"morning\",\"dead\",\"opened\",\"'ll\",\"event\",\"previous\",\"cost\",\"instead\",\"canada\",\"band\",\"teams\",\"daily\",\"2001\",\"available\",\"drug\",\"coming\",\"2003\",\"investment\",\"\\u2019s\",\"michael\",\"civil\",\"woman\",\"training\",\"appeared\",\"9\",\"involved\",\"indian\",\"similar\",\"situation\",\"24\",\"los\",\"running\",\"fighting\",\"mark\",\"40\",\"trial\",\"hold\",\"australian\",\"thought\",\"!\",\"study\",\"fall\",\"mother\",\"met\",\"relations\",\"anti\",\"2002\",\"song\",\"popular\",\"base\",\"tv\",\"ground\",\"markets\",\"ii\",\"newspaper\",\"staff\",\"saw\",\"hand\",\"hope\",\"operations\",\"pressure\",\"americans\",\"eastern\",\"st.\",\"legal\",\"asia\",\"budget\",\"returned\",\"considered\",\"love\",\"wrote\",\"stop\",\"fight\",\"currently\",\"charges\",\"try\",\"aid\",\"ended\",\"management\",\"brought\",\"cases\",\"decided\",\"failed\",\"network\",\"works\",\"gas\",\"turned\",\"fact\",\"vice\",\"ca\",\"mexico\",\"trading\",\"especially\",\"reporters\",\"afghanistan\",\"common\",\"looking\",\"space\",\"rates\",\"manager\",\"loss\",\"2011\",\"justice\",\"thousands\",\"james\",\"rather\",\"fund\",\"thing\",\"republic\",\"opening\",\"accused\",\"winning\",\"scored\",\"championship\",\"example\",\"getting\",\"biggest\",\"performance\",\"sports\",\"1998\",\"let\",\"allowed\",\"schools\",\"means\",\"turn\",\"leave\",\"no.\",\"robert\",\"personal\",\"stocks\",\"showed\",\"light\",\"arrested\",\"person\",\"either\",\"offer\",\"majority\",\"battle\",\"19\",\"class\",\"evidence\",\"makes\",\"society\",\"products\",\"regional\",\"needed\",\"stage\",\"am\",\"doing\",\"families\",\"construction\",\"various\",\"1996\",\"sold\",\"independent\",\"kind\",\"airport\",\"paul\",\"judge\",\"internet\",\"movement\",\"room\",\"followed\",\"original\",\"angeles\",\"italy\",\"`\",\"data\",\"comes\",\"parties\",\"nothing\",\"sea\",\"bring\",\"2012\",\"annual\",\"officer\",\"beijing\",\"present\",\"remain\",\"nato\",\"1999\",\"22\",\"remains\",\"allow\",\"florida\",\"computer\",\"21\",\"contract\",\"coast\",\"created\",\"demand\",\"operation\",\"events\",\"islamic\",\"beat\",\"analysts\",\"interview\",\"helped\",\"child\",\"probably\",\"spent\",\"asian\",\"effort\",\"cooperation\",\"shows\",\"calls\",\"investigation\",\"lives\",\"video\",\"yen\",\"runs\",\"tried\",\"bad\",\"described\",\"1994\",\"toward\",\"written\",\"throughout\",\"established\",\"mission\",\"associated\",\"buy\",\"growing\",\"green\",\"forward\",\"competition\",\"poor\",\"latest\",\"banks\",\"question\",\"1997\",\"prison\",\"feel\",\"attention\"]]]}}},\"view\":{\"type\":\"object\",\"name\":\"CDSView\",\"id\":\"p1039\",\"attributes\":{\"filter\":{\"type\":\"object\",\"name\":\"AllIndices\",\"id\":\"p1040\"}}},\"glyph\":{\"type\":\"object\",\"name\":\"Scatter\",\"id\":\"p1035\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"y\":{\"type\":\"field\",\"field\":\"y\"},\"size\":{\"type\":\"value\",\"value\":10},\"line_color\":{\"type\":\"field\",\"field\":\"color\"},\"line_alpha\":{\"type\":\"value\",\"value\":0.25},\"fill_color\":{\"type\":\"field\",\"field\":\"color\"},\"fill_alpha\":{\"type\":\"value\",\"value\":0.25},\"hatch_color\":{\"type\":\"field\",\"field\":\"color\"},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.25}}},\"nonselection_glyph\":{\"type\":\"object\",\"name\":\"Scatter\",\"id\":\"p1036\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"y\":{\"type\":\"field\",\"field\":\"y\"},\"size\":{\"type\":\"value\",\"value\":10},\"line_color\":{\"type\":\"field\",\"field\":\"color\"},\"line_alpha\":{\"type\":\"value\",\"value\":0.1},\"fill_color\":{\"type\":\"field\",\"field\":\"color\"},\"fill_alpha\":{\"type\":\"value\",\"value\":0.1},\"hatch_color\":{\"type\":\"field\",\"field\":\"color\"},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.1}}},\"muted_glyph\":{\"type\":\"object\",\"name\":\"Scatter\",\"id\":\"p1037\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"y\":{\"type\":\"field\",\"field\":\"y\"},\"size\":{\"type\":\"value\",\"value\":10},\"line_color\":{\"type\":\"field\",\"field\":\"color\"},\"line_alpha\":{\"type\":\"value\",\"value\":0.2},\"fill_color\":{\"type\":\"field\",\"field\":\"color\"},\"fill_alpha\":{\"type\":\"value\",\"value\":0.2},\"hatch_color\":{\"type\":\"field\",\"field\":\"color\"},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.2}}}}}],\"toolbar\":{\"type\":\"object\",\"name\":\"Toolbar\",\"id\":\"p1012\",\"attributes\":{\"tools\":[{\"type\":\"object\",\"name\":\"PanTool\",\"id\":\"p1025\"},{\"type\":\"object\",\"name\":\"WheelZoomTool\",\"id\":\"p1026\",\"attributes\":{\"renderers\":\"auto\"}},{\"type\":\"object\",\"name\":\"BoxZoomTool\",\"id\":\"p1027\",\"attributes\":{\"overlay\":{\"type\":\"object\",\"name\":\"BoxAnnotation\",\"id\":\"p1028\",\"attributes\":{\"syncable\":false,\"level\":\"overlay\",\"visible\":false,\"left_units\":\"canvas\",\"right_units\":\"canvas\",\"top_units\":\"canvas\",\"bottom_units\":\"canvas\",\"line_color\":\"black\",\"line_alpha\":1.0,\"line_width\":2,\"line_dash\":[4,4],\"fill_color\":\"lightgrey\",\"fill_alpha\":0.5}}}},{\"type\":\"object\",\"name\":\"SaveTool\",\"id\":\"p1029\"},{\"type\":\"object\",\"name\":\"ResetTool\",\"id\":\"p1030\"},{\"type\":\"object\",\"name\":\"HelpTool\",\"id\":\"p1031\"},{\"type\":\"object\",\"name\":\"HoverTool\",\"id\":\"p1041\",\"attributes\":{\"renderers\":\"auto\",\"tooltips\":[[\"token\",\"@token\"]]}}],\"active_scroll\":{\"id\":\"p1026\"}}},\"left\":[{\"type\":\"object\",\"name\":\"LinearAxis\",\"id\":\"p1020\",\"attributes\":{\"ticker\":{\"type\":\"object\",\"name\":\"BasicTicker\",\"id\":\"p1021\",\"attributes\":{\"mantissas\":[1,2,5]}},\"formatter\":{\"type\":\"object\",\"name\":\"BasicTickFormatter\",\"id\":\"p1022\"},\"major_label_policy\":{\"type\":\"object\",\"name\":\"AllLabels\",\"id\":\"p1023\"}}}],\"below\":[{\"type\":\"object\",\"name\":\"LinearAxis\",\"id\":\"p1015\",\"attributes\":{\"ticker\":{\"type\":\"object\",\"name\":\"BasicTicker\",\"id\":\"p1016\",\"attributes\":{\"mantissas\":[1,2,5]}},\"formatter\":{\"type\":\"object\",\"name\":\"BasicTickFormatter\",\"id\":\"p1017\"},\"major_label_policy\":{\"type\":\"object\",\"name\":\"AllLabels\",\"id\":\"p1018\"}}}],\"center\":[{\"type\":\"object\",\"name\":\"Grid\",\"id\":\"p1019\",\"attributes\":{\"axis\":{\"id\":\"p1015\"}}},{\"type\":\"object\",\"name\":\"Grid\",\"id\":\"p1024\",\"attributes\":{\"dimension\":1,\"axis\":{\"id\":\"p1020\"}}}]}}]}};\n",
              "  const render_items = [{\"docid\":\"1845d609-fdfe-40d1-bebf-f419207aeada\",\"roots\":{\"p1004\":\"d425cbc4-84d0-427c-a6b3-4d6fa21d6789\"},\"root_ids\":[\"p1004\"]}];\n",
              "  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
              "  }\n",
              "  if (root.Bokeh !== undefined) {\n",
              "    embed_document(root);\n",
              "  } else {\n",
              "    let attempts = 0;\n",
              "    const timer = setInterval(function(root) {\n",
              "      if (root.Bokeh !== undefined) {\n",
              "        clearInterval(timer);\n",
              "        embed_document(root);\n",
              "      } else {\n",
              "        attempts++;\n",
              "        if (attempts > 100) {\n",
              "          clearInterval(timer);\n",
              "          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
              "        }\n",
              "      }\n",
              "    }, 10, root)\n",
              "  }\n",
              "})(window);"
            ],
            "application/vnd.bokehjs_exec.v0+json": ""
          },
          "metadata": {
            "application/vnd.bokehjs_exec.v0+json": {
              "id": "p1004"
            }
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "draw_vectors(word_vectors_pca[:, 0], word_vectors_pca[:, 1], token=words)\n",
        "plt.show()\n",
        "# hover a mouse over there and see if you can identify the clusters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NmrjBQO9N7CB"
      },
      "source": [
        "### Phrases"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rywzLhoAnKJ-"
      },
      "source": [
        "Word embeddings can also be used to represent short phrases. The simplest way is to take __an average__ of vectors for all tokens in the phrase with some weights.\n",
        "\n",
        "This trick is useful to identify what data are you working with: find if there are any outliers, clusters or other artefacts.\n",
        "\n",
        "Let's try this new hammer on our data!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZU_Q2DTjnGgO"
      },
      "outputs": [],
      "source": [
        "def get_phrase_embedding(model, phrase):\n",
        "    \"\"\"\n",
        "    Convert phrase to a vector by aggregating it's word embeddings. See description above.\n",
        "    \"\"\"\n",
        "    # 1. lowercase phrase\n",
        "    # 2. tokenize phrase\n",
        "    # 3. average word vectors for all words in tokenized phrase\n",
        "    # skip words that are not in model's vocabulary\n",
        "    # if all words are missing from vocabulary, return zeros\n",
        "\n",
        "    vector = np.zeros([model.vector_size], dtype='float32')\n",
        "\n",
        "    phrase = phrase.lower()\n",
        "    tokens = tokenizer.tokenize(phrase)\n",
        "    used_words = 0\n",
        "\n",
        "    for word in tokens:\n",
        "        if word in model:\n",
        "            vector += model[word]\n",
        "            used_words += 1\n",
        "\n",
        "    if used_words > 0:\n",
        "        vector = vector / used_words\n",
        "\n",
        "    return vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CgC5nqHRnPed"
      },
      "outputs": [],
      "source": [
        "vector = get_phrase_embedding(en_w2v_model, \"I'm very sure. This never happened to me before...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dPnvggsunU2x"
      },
      "outputs": [],
      "source": [
        "# let's only consider ~5k phrases for a first run.\n",
        "chosen_phrases = data[::len(data) // 1000]\n",
        "\n",
        "# compute vectors for chosen phrases\n",
        "phrase_vectors = np.array([get_phrase_embedding(en_w2v_model, phrase) for phrase in chosen_phrases]) #SOLUTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fxtR-rXMnsf2"
      },
      "outputs": [],
      "source": [
        "assert isinstance(phrase_vectors, np.ndarray) and np.isfinite(phrase_vectors).all()\n",
        "assert phrase_vectors.shape == (len(chosen_phrases), en_w2v_model.vector_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-bOwoX4Dnup2"
      },
      "outputs": [],
      "source": [
        "# map vectors into 2d space with pca, tsne or your other method of choice\n",
        "# don't forget to normalize\n",
        "\n",
        "phrase_vectors_2d = PCA(n_components=2).fit_transform(phrase_vectors)\n",
        "\n",
        "phrase_vectors_2d = (phrase_vectors_2d - phrase_vectors_2d.mean(axis=0)) / phrase_vectors_2d.std(axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "id": "KjeWEfWLnw04",
        "outputId": "ac65905b-9448-4924-eacf-c8f1de1ae40d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"b6a6d937-1cc0-4805-b9c2-2799b7ab8bf4\" data-root-id=\"p1047\" style=\"display: contents;\"></div>\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "(function(root) {\n",
              "  function embed_document(root) {\n",
              "  const docs_json = {\"0ae6e723-8651-4dd7-ae04-7c6c0199d9ee\":{\"version\":\"3.3.1\",\"title\":\"Bokeh Application\",\"roots\":[{\"type\":\"object\",\"name\":\"Figure\",\"id\":\"p1047\",\"attributes\":{\"height\":400,\"x_range\":{\"type\":\"object\",\"name\":\"DataRange1d\",\"id\":\"p1048\"},\"y_range\":{\"type\":\"object\",\"name\":\"DataRange1d\",\"id\":\"p1049\"},\"x_scale\":{\"type\":\"object\",\"name\":\"LinearScale\",\"id\":\"p1056\"},\"y_scale\":{\"type\":\"object\",\"name\":\"LinearScale\",\"id\":\"p1057\"},\"title\":{\"type\":\"object\",\"name\":\"Title\",\"id\":\"p1054\"},\"renderers\":[{\"type\":\"object\",\"name\":\"GlyphRenderer\",\"id\":\"p1081\",\"attributes\":{\"data_source\":{\"type\":\"object\",\"name\":\"ColumnDataSource\",\"id\":\"p1044\",\"attributes\":{\"selected\":{\"type\":\"object\",\"name\":\"Selection\",\"id\":\"p1045\",\"attributes\":{\"indices\":[],\"line_indices\":[]}},\"selection_policy\":{\"type\":\"object\",\"name\":\"UnionRenderers\",\"id\":\"p1046\"},\"data\":{\"type\":\"map\",\"entries\":[[\"x\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"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\"},\"shape\":[1001],\"dtype\":\"float32\",\"order\":\"little\"}],[\"y\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"8pL+vg9Sjr+cVaG9VVmRPlQ3Sz6eDP88sEzRvoldLL6e9S4/jfC2vswYuT+kzl6/mVDZvo24+T4E59K+mv6uP294Db8Rt9k/u2YGPzwfAECahnS9PjpEv0JyiT7Kkak/B7RDP3vmBL3B79S/V1rRPs8+zr5+Ws6/M20Av28NDL6CUhxAdRBTPimSyb6VXQm/XN65v17y6z0iG6089fZRQLvNjz/do9S+KT06P+CovL/H65Y9CAMivn7K17+8P0e+oAcYQNY5oz+2XKo+bxifv13awj8aBZ2/1cLIP4SuCL9VFXg/ZFxYPxxBV7+i91a+88ylPRmiAj84K8G/rHinv0J6CL9nraS8HziNv6DCrzwtFXC/2FnUvBPgv75TMxW/wVEnvumbD78swKs+H7xiP6WaYj4Ghs2+TdSAP+h8FL9p9Ys9MmfUvq19SL//yBQ/0SAzQCYqAsCs1CA+RaIuP9M4Yz8HdxC/AkjSPidswr9hzS6/7XvhvpTUcb9Etmc/VAyCvDjl67+SGGC++dI3P+aI8j+o6ps/3cYGv9+bdr7Uhc89PTCuv7ZfLz9FGju+8Ji8vvgI0b9MFlq/gfW+v/1EQb8yuMA/jYKlPtovvr0C2Ku/V3eUv0M0Yb5EiIo+4RLvvum3BL1GZca9NYz6vBOdhj+iMk2/E2Dmv9IQ/b4AMAa/fpnDP5MXCL+R9gg/fhM1PXcBsr0nn6a+d3BIvy633L90bfA+M6Qzvr+MpL+iSh++mTkpv721yT754dE+IzpsvlyyFz6Eoxy/RynCvwYDkL/2La89wq0jvyJRMj6xlNe+ktmEv7f9i73qT1y/i+GNPxflCL5T2Le/C5fmv19//j8febI/iDcVv1x7wr4+5OY/V2EIv9wY6j2WhRu+GF2wv3Rn3j+jCOc+QLccQDXK2j4R2/m+2xQIPxv6Hj/tJWu/pDlJv2pP9r/8RJC9hSe9vuEejL/9bcA/JF7nP0rjG0C7M8S/wCP6PtmXL7+HpUM+ussRQCuhxb/UTkZAYBumvzkV2j6g76s/dNgEPyeMsj/5jZW/OecvPygQAT/QBfA+ai+oPpljCkA018i+mgErP94QAUDpk9C+7uGwv3Ikk75RbS68f3C3vyVy4r7ULZ2+2TKBP7kttL+T8my+CaU1PxX91D/Opdo/JwAcv9D86b4I7U+/H+cWQNMYBD+oYEW/LF70Po9Gdb9iMIW/8x6iP7BAzr/8zIs/+ty3v7brrr7iPVJAv18av/rKGL+T/R9A+31vPv7vo78W8q6+5Wecv6Uppb/zwVm/mn3yvgXMeT8XAYq+8mmIv9eVnb8WFzI9UVjBPejZOD8PTRK/4TAUPQRUiD7x8Kq/aQO0PXHGr7/Gs6e+lgjmPpYRir87Spe/wemAv4PCJL4Y4Na+PTMwvwYR2b8Tlda/f5ExP4KFzz6o7yY+TR2DvwCzET9gUnU+elIHv1Xgsb2PObc/fhKfPeA5r78+GhE+i8DSvw6Auz4PCp+/ZMw5vzEd174VqOY+z40nP4JdRUA2cYI+U9P1PymlLj/Unzc/NT20v+y/jz4BXd29VuWEv7HYgr82Qbc+tuCGP6G2sr8oTa6/1izOvnOMTb592zY/3zsJv02cUT8BSWy/NccLP/zt3L7IeX0/w0Qwv3yvyD8ULjO9c5QuvquM875F9XC/k468P/pAJL9mlyo+/pyAPyBzJ73dGYG+BTFZPxT+Ib/PWHE/wGUqPyi7oj07GfW+WpvHPf7Ngb+TPdO/O882PglG4D+hbvs+oX7wvwLqjD/XYFm/IfdfvjAIFb9PIby/4ywfQEiHd79Pr+K+15MFvy3bS7+dVzK+EA1Gv9Qy677MzKq+a9IPv0N1+T2gxBW/cGdUv0Iqzz9mRcU/0St+vwt1870K01A+WT/KvPefvz9eWpq+FNI5v7QYE78QdGs/I+fUvoEbMT9LD4S/A7mgv0gTbz8Ol6w/wM3tPdS+jb8yT70/2hluvgfX1L9WoZC+EAAAv450BD4eA2O/qGZPv2eJZz/fzoE/L+rNPzEDir/RVJa+9TaGPsz75T+c8xc+OP4FPqbiBT9+l6m/XhOMP4mMLb+PuHW/EXmBPzfm7z9AdSA+CG68O4jyHz/7Wya//Ftqv/ScEz7tQKm+G/JRP+NS9z6vaY0/cFqhv/EUND5dMDO+n8LSP9Scl7+UuGw/pUowP4Miu72l0X+/Jc5dPsci7L5D14M+WvBHv3yt4L4jPOw9sphcvv9KIb98P5e/1riFviFHhD/kq3y/f2rCP1XThb0Panc/ONTYv528rT9DMjS/051SPzbUJz+3qfY+LNULvpFAFz32qKK/bRoIPgoZHr9g92g/XakNv2/EoL5th8C/H2q1P5Qxiz4dcOW+PaLHP4oaer9d8EC+xrDyv1ZJVDzJ+ni/m8k8P7k9Bb9DQd6+lWMyv1ySeT8GWIa/gwOOv8TsGUDVZ58/jiLiPig4Kj2HQWa/NE+rPh/9s76gvgM/QWCcvlWf8D7C6w+/Zit9viplbr/jc0o9TgM9P+jzEz6qj6a+mMCBvAqqGL4lUbW+sbHHv19JJr/dRzI/kov9P7awqD8qDG++4x0lwF0zOb9KSnI96nANP7fZ6735Rje/J2Z9O7kIlD89Qkm/TQuZP4iAi70EA2i/ACMWv6AstbxPAhO/gGtdv3/XDr6MuP2+yBXtPp3gTb4PmvO8tsy4vk9bbL8VyY6/sVmDPRvr6D2e654/hG9lQF/Q9r6mvaq+1hH/PTfXBkCxRZA+/EPrPb/guz4980lA4mtcv7PUjz/2pR+/zPQrv/BGHr4nBaE/oEY1v/yRpr/yziI/+xQEQBV4Zb+OLQi/fRVAvx/Imr5CN0ZAbN0nv9gw4D6eI08/Z2Amvl3a275F8QVAMFqBPdQY4z7JYDi+CqhJPwxph78AtHA/8jeHPqA6rr+1j0M/OsZeP3tb8r4kE7Q/8xICv/0EoT7Y8QO+903OP6NzjL5wcfy+RwIjv1zobj+xAYa/jglwPzT6TL0fo6e+iRGlP13PI75LS5I/s7qfP2Nad75c2BE/KQTiPhRc4b4MJx4/aTEpv96N8T6T2a6+7DIzv6jiLL/81ze/fWXAv9Jrdr9kKbO9Ao8VQE7+17/ESL6/B6rlP2u8Zr9Fr4W/0ayOvwTBTb9oawQ9FqkgP6y6gz6yZ5Q/qU8ZPpzN1r2M6JI+dz+rP9dler78ECs/i2WwvlbvcD/4kbi+FtZHv0d/vL9AP54/FqUJv/qpAr9Px3w+SbWIPjKfr77i3Y6+Kq3Zvx4GMb/wRyq+G8O/PlHHBT5fNDW/KCEfQOQBOT35G8q/COu4vwxqlL9JGbm/VNSQvZAncb8SQd292xHrvz0OHD2goji+dRi+vivZY79Ls02/+SCXv/uRjb/slZS+5OGUvVEvGr+yztK+/ohgPooHL7785gBA6xYBP0Rfuz6AEky/R45XP2HbhT+ajrK/ixQAQCcRBD/7AEy95N7wvp1S+r7VVNa+oR4YP2vmzj55Ngy/R7o4v01jdT5G+wM/JXu0PRYRhD5MtrS+L3lYv7hBAL8KBig/C0zHP6jbtL5LjG0/ihhev/y1Hb4PrvI/KwTVPFyomb+rbA6/4eCZvkkSkT4VJdK/Xc0kPzRRrL9E3M6/bzLZP3cjnr8zPkS/LjspPwhz2D56Zb4+AEOiPZY8Az8ZbQw/NjATvmEBYb5SF7c/TjPsvp1/3j0iVJe/6QJPP9/FD797WAtAVMDYPlj2iz9AkPi+VcJiv7ouAD/oqSI+Koi+vnB8R74MC1u9brO5PgN5tr9gMgk/f7PwPJfYpL9U8lI97dwwvwY+dr+VG5y/OvKiP/RFp79CtN4+OlQ0P02I/j+sLGK9Cwsiv79mKT+4GJy/Ei8UvpaEGUCWogS+QidFvpLZhL9DwkpA52qfvYQodr9ZpJW/A95/v+HijL5NR5m/sD2FPa/GtL4B9ve9mNRqP/3bUr9B7Ae/E+GxPXMUPj95IuA+JmqePiOpPr/ad7G9M6qSP19jhz3dIga/9jd1vw8XUD9yaGC/8r9avzD1u74+N1O/xja8vgz6Q0Dad9C/l73kP+3E4L4SL16/6LGAv0WdDb6EBWA/T+z4vtC1pr2Kbx4/jS6QvuH5Az+lbME+IR6fPvTIkj45MRU/TNoxPh/4Ab6u2zI/LvhYP0BEZ78b8x0+Mt6pva6Q+z8YYfI9a1dlu9J36z6fmbs+KJKtv6UrqL+EDck/WJRsP4ULjb8Krs0/BwBiQE9kg71v9xQ/8XkrP/+moL9y2lA/SNFaP4fZnj+JVqI+W6RzvyTkdT8ePz+/aXKTPfH+gr8fdBq/CkIlPzyLCb/nYU+/0XdWPuw9x7/Thii/3MaVP7k1tb49gZ4/wwcNQGWia7/bkpW+kdmwP9BWF79YiY8+dxUwPT94H7//duW+TjfTux7skr69hDI+yECyvhmZfr+/nHS/uzluv0DwIL+PXUi/sSuAvwf62780Un8+R6Y7QHPqmr7Zc5Q8tCC0PvZBtb53WZW+YOyPP4Wyrz90c1+/b42eO7gFczxssj9AcbZ4P0Z/zb9NWqI/4xKRP+w4tL8U5aO/FeGcPQCN8j6pWyS/FVWrv9rjzz9vTSg/xNrHPAJWZT8v8is+SWQJv17TBL8yEly/YI7wPgJtoz4bJIs+vUWCv4vAFb7lIlm//zRMv/kagb46WHW+t5hYvwBcHL9fmoa/Gv8tPyA+rb/akoC/Ykp9PsMgbj5bBKc+bw02v/DYVz+GUqs/yoZ+Ph0aaz/k2s8/a9IWQMn4Dr9eEE+/agsOv9QGUD808Os8n4cAPz4Fyz9xaFM/7alMQEpHjj2EIXS/BbM4v9o6Oz96LZW/KZ0cPwB/mb96g4O/CAlEv4aGpr/ZPDC/LZpiQLTfj7+BHcQ/k923P69IXL3VL/a/Wmq0v8fRNT/dN04/OiwMQOC+VUBz6wxA6SCRP1iAO72tE/U/EdY/v/YEU7ysJ58/QPcJv4Jmvr41oqm+xQUQPoMVtD4ILc4+2qWOP4p5HL4Kq3s/m+SZvl7sbD/DhX6/VUBTPhIRxT5Lo/C+nlrZP59psr7X4XG/L7UCPxMSub4J8FW/0SWuv/t/j79Y9RM/sDq5PTsXIj9U6Sw/PDwCv5pQOb/Sfe89ZFZdPwjihr9fAbm+vnkOv9GH+74ppkW/+IYMPyB0j76y+iy/OKu9PsgEwD2MxA+/Wisfvul+HT8bdPO+Bn3hPtQdA0CLPAK/thE7viCDSb9CkRI+moqhPRC1Lb/vFAM+z89nv1VOor/T0CK9xjQ2PgdJgb9aGV4/z1MFQLcYQj5oXz4/JtWOv4RVQD8=\"},\"shape\":[1001],\"dtype\":\"float32\",\"order\":\"little\"}],[\"color\",[\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\"]],[\"phrase\",[\"Can I get back with my ex even though she is pregn\",\"What is the best way to become an arms dealer in t\",\"Why doesn't Japan contribute to peace and prosperi\",\"Which is the best Panasonic air conditioner servic\",\"What did ancient Egyptians believe about the after\",\"How does one prepare for the RBI grade B officers \",\"Which institutions in Kolkata give coaching for en\",\"Will omar bravo be in fifa 17?\\n\",\"What are the pros and cons of arranged marriages?\\n\",\"What will happen if all the vegetable dies?\\n\",\"Why do people hate hypocrites?\\n\",\"What do you consider poor, middle class, wealthy a\",\"How do I concentrate on my studies?\\n\",\"What is new age psychobabble?\\n\",\"How can you tell if your man is cheating even if h\",\"Can you see yourself during lucid dreaming?\\n\",\"Which browser is most safe in terms of privacy and\",\"Can Google Assistant run on OnePlus 3T?\\n\",\"Apart from the VW Vento / Polo and Skoda Rapid, ar\",\"What is Panera Bread?\\n\",\"Do athletes live longer and healthier? If not, why\",\"Could a pitbull take on a wolf in a fight?\\n\",\"What has Obama done for Latinos/Hispanics?\\n\",\"How much is |x|^2?\\n\",\"How does operator.com work?\\n\",\"Why do people not make movies/talk about the Romas\",\"What were the major contributions of the political\",\"Company Secretaries (CS): How do I prepare for CS \",\"What are the job prospects of chemical engineers a\",\"I have never gone to a bank. How do I put money in\",\"What is the best strategy to prepare for the GATE \",\"Who is this porn star?\\n\",\"Why are specs & sunglasses so expensive?\\n\",\"I installed the movie torrent with Ultra XVid Code\",\"Can we ride scootry with learning lisence age of 1\",\"Two cards were drawn, without replacement, from a \",\"How much money is needed per month to live in indi\",\"Why do companies issue bonus shares?\\n\",\"Why are Iranians and Afghans considered white Amer\",\"Could mumps cause deafness?\\n\",\"What is meaning of sadaka?\\n\",\"What should I know before starting a YouTube caree\",\"Is the ITI College Principal is gazetted officer?\\n\",\"How do you feel now that Donald Trump is now the P\",\"What is the difference between imperial units and \",\"What is the easiest way to do effective self hypno\",\"Why has China increased its involvement in the Syr\",\"From which year CBSE class 10th exam be reintroduc\",\"Is 1080p a Blu-ray?\\n\",\"Does using mirrors to concentrate thermal energy d\",\"How do I avoid attractions by phones?\\n\",\"What are some of the effects of education can you \",\"What are the characteristics of a Pisces Sun/Libra\",\"What is the most cost-effective option to ship pac\",\"Are red and blue complementary colors?\\n\",\"Is it possible to make a material that is a superc\",\"What is the best Shonen Jump manga?\\n\",\"Are Oracle and Cisco good companies for a new grad\",\"If lighting a match is considered a chemical chang\",\"Why is Hillary so afraid of Putin?\\n\",\"Which is the best book to study electronics basics\",\"What are the basics I should know before learning \",\"Can I use Cph4 on a day to day basis?\\n\",\"Is it safe when I buy things from China?\\n\",\"Why did some ethnic minorities support Brexit?\\n\",\"How much money has tinder made?\\n\",\"What is the limit?\\n\",\"Will browsing Facebook while connected to Tor reve\",\"If I get 68.4 percent in ftre 2016 class 10 then w\",\"No product market fit: change product or market fi\",\"What makes you sad about India?\\n\",\"How do I know if someone has read my messages on w\",\"Why there is a sound when we crack our knuckles?\\n\",\"Why do I only make friends with guys?\\n\",\"What is 'open-mindedness'?\\n\",\"What is the cause of carpal tunnel syndrome?\\n\",\"What is the difference between a \\\"slow cooker\\\" and\",\"What is Hillary Clinton's stance on nuclear energy\",\"Do IIT colleges require a caste validity for an ST\",\"How do I listen a song from you?\\n\",\"Why do so many Iranians immigrate to Canada?\\n\",\"What will happen to India-U.S. relations after Tru\",\"A program that stored five words in the memory the\",\"What are ways of joining to ISRO as engineer other\",\"Can Magneto defeat Hulk?\\n\",\"What time of year is it best to visit Singapore?\\n\",\"How do I study for ib?\\n\",\"What should I do if someone doesn't reply to my em\",\"How much does Manveer Singh Phogat gets for Dangal\",\"What is it like to be cannibal?\\n\",\"How can the Android app development companies help\",\"Who would you say is the most fun person in Israel\",\"How can one improve her figure and butt size witho\",\"As a company that provides travel agencies and tou\",\"What is the most beautiful thing you saw today?\\n\",\"Is gay flirting good?\\n\",\"Can I use Stripe in Europe?\\n\",\"Will Britain leaving the European Union lead to th\",\"Why are so many East Asian immigrants so averse to\",\"Why do we need computer networking?\\n\",\"What is retina detachment?\\n\",\"Why don't more bars have mechanical bulls?\\n\",\"How do I get better understanding of C++?\\n\",\"Which is the most profitable Porsche US dealer?\\n\",\"What are the best over the ear headphones for abou\",\"Is it true that the first kill is the hardest?\\n\",\"Which is best 32 inch led tv to buy below 20,000 I\",\"I am scoring 130/506 in FiitJEE aits part test adv\",\"What kind of websites are missing from the Interne\",\"What is the best way to use free time at IITB?\\n\",\"Is it possible for me to buy my first company usin\",\"What should I do to have sex with as many women as\",\"What is the scope of Executive MBA in India?\\n\",\"Which BMW models do not have a Hofmeister Kink?\\n\",\"What is yellow journalism?\\n\",\"Why do doctors charge uninsured patients 10 times \",\"Which one is the best public sector job or private\",\"Will social media ever help to spur on the US youn\",\"How should I know a video is 360 degree?\\n\",\"Is a practice manual sufficient for the CA Final I\",\"Career Advice: Being an Indian college student, ho\",\"What are the advantages and disadvantages of Li-Fi\",\"On Snapchat, I deleted someone. Can they re-add me\",\"Are there any cereals that taste good with water?\\n\",\"Why does a woman's vagina push a mans penis out?\\n\",\"What is the British word for bullpen?\\n\",\"How hard is it for international students to get a\",\"How did Revan build his foundation of his army in \",\"What is the best way to read a fictional book? Do \",\"How do you replace a ignition lock cylinder?\\n\",\"How can I prevent business failure?\\n\",\"How often do tides occur? What causes it?\\n\",\"How do I learn Calculus on my own?\\n\",\"What is the reason for Priyanka Gandhi not changin\",\"What should I eat when I'm sick with a cold or flu\",\"What is a Business Intelligence Analyst?\\n\",\"Which sports should I start to play to paticipate \",\"How should I prepare for Java fresher interview?\\n\",\"How different are cuisines of Arab countries?\\n\",\"What is the meaning of the phrase, all is fair in \",\"Why does Quora send me a notification that my ques\",\"What are the hardest obstacles to breaking into a \",\"What makes a falling snowflake large (or not)?\\n\",\"What is the compensation for Partners/Principals a\",\"What is the difference between an array and a vect\",\"If you kiss the NC State wolf do you become an NC \",\"Is it boring (from a social perspective) to live i\",\"What would have happened if in 1971 war all 93000 \",\"What are the easiest things to do while being abro\",\"Does getting root canal cause problem in speaking \",\"What is the definition of a truncated sentence and\",\"Would I look good with a nose ring? if yes which n\",\"What are the perks of working in Amazon?\\n\",\"How can we say that climate change does not bring \",\"What it is like to meet \\\"Shahid Kapoor\\\"?\\n\",\"How does it feel when you are dead?\\n\",\"Which is the best juicer, grinder or mixer in Indi\",\"How do I learn to think more logically?\\n\",\"Which movie has the best beginning ever?\\n\",\"Which laws been enacted to prevent family members \",\"What is iPhone 6s plus cost present?\\n\",\"What is Ohm's law and amperage I?\\n\",\"What is the nicest thing a stranger has done for y\",\"Why do some heroic people who do good things choos\",\"How will Hindus react if Babri Masjid is reconstru\",\"R2I - How did you plan R2I from US if you own the \",\"How can I master C programming in 7 days?\\n\",\"What is the right way to clean ear wax?\\n\",\"What are some good games to play during class?\\n\",\"Is it possible to hack WhatsApp messenger?\\n\",\"Why do airplanes carry more weight than helicopter\",\"Shaving: Do electric shavers work better than manu\",\"Has anyone benefited, health-wise, from essential \",\"Can Students at Hogwarts have sex while there? Doe\",\"How can we enhance our efficiency with Yoga?\\n\",\"What are the best app review sites and blogs?\\n\",\"Can two companies be registered on the same addres\",\"Is it true that as per Indian law, one can't be ha\",\"Who would win in a war between Bangladesh and Myan\",\"How do you reply when someone thanks you for forgi\",\"Who would win a fight between wolverine and Batman\",\"What is one thing you wish for yourself in the fut\",\"Can you cry underwater?\\n\",\"What's the difference between SSL, TLS, and HTTPS?\",\"Why are antigravity muscles more affected in Upper\",\"In order to buy a house, does one have to rent fir\",\"What is the probability of choosing a pink ball fr\",\"Which is the best car to get under 8 lakhs?\\n\",\"Why isn't China's role in the Korean and Vietnam w\",\"What is the Laplace transform of t^(1/2) * e^ (-1/\",\"To those who told a big lie to their parents and t\",\"What is runtime polymorphism or dynamic method dis\",\"I had sex 5 days after my period, what are the cha\",\"How would you describe yourself in one tweet?\\n\",\"How do fairy tales influence creativity in humans?\",\"How do I add delay() and sound() in Dev-C++?\\n\",\"What is the pathophysiology of ADHD?\\n\",\"What are the top benefits of life insurance polici\",\"Can I get a TV from Bang & Olufsen for under $2500\",\"How is the life of an ece student at dayananda sag\",\"What is meditation?\\n\",\"Were the Ancient Greeks scientists, or just philos\",\"How does Google authenticator work?\\n\",\"Wouldn't it be better if kids were allowed to focu\",\"Can you apply for a certificate on Coursera/edX af\",\"Why do Quora engineers use large monitors?\\n\",\"How do I start an online clothing business?\\n\",\"How will the government meet the challenges of acc\",\"I saw a charge on my credit card under from a comp\",\"What is the difference between socialization and r\",\"How would the world be different if everyone spoke\",\"Who receives the fares in a cab service?\\n\",\"As a non-resident alien doing a summer internship \",\"Which is the best camera smartphone under 20k?\\n\",\"What does it mean to dream about someone before th\",\"What are the subjects in which I can apply for my \",\"What are the basics of Jainism?\\n\",\"What is the Difference between existential nihilis\",\"How can I see my girlfriend's WhatsApp chat messag\",\"What are some ways to enjoy sex with my newly marr\",\"How can I study the Bible?\\n\",\"How can someone be a friend, girlfriend, wife and \",\"What are the Snapchat usernames of punjabi celebri\",\"What is 1/2 times 1/2?\\n\",\"Where does the word restaurant come from and what \",\"What can I do with a computational linguistics deg\",\"Will trump win as president?\\n\",\"What impact will AI eventually have on how we plan\",\"Why is eating too unhealthy?\\n\",\"What if the Syrian civil war never happened?\\n\",\"How do the teachings, learning, followership and/o\",\"Did you ever been in a group of stupid people?\\n\",\"What are the multiple types of social issues?\\n\",\"Where can I find beginner NodeJS tutorials that us\",\"If I got a 7.4 CGPA in the SA1 10 class, then can \",\"Which the best time table for 10th class exams pre\",\"Elite Escorts in DHA Lahore?\\n\",\"My ex bf says he doesn't have feelings for me righ\",\"What are the questions in the interview for a fres\",\"What do you think are some of benefits to humans f\",\"Which one is the best medical college hostel in in\",\"Have you lived in a tiny house?\\n\",\"What are some things new employees should know goi\",\"Where can I hire high pressure cleaning service in\",\"How many Bollywood Actresses consume alcohol in re\",\"How does PayU earn money?\\n\",\"Is it possible to change your personality as a chi\",\"How do I apply to London School of Economics as an\",\"How do I build a profile to get accepted into a st\",\"How can I get real ghost stories?\\n\",\"Is it possible to hack NASA's New Horizons satelli\",\"What is the best way of getting good at answering \",\"How would you deal with jerks?\\n\",\"How can I do internship in Accenture India?\\n\",\"Why would an Indian girl not want to get married?\\n\",\"My WhatsApp chat backup got deleted from Google, I\",\"Is going to college really worth it or just a wast\",\"How many prophets did God send to the Jews?\\n\",\"What is the relation and difference between Artifi\",\"If you don\\u2019t have a good network, what would be th\",\"What are the best place to visit in Rio de Janeiro\",\"Which is the best college for PG in Cyber Security\",\"Which are the best English serials?\\n\",\"How do you say \\u201cWhat\\u2019s up?\\u201d in Chinese?\\n\",\"Is it bad to take expired fish oil pills because t\",\"Will there ever be a genuine Authoritarian candida\",\"Is World War III on its way right now?\\n\",\"How can you use time formats in Excel?\\n\",\"What is the best antivirus for Windows 8?\\n\",\"Why do people like Metal/Hard rock so much?\\n\",\"What are the worst smelling things in the world?\\n\",\"Could someone explain the following electives at N\",\"What's a funny thing?\\n\",\"What are the main reason of cracks?\\n\",\"How do I hitchhike in Europe?\\n\",\"What is the physical significance of quantum mecha\",\"How do we get dead people off business junk mail l\",\"Who among the four in the picture given in descrip\",\"How do I know if I authentically, genuinely, hones\",\"On average, how long does it take a letter mail fr\",\"When will One Piece have episode 517 dubbed?\\n\",\"What should I do if I fell in love with my best fr\",\"How do criminal lawyers sleep at night even when t\",\"Can I get refund for Tatkal e-ticket because train\",\"How can I buy the new Macbook 12\\\" M7 512GB model i\",\"What are the different e-governance methods used b\",\"How do I run smoother GTA V? I have intel core i3 \",\"What is the use of tanpura?\\n\",\"What are the Snapchat usernames of celebrities?\\n\",\"Which is better- cracking gate and going for IIT/i\",\"Can you lose weight without exercising?\\n\",\"What is the best way to make life more interesting\",\"Is Delhi a must for UPSC coaching?\\n\",\"Which are the best colleges for electronics and in\",\"I have been a .Net developer for over 2 years and \",\"Has a smartphone ever been taken to space? If yes \",\"What questions should I ask my boyfriend, we are b\",\"How do I delete a contact blocked in WhatsApp?\\n\",\"Is it a good time to buy real estate in Cyprus?\\n\",\"South India: Why is South India much more develope\",\"What is the formula for a hydrocarbon?\\n\",\"What if an alien comes and tells us that the physi\",\"What are the pros & cons of democracy?\\n\",\"I'm 16 years old and wanted to lose weight and bod\",\"Can I add more peers to the torrent for max speed \",\"What are the best neighborhoods to Airbnb in Chica\",\"What we will get in mahabalipuram beach sunrise or\",\"How fast can you accelerate to the speed of light?\",\"What is the difference between R-squared and Adjus\",\"How many times can women reach orgasm in a hour an\",\"Why didn't Johor, Batam & Singapore integrate more\",\"Which products are more profitable in online sell?\",\"How do I get rid of muscle?\\n\",\"What is the process of directing and casting child\",\"Is the 7th pay commission needed?\\n\",\"What are the best games that are compatible on a C\",\"What was the significance of the battle of Somme, \",\"How do you see Pakistan PM Nawaz Sharif's speech a\",\"Where can I publish my apps?\\n\",\"What was your darkest moment?\\n\",\"Why does the UK have an unwritten Constitution?\\n\",\"What are the necessary steps in documenting a mobi\",\"Why was life created? Why was life so painful?\\n\",\"How can I use explainer video to review products o\",\"What is difference between residue and error?\\n\",\"If 6.5 to 8.5 will be the safe level of pH value i\",\"I am 23 and don't know what I want. My life is ver\",\"What are your three favorite websites for reading?\",\"Why do people choose to be a GAY?\\n\",\"What is the process of death?\\n\",\"Why does light red deserve the special name \\\"pink\\\"\",\"Who are millennials?\\n\",\"What it's like doing CA articleship from Big 4s?\\n\",\"What is the most important right or freedom guaran\",\"Why do some porn stars have unprotected sex?\\n\",\"What are my reasons to live?\\n\",\"How small would a planet need to be to plainly see\",\"Some religion speaks of burning in hell after deat\",\"What does it feel like to be an IITian?\\n\",\"How does cognitive behavioural therapy work?\\n\",\"Why should you visit India?\\n\",\"I lost my Google account information. How can I re\",\"What if I port a number from Airtel to Vodafone in\",\"What are the reasons why time travel is impossible\",\"Will my iPhone alarm still go off if \\\"Do Not Distu\",\"Did South Korea cheat during the 2014 Asian Games?\",\"Take the minimum lethal volume of a gaz, put it in\",\"\\\"How to improve Project Management skills?\\\"\\n\",\"When you were small, did you ever think that your \",\"Where did the pointy \\\"S\\\" symbol come from?\\n\",\"How does it feels like to have a rich boyfriend?\\n\",\"What have you used your intelligence for?\\n\",\"What is a freewheeling diode?\\n\",\"How do we derive pi?\\n\",\"What is the importance of communication skills in \",\"How can I put icons on YouTube video titles? Also \",\"What does the phrase \\\"resonate with me\\\" mean?\\n\",\"How many types do we have of Manual testing?\\n\",\"What are IBAN numbers?\\n\",\"What is regret?\\n\",\"As a student specializing in English language, lit\",\"What is the corporate culture like at Corning? How\",\"How can I convert jazz standards to jazz guitar so\",\"How good was the surgical strike by Indian Army on\",\"What recipes are most conducive to romance?\\n\",\"What are the unknown facts about Tamil people whic\",\"Where do I find the most beautiful woman in the wo\",\"What does the grey phone icon mean on the messenge\",\"How do I share 360\\u00b0 photos on WhatsApp?\\n\",\"What is the difference between working stress meth\",\"What are the opportunities for an MBA in finance?\\n\",\"Can you patent clothing or fashion designs?\\n\",\"My in laws are apologists for Nazi war criminals a\",\"Which is the safest city in India for women?\\n\",\"What horse breed were commonly used during the \\\"Wi\",\"Is it weird to sometimes feel almost overwhelmed b\",\"Can anyone please list all the SAP SD topics a per\",\"In the filling of ibps application I put martial s\",\"In a restaurant, what are the different types of t\",\"Why does amir khan never go to any filmy awards fu\",\"What is a good inpatient drug and alcohol rehab ce\",\"Why does UV light cause contamination on optics, b\",\"How do I invest in mutual funds in India?\\n\",\"How comfortable are you with failure?\\n\",\"What skills are required to become a quant?\\n\",\"Why do startups announce fundraising?\\n\",\"What is your review of Amazon Video?\\n\",\"Why there is no team from Tamil nadu in pro kabbad\",\"How do I auto forward texts from my Verizon phone \",\"How do the Chinese people view Americans?\\n\",\"What is virgin or virginity?\\n\",\"What are the different ways of submitting a Reques\",\"Can a high school teacher legally force students t\",\"Why does water droplets form on the outer surface \",\"Which mammals have dark circles around eyes beside\",\"How do each components of a printer work?\\n\",\"What are some foods beginning with the letter W?\\n\",\"What are symptoms of a bad transmission control mo\",\"How do astronauts in ISS vote for Presidential ele\",\"What is the difference between Aim and Goal?\\n\",\"What is AT & C?\\n\",\"Who was Jackson Pollock? Was he mentally ill?\\n\",\"How do I make good vine edits?\\n\",\"How can I cut my penis?\\n\",\"How can I change my Quora profile photo?\\n\",\"My husband was here seeking asylum before we got m\",\"Is it good to use Laravel to develop a web app wit\",\"I have a mild sore throat an headache. What is tha\",\"When will a working nintendo 3DS emulator release \",\"What do we know about the health effects of vaping\",\"INSEAD: Worth the investment?\\n\",\"How is long rides in royal Enfield classic 350?\\n\",\"What famous boxers have participated on Dancing wi\",\"Will season 10 of Big Bang Theory be the final sea\",\"Can I crack KVPY (SX) with only three months left \",\"What are some little-known facts from World War II\",\"What is the most unique way of exam cheating you'v\",\"When was the last time a slam dunk broke a basketb\",\"What should I do for my excessive hair loss?\\n\",\"How do I find people's psychological weakness?\\n\",\"What is the difference between Awareness and Consc\",\"I hate everything that people around me like. Is i\",\"I think I am pretty good at thinking of a business\",\"How do you determine the thickness of a footing ba\",\"Why does vapours are formed when we pressurize alc\",\"Is it easy to adjust in German Universities withou\",\"What is UNIX and UNIX-like?\\n\",\"What is the best way to promote www.dorkyard.com?\\n\",\"What's up in Addis Abeba tonight?\\n\",\"Is there any point to going to college if you have\",\"How much would it cost to construct 800 sqft area \",\"What is an ideal wife? What is an ideal husband? W\",\"What information does port scanning provide?\\n\",\"What are the application of quasicrystals?\\n\",\"What is the determinant of the inverse of a matrix\",\"How is Brad Pitt in \\\"real Life\\\"?\\n\",\"I have a 3 yr bachelor's degree in Computer Scienc\",\"Demonetisation is good for county like India or no\",\"My parents think I am rude for being so introverte\",\"How many people have jumped off the Golden Gate br\",\"What are Osho's views on Islam?\\n\",\"Why does the government regulate health care?\\n\",\"Which phone has the best sound recording quality?\\n\",\"What is the best part of your life, and why is it \",\"Which is better hair wax or hair clay?\\n\",\"How do I charge my motorcycle battery?\\n\",\"What are the updates we get after miui 8.0.6.0?\\n\",\"Why does Robinhood need to bypass the App Store?\\n\",\"Which is a better route, Alipiri or Sri Vaari?\\n\",\"How much extra would it cost if Apple manufactured\",\"When will the next recession be?\\n\",\"What are some arguments in support of electing Don\",\"What does Russia want with Ukraine?\\n\",\"What is the difference between a recorder (block f\",\"What is the meaning of random number?\\n\",\"Which one is good for health: tea or coffee?\\n\",\"Is Texas good state for non-resident to register a\",\"What is kirchoff's law?\\n\",\"Is it wrong for a family member to keep making com\",\"My parents are forcing to marry a girl of their ch\",\"Which is better, Windows+Linux or OSX?\\n\",\"Why aren\\u2019t Christians that pray to/have a relation\",\"How much TDS will I have to pay for an RD account \",\"What is the meaning of thematic connection?\\n\",\"How should you prepare to take your maneuverabilit\",\"What are the best materials/videos/resources to ge\",\"Can a \\\"dirty\\\" finish be added back to jeans?\\n\",\"Why does my dog keep whining at night?\\n\",\"Is it bad to turn off my PC using the power button\",\"What is image processing?\\n\",\"I went to school with mostly black kids, they bull\",\"Does Donald Trump actually think he can become Pre\",\"Which are the 5 best movies you have ever seen?\\n\",\"How do I get traffic to excursions travel website?\",\"Where can I download the Android game Leo's Fortun\",\"How do I get more followers and upvotes on Quora?\\n\",\"What is a factory reset on a phone?\\n\",\"Which phone should I buy if my budget is 12000?\\n\",\"I have GPU implementation as a graduation project.\",\"What are the libertarian views on the Antarctic Tr\",\"What would the world be like if it were ruled by a\",\"How do you choose your first bank?\\n\",\"Who runs berkuliah.com?\\n\",\"What does Godel's incompleteness theorem mean for \",\"How do I delete a Gmail account?\\n\",\"If my ultimate goal is to become a vegan, should I\",\"Did the US win the war in Afghanistan?\\n\",\"How can I become a good engineering student?\\n\",\"What are some ways to increase intuition?\\n\",\"What causes depression in humans?\\n\",\"How can I control my anxiety and worries?\\n\",\"How can we jump in between the working regions of \",\"How do I stop loving someone who loves me?\\n\",\"Can personality and insecurity create a liar?\\n\",\"What is the best country and university to do a Ph\",\"How do I edit a video offline?\\n\",\"What is the rent of kiosk in an upscale mall?\\n\",\"What should I start reading if I want to attempt t\",\"Which is the best anti-virus for computers?\\n\",\"Does food unite people?\\n\",\"What do you like most about Internet?\\n\",\"What is a good model of federalism in the Philippi\",\"How do you know if a girl secretly loves you?\\n\",\"Who is the most annoying fictional character you h\",\"How do you feel when your question is unanswered o\",\"Did early humans know how babies were made?\\n\",\"If I cancel xfinity, how can I sign up as a new cu\",\"Are there any TV series similar to House MD?\\n\",\"What you need to know before buying furniture for \",\"Have you ever had a dream happen in reality?\\n\",\"Is dark matter just a scientific theory or has its\",\"How can you increase your tolerance for pain?\\n\",\"How many logical fallacies are there?\\n\",\"How do buttercream icing frosting separate?\\n\",\"Which is the cheapest cinema hall of India?\\n\",\"What do you think would be a good gre score?\\n\",\"What is the best way to update Xiaomi redmi 3 to M\",\"What does toe jam cheese taste like?\\n\",\"How do I know if a YouTube video is copyrighted?\\n\",\"How should I start a business reselling shoes?\\n\",\"How do I hire a mobile app development company?\\n\",\"What is paras pathar?\\n\",\"How is the word \\\"colony\\\" used in a sentence?\\n\",\"What is Rebecca Fugate known for?\\n\",\"What should I consider before starting my consulta\",\"Do you feel that many attractive women get away wi\",\"Why do I feel so much guilt for kissing a girl?\\n\",\"What are some good tutorials for learning Blender?\",\"Is it deceitful to befriend someone in the hopes t\",\"Who do you think BJP will put as a candidate for t\",\"Which protein supplement is best for gym to gain w\",\"What is your review of KVPY SX/SB 2016?\\n\",\"How do I get people's attention for my work?\\n\",\"What are some of your own personal stories and exp\",\"If salt concentration of the sea(3%) were differen\",\"What is the chemical name for mothballs? How was i\",\"Vitamin D receptors in the Testes?\\n\",\"How do I lose weight without working out?\\n\",\"Where can I watch anime?\\n\",\"What is BusyBox used for?\\n\",\"What would be a good desktop computer for software\",\"What are your top five favorite books and why?\\n\",\"What are some good Harry/Ginny fanfiction?\\n\",\"What are the pros and cons of having sex during pe\",\"Which device will you enjoy watching movies in: a \",\"Will there be \\\"faithless\\\" electors this election?\\n\",\"Is Donald Trump an undercover democrat?\\n\",\"Why am I the way I am?\\n\",\"Why do some women get their nipples pierced?\\n\",\"What do Delhi University girls (especially North C\",\"What is the name of this TV series?\\n\",\"My salary is below the Basic Exemption Limit, yet \",\"What is a foliated rock?\\n\",\"What are some of the best books to start learning \",\"How should I prepare for IIT-JEE 2018?\\n\",\"How do unions work?\\n\",\"Can we give neet coaching in class 11?\\n\",\"Which is the best dish TV connection in Hyderabad?\",\"How can you train a Doberman/Lab mix?\\n\",\"How do you reduce stress at work?\\n\",\"What is the best algorithm for finding the number \",\"How can I earn $250 in 2 months?\\n\",\"Why did GE buy NBC?\\n\",\"What is the highest level of c?\\n\",\"How do you mash potatoes without a masher? What el\",\"How difficult is it to learn Python?\\n\",\"How do you convert years into seconds?\\n\",\"How do you view bisexuality?\\n\",\"What is information technology? What are some exam\",\"Why are Altoids so strong?\\n\",\"How effective is email marketing?\\n\",\"Why does my tutor keep winding me up. He says he i\",\"How can I start my Tok essay which is about accura\",\"How do I repair my corrupt memory card?\\n\",\"I have 3 years to prepare for IIT JAM Physics. How\",\"What are the best Instagram hack tools that have n\",\"I am studing interior design. What are some good i\",\"What are some stupid jokes that make you laugh?\\n\",\"What are the factors affecting Real estate investm\",\"How can I get rid of white dry spot on my face? It\",\"What is it like to have an ugly wife/partner?\\n\",\"What do you love most about your life and why?\\n\",\"In the unlikely event that the Electoral College t\",\"How is life as an Engineer?\\n\",\"Where and why are the imaginary numbers used?\\n\",\"What are some good hypo-allergenic lipsticks?\\n\",\"Did the United Nations play a part in the divide o\",\"When and Why did America become a world power?\\n\",\"What are some recipes using Hormel Black Label Ham\",\"Which is the best company to invest shares on Nove\",\"The man I'm about 2 marry says when I have my peri\",\"What can be the best answer for why finance?\\n\",\"What are the best facts about the universe?\\n\",\"What's the sweetest thing you did for a bestfriend\",\"What is the difference between techno and trance m\",\"TV Sitcoms: Why do English comedy shows have peopl\",\"Does percentile system would affect neet 1 student\",\"Is there Uber in Valencia, Madrid and Barcelona?\\n\",\"Have real-life siblings ever shot intimate scenes \",\"How should I improve my writing skill for blogging\",\"Can cold weather affect a menstrual cycle?\\n\",\"How can we earn money online while studying?\\n\",\"Can a tablet keyboard be used on any kind of table\",\"What are the Upcoming development projects in Chha\",\"Where can I buy cheap Twitter followers?\\n\",\"Why do passengers from aircraft are not given a bu\",\"When should I tell my crush I like her?\\n\",\"Why does Pakistan have a better image and reputati\",\"What are Andrea Pirlo's strengths as a midfielder?\",\"From a point in space billions of light years away\",\"Will Medicaid pay for electrologist to do the shav\",\"Why do technical employees despise sales people so\",\"What are the best freelance websites for C#?\\n\",\"Will I be successful without educations?\\n\",\"How can I learn about cars?\\n\",\"What is the best question asked in an interview?\\n\",\"Why there is so much hatred against Brahmins in In\",\"How do I learn to enter journal entries online in \",\"Will CS be issuing a PR message for Boston?\\n\",\"Why do some people 'hate' drugs or people who ever\",\"How do I know my passion? What is my talent and wh\",\"How do pessimists and optimists differ?\\n\",\"How many pulleys did it take for Archimedes to lif\",\"What is the best course after 12th for a medical s\",\"What are the steps that I should follow to get in \",\"Where was the boston marathon?\\n\",\"What is it like to be in or around a bomb blast?\\n\",\"Will Trump destroy international US-companies thro\",\"Should celebrities have the right to voice their o\",\"Can I say that: \\\"A battery can be seem as a capaci\",\"What is it like to be an ENTP?\\n\",\"How do I start designing on glass?\\n\",\"What is the market risk premium formula?\\n\",\"How can I pay the parking meter if I have no coins\",\"Is it true that Obama has a secret son named \\\"Luth\",\"Which is the best coaching for IAS in up?\\n\",\"How big is the equity funding market in North Amer\",\"Which are the good government medical colleges in \",\"How do I control my hair fall?\\n\",\"Is it really worth creating Shopify themes?\\n\",\"What can cause knee pain? It only hurts when I sta\",\"Where can you find a list of common 9 letter words\",\"NSFW: Is this penis color normal or should I see a\",\"Why do most women remove the hair from their arm p\",\"Which processor is better (faster/more efficient),\",\"Which two statements are true regarding views in s\",\"What is the easiest and quickest Indian food recip\",\"What are the best local SEO companies in India?\\n\",\"How do I get rid of adult content on my Quora feed\",\"Can the zombie fungi attack humans as well?\\n\",\"If I wanted to learn about the Roman Empire,what w\",\"What are the key differences between LXDE and XFCE\",\"Can people see the sellers real name, e-mail addre\",\"Should I still watch The Matrix movie?\\n\",\"Is there any truth to the rumor that the youngest \",\"Is it ok that I don't want to hang out with my fam\",\"I am in class 9. If i want to crack IIT JEE, then \",\"Will Obama's gang stalking/surveillance program be\",\"What are some good songs to lyric text prank a fri\",\"Where can I get best quality video DJ for party in\",\"How long does it take for your hair to grow?\\n\",\"Should I update my Redmi 3s from MIUI 7 to MIUI 8?\",\"How do muscles work?\\n\",\"WHAT IS THE BEST ROUT FOR NEPAL PASUPATI NATH TEMP\",\"How to make a website similar to feedwiser.com in \",\"Why does India so scared of CPEC?\\n\",\"What did your first sex feel like as a girl?\\n\",\"In International ODI/T20 cricket matches, if a bat\",\"Why can humans feel acceleration, but not constant\",\"Can the Microsoft Surface Pro 4 run AutoCAD?\\n\",\"What are the differences between stock Crown Victo\",\"What are the good ways to download Lynda.com's tut\",\"How much is the average salary package for a 1.5 y\",\"How can you reduce the barriers of communication?\\n\",\"Why would someone use Instagram Stories over Snapc\",\"Whiskey: How many 'shots' are in a fifth of Jack D\",\"What might happen now that President-elect Donald \",\"How do I write a waiver letter for school?\\n\",\"I am interested in persuing ma industrial psycholo\",\"Does modafinil shows up on a drug test? Because my\",\"Is it possible to get high off Vyvanse?\\n\",\"Is an agnostic necessarily a skeptic, and how?\\n\",\"Where can I get best support in Sydney for buying \",\"What are the duties of a lieutenant in Indian army\",\"Why is smileys not used on Quora?\\n\",\"What does it feel like for a man when someone who \",\"How does post graduation permit impact .lets say I\",\"Online Payment Gateways and Processing: What is th\",\"What are the best books to learn c programing lang\",\"Solid State Physics: What is The Theory of Alloys?\",\"How do I fill in my first name in a PAN card dupli\",\"Why is egg yolk not good for you?\\n\",\"Anatomy of Female Pelvis: Do women really have an \",\"How much does it cost to develop mobile applicatio\",\"Who is the most honest Game of Thrones character?\\n\",\"What is a high quality Apple MacBook Air charger?\\n\",\"Where and how is the WWE championship belt made?\\n\",\"What is green communication?\\n\",\"I have been a good student since chiild hood but j\",\"I'm solving exercises of artificial neural network\",\"Compared to your own compensation, and in consider\",\"How can I keep browsing Quora forever?\\n\",\"Having built web stuff the old way (PHP/MySQL) bac\",\"Is our new currency note of Rs.2000 equipped with \",\"What's the best way to join a startup in DC?\\n\",\"What would happen if we added a second Earth of eq\",\"When will piracy on Android stop?\\n\",\"What do you mean by executive consultant and suppo\",\"Why do I always feel like I am missing something?\\n\",\"What does a user see when he/she gets a new messag\",\"How can I become a web developer?\\n\",\"Is there any good alternative softwares to Tally?\\n\",\"Would you have sex during period?\\n\",\"Are there prominent Bangladeshi Hindus?\\n\",\"I have registered for PhD (no NET) (phy) in 2013, \",\"I changed my name, but the person did a mistake. M\",\"At what age do your breasts stop growing?\\n\",\"How do I get a girl's phone number in a library?\\n\",\"I am into a habit of over thinking things. How do \",\"What is the average salary of a civil engineer?\\n\",\"What is the difference between rote learning vs me\",\"What are the ways to compete in the Olympics in 20\",\"What trivia (and/or little-known facts) do you fin\",\"Xiaomi Redmi note 3: Which is the best colour to b\",\"What does \\\" the Hadamard Perron theorem\\\" means?\\n\",\"Is there a way to see the viewing history and chat\",\"What is the best place for trekking in Goa?\\n\",\"How does an instant messenger work?\\n\",\"What are the disadvantages of the World Trade Orga\",\"Why does the US military not use AK series rifles?\",\"Does Moto m have gorilla glass?\\n\",\"What is the hierarchy of an associate consultant a\",\"What are some major landforms in Texas, and how do\",\"What other jobs can a medical degree holder do mea\",\"MY HP DEXTOP DOESNOT CONNECT WIFI WHY?\\n\",\"How can I get motivated to workout?\\n\",\"What should I gift it to my mom on her birthday?\\n\",\"Which is the best video you have ever seen?\\n\",\"I was selected in campus and was issued a joining \",\"What makes a poem a good way to express emotions? \",\"What would happen if I cut down a tree outside my \",\"Can you make money in Amway?\\n\",\"Body Weight: How many pounds can I gain every week\",\"What are the impacts (both positive & negative) of\",\"I forgot the password which I used to login n n lo\",\"What are the best websites for career?\\n\",\"What is your favourite episode of the office (USA)\",\"Why is time slower down near heavy objects?\\n\",\"How do l update any version after rooting the mobi\",\"Why is 3 am called the witching hour?\\n\",\"How do I run a shell script from Java code?\\n\",\"What are the advertising campaigns of 2011?\\n\",\"Should I opt for computer science if I don't take \",\"What are the polymers of protein?\\n\",\"How much better will the JWST be than Hubble?\\n\",\"What are the greatest examples of absence of mind?\",\"How can I understand the STOCK market from the bas\",\"How do I make Gazpacho?\\n\",\"What is the typical role of a brand manager?\\n\",\"Who are the top 5 hottest women ever?\\n\",\"What is the name of the game that Aamir Khan was r\",\"How long does it take to learn dance?\\n\",\"What's the funniest thing that's happened to you a\",\"Why are metals malleable and ductile?\\n\",\"List of national daily in India?\\n\",\"Are Volvos actually safer than comparable cars?\\n\",\"Can you tell who has been looking at your Instagra\",\"A ball dropped from the roof of a building takes 4\",\"What percentage of Hillary Clinton's supporters ha\",\"Do you think you are beautiful?\\n\",\"Which are the free email marketing tools?\\n\",\"What topic of discussion do people hate the most? \",\"What is the point in having hyper-politicised stud\",\"Why Steve Jobs is considered as innovator?\\n\",\"How long would it take an average programmer to wr\",\"Why are conservatives defending Holly Fisher? (see\",\"What is so important about Adam Smith's pin factor\",\"What is the Arizona bark scorpion, and how do anim\",\"How do I stop smoking cigarettes?\\n\",\"What are the functions of a computer's motherboard\",\"How can tea bags help for styes?\\n\",\"How can I get a patent for my really effective inn\",\"Can India ever become 'Sone Ki Chidiya' again?\\n\",\"Is there any way to play Android games LAN multipl\",\"Why should I ask my first question?\\n\",\"Who are the top writers on Hinduism on Quora? Who \",\"How do I wake up at 4:00 A.M.?\\n\",\"Why is Quora moderation collapsing all my answers?\",\"In an honest assessment, what do you think of Trum\",\"What type of bonding is present in a coordinate bo\",\"Is it possible to delete your Wikipedia account hi\",\"I'm a +2 CBSE non-medical student. Is there any pr\",\"Are there any limitations as to setting up a forei\",\"How will the drought in California affect its econ\",\"What is Informatica online training?\\n\",\"Is it compulsory for a Web designer and developer \",\"How could the US realistically pay off its debt?\\n\",\"Who is Barry Soetoro?\\n\",\"How do I solve [math]2x^3-x^2+11x+3=0[/math]?\\n\",\"What are some hobbies couples can do at home?\\n\",\"How have meerkats adapted to the desert?\\n\",\"What causes dizziness when you lay down?\\n\",\"What should one do after a civil engineering degre\",\"What are the advantages of hiring skip bins servic\",\"Why is it necessary that singers lip-sync?\\n\",\"How can I turn off the screen overlay detected on \",\"How do you clean or polish a pair of Woodland shoe\",\"What are some classes you wish you took in high sc\",\"What is the formula of [math](a+b)^3[/math]?\\n\",\"What is it like to commit yourself to a psychiatri\",\"Is there any way to slow or reverse the late effec\",\"What would the implications be if we discovered th\",\"Any other program to help on code contribution for\",\"What is the bond order of [math]H_2[/math]?\\n\",\"What is the best way to create a website without c\",\"What were some causes and effects of the French Re\",\"What are some catchy headlines for a dating site?\\n\",\"Should I get Company of Heroes, World in Conflict \",\"How do I remove a person from a group in Skype?\\n\",\"Why was Manmohan Singh briefed by PM Modi after su\",\"Does anybody want to learn Chinese?\\n\",\"Is Xiaomi going the Nokia way to oblivion?\\n\",\"Should I buy hp 17.3 AMD laptop or lenovo 17.3 i5 \",\"Which is better a government job or a software job\",\"How can the word \\\"credulity\\\" be used in a sentence\",\"Does uber track time on app?\\n\",\"How do I get over direct rejection?\\n\",\"How can any institute get an ISO certificate?\\n\",\"What are the best pranks?\\n\",\"Are non-solicit agreements enforceable if the pers\",\"Which phone is best in 2016 for a 18 years boy my \",\"What is the definition of an archetypal hero?\\n\",\"Why are some \\\"ugly\\\" people still very attractive?\\n\",\"What are the chances of Donald Trump's impeachment\",\"What would a society based on laws enforcing only \",\"What is the full form of \\\"veto\\\" power?\\n\",\"How much do people get paid to do a TED talk?\\n\",\"What does it mean to say \\\"enriching herself off of\",\"How can I be more persuasive at work?\\n\",\"What is the corporate culture like at National Bev\",\"What is the fastest way to get a PAN card?\\n\",\"Who will win in America presidential elections in \",\"How do I solve this differential problem?\\n\",\"How is Banjara's Saffron Facial Kit used?\\n\",\"How do you understand life?\\n\",\"Will an MS from NUS in electrical engineering prov\",\"How does one create a strong password? Any tips?\\n\",\"Who was the best dressed at the 2016 Emmy's?\\n\",\"What is the cost of manufacturing a SIM card?\\n\",\"Are you tolerant?\\n\",\"Is [math]\\\\{1,2,3\\\\}[/math] a compact subset of a me\",\"What kind of energy is involved in hearing and vis\",\"What happened with Lehman Brothers?\\n\",\"What is a good web page publisher?\\n\",\"Why does eating radishes cause diarrhea?\\n\",\"How do I encrypt the data on my Android phone?\\n\",\"If there were an Oscar for \\\"Best Line in a Movie\\\",\",\"Why are tyres black?\\n\",\"What is the best way to unlock a Motorola Droid Bi\",\"Is a $45 a month job worth the experience?\\n\",\"Should I settle in Canada or Japan?\\n\",\"How is the appraisal process in Accenture? How wil\",\"How does sand turn into glass?\\n\",\"What effect will increased automation of jobs and \",\"I am 25 years old Indian guy, want to settle in Ne\",\"What are some Raksha Bandhan gift suggestions for \",\"How do I write a multi-dimensional villain that is\",\"Why is there no nucleus in a red blood cell?\\n\",\"Why do Quora allow anonymous fake questions from A\",\"Is it possible to merge a foursquare venue into a \",\"How do I find out if I have Siri on my phone?\\n\",\"Why do I feel like I'm not living my life?\\n\",\"What will happen to global stock market if Donald \",\"What makes weeds grow so much faster and easier th\",\"Do people with extremely high IQ need higher sugar\",\"What should teaching assistants do?\\n\",\"Why is Perth one of the most liveable cities in th\",\"How do you get to the entrance for Resolution Cave\",\"How do I get involved in research as an undergradu\",\"If you have one option to remove anything, what wi\",\"What are the risk after angioplasty?\\n\",\"Why can't men read the signals women give off when\",\"How can a non-EU medical graduate get into residen\",\"How do I stay active?\\n\",\"I'm going to Paris. What is the equivalent \\\"neighb\",\"How do I get rid of dandruff, or at least prevent \",\"Is Medicaid going to pay for the electrologist for\",\"When Australia became a nation in 1901, Did aborig\",\"What is the difference between SSL and Sitelock?\\n\",\"What are some unsolved problems in deep machine le\",\"What's the difference between computer engineering\",\"Is it possible to get a decent job after completin\",\"What is the difference between MG & BG in railway \",\"How do I control an Arduino with a Raspberry Pi?\\n\",\"What is the best field to pursue MS after doing el\",\"What is the difference between Directx and graphic\",\"How do I wirelessly charge the electrical devices \",\"Can you upload Numbers sheets from iPad to Google \",\"What's the best movie franchise you have ever watc\",\"If light does not have mass, then how can it be ab\",\"Why is the book of Esther in the Bible?\\n\",\"What makes comic books worth reading?\\n\",\"What are the advantages of outsourcing property ma\",\"What is a Quora credit competition?\\n\",\"Are data analyst/data science jobs boring?\\n\",\"Why don't satellites crash into each other?\\n\",\"How do dermatologists remove blackheads?\\n\",\"How can I choose between my dad and my mom?\\n\",\"Can you really not change people?\\n\",\"Being a non believer of a spiritual entity, I have\",\"Is black coffee fattening? If so, what makes it fa\",\"The education system is outdated. What would you d\",\"Who are the founders of Quora?\\n\",\"What is it like to be a landlord?\\n\",\"How many stamps do I need to send a letter to germ\",\"My father just recently got married. His wife goes\",\"Which countries are best to migrate from the US?\\n\",\"Can any one tell me a basketball club in Bangalore\",\"How can Spotify download songs offline?\\n\",\"How do I make money online for free in Spain?\\n\",\"Why is Tornado Alley prone to tornadoes?\\n\",\"How does helium change the inhaler's voice?\\n\",\"What is a bedding ceremony in Game of Thrones?\\n\",\"What is it like living in former East Germany as a\",\"Did the USA or NATO commit any war crimes in Iraq?\",\"Why don't we capture terrorist and behead them?\\n\",\"What is your favorite quote (books, movies, people\",\"What mixes well with peach vodka?\\n\",\"Which Patanjali products contain cow urine?\\n\",\"Why are three phases denoted by RYB?\\n\",\"Where could I learn JavaScript online?\\n\",\"Is it appropriate to wear a sports bra simply to t\",\"What are the differences between Jenkins CI and Dr\",\"T right do you think we should be entitled to?\\n\",\"What was the public's reaction to Crystal Pepsi?\\n\",\"How can I crack MH-CET 2017 engineering by self-st\",\"What is the way to become a dental hygienist in th\",\"Why do solving math/statistics problems causes my \",\"Does your name sound as awkward to others as it so\",\"What is the proper format of writing formal-inform\",\"How does doc2vec represent feature vector of a doc\",\"Why are software development task estimations regu\",\"How can I set up molecular pathology lab?\\n\",\"How do I score a rank in CA - IPCC?\\n\",\"What are some examples of strong organic acids?\\n\",\"What can be a good hindi (indian) name for a tea b\",\"Is the Google host matching process different for \",\"Is Cuba considered part of Latin America?\\n\",\"Does the following script (\\u0256\\u2200\\u0f61\\u0632\\u2202 \\u0250\\u0167 \\u01ab\\u04bf\\u03de\\u026e\\u2609 \\u027d\\u03c6\\u0289\\u029b\\u0195), \",\"How can I increase my website's DA?\\n\",\"Is it normal to imagine having sex with other guy \",\"What is the percent purity (approx) of consumable \",\"Do soulmates just come walking into your life when\",\"If I use marijuana with my boyfriend, is there a p\",\"Can you analyze everything in soil?\\n\",\"What difference it would make if India Nuked and K\",\"What are the advantages of a dominant party system\",\"What were some things India did not do but takes c\",\"How many total women have accused Bill Clinton of \",\"Why do I wish some fictional characters existed?\\n\",\"Where can I find best hotel at Ranikhet?\\n\",\"How do I make good memes?\\n\",\"What are some of the common sayings or proverbs in\",\"What kind of writing style makes someone a \\\"dark w\",\"Are Trump and Hillary really the best America has \",\"How can I make my career in embedded system and ro\",\"Will adding a USB to VGA adapter always give an ex\",\"We will never be able to see our own faces with ou\",\"What are the ways you can stop a friend from pitch\",\"What is the average time for preparation of IAS?\\n\",\"How can I learn new things quickly?\\n\",\"What is the definition of political courage?\\n\",\"What makes death scary?\\n\",\"I'm really pretty but I don't want to be I hate th\",\"Is Assam Down Town University good?\\n\",\"How do the brain structures of bonobos change as t\",\"What's the biggest scam?\\n\",\"Does the US government have an alien flying saucer\",\"I need to gain weight, but I don't have abs. It's \",\"Why should I study Calculus?\\n\",\"Do you think your childhood contributed to your fi\",\"How does the Goods and Services Tax (GST) works?\\n\",\"Where can I download Cisco 500-285 exam dumps?\\n\",\"How do I can make a second nation in Cybernations \",\"Did Neil Armstrong really land on the moon?\\n\",\"Why is Devil any other than God head of state?\\n\",\"How do I stop being possessive over my girlfriend?\",\"How does Kongregate compute the statistics of adve\",\"Who is the best nuero physician at NIMHANS, Bangal\",\"What are nonprofit organizations?\\n\",\"I want to know the process of starting outbound ca\",\"Which are some of the best hotels to stay in Helsi\",\"What is good about Deloitte Chicago?\\n\",\"How do I recover data from a formatted hard drive?\",\"Could India and Pakistan unite again?\\n\",\"How often should I massage my face with Argan oil?\",\"How is psychodynamic therapy different from psycho\",\"What are some of Barack Obama's character traits?\\n\",\"Would it make sense to replace the B-52's 8 1960s \",\"Is it possible to bring forward my flight date of \",\"How can I learn marathons?\\n\"]]]}}},\"view\":{\"type\":\"object\",\"name\":\"CDSView\",\"id\":\"p1082\",\"attributes\":{\"filter\":{\"type\":\"object\",\"name\":\"AllIndices\",\"id\":\"p1083\"}}},\"glyph\":{\"type\":\"object\",\"name\":\"Scatter\",\"id\":\"p1078\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"y\":{\"type\":\"field\",\"field\":\"y\"},\"size\":{\"type\":\"value\",\"value\":20},\"line_color\":{\"type\":\"field\",\"field\":\"color\"},\"line_alpha\":{\"type\":\"value\",\"value\":0.25},\"fill_color\":{\"type\":\"field\",\"field\":\"color\"},\"fill_alpha\":{\"type\":\"value\",\"value\":0.25},\"hatch_color\":{\"type\":\"field\",\"field\":\"color\"},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.25}}},\"nonselection_glyph\":{\"type\":\"object\",\"name\":\"Scatter\",\"id\":\"p1079\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"y\":{\"type\":\"field\",\"field\":\"y\"},\"size\":{\"type\":\"value\",\"value\":20},\"line_color\":{\"type\":\"field\",\"field\":\"color\"},\"line_alpha\":{\"type\":\"value\",\"value\":0.1},\"fill_color\":{\"type\":\"field\",\"field\":\"color\"},\"fill_alpha\":{\"type\":\"value\",\"value\":0.1},\"hatch_color\":{\"type\":\"field\",\"field\":\"color\"},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.1}}},\"muted_glyph\":{\"type\":\"object\",\"name\":\"Scatter\",\"id\":\"p1080\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"y\":{\"type\":\"field\",\"field\":\"y\"},\"size\":{\"type\":\"value\",\"value\":20},\"line_color\":{\"type\":\"field\",\"field\":\"color\"},\"line_alpha\":{\"type\":\"value\",\"value\":0.2},\"fill_color\":{\"type\":\"field\",\"field\":\"color\"},\"fill_alpha\":{\"type\":\"value\",\"value\":0.2},\"hatch_color\":{\"type\":\"field\",\"field\":\"color\"},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.2}}}}}],\"toolbar\":{\"type\":\"object\",\"name\":\"Toolbar\",\"id\":\"p1055\",\"attributes\":{\"tools\":[{\"type\":\"object\",\"name\":\"PanTool\",\"id\":\"p1068\"},{\"type\":\"object\",\"name\":\"WheelZoomTool\",\"id\":\"p1069\",\"attributes\":{\"renderers\":\"auto\"}},{\"type\":\"object\",\"name\":\"BoxZoomTool\",\"id\":\"p1070\",\"attributes\":{\"overlay\":{\"type\":\"object\",\"name\":\"BoxAnnotation\",\"id\":\"p1071\",\"attributes\":{\"syncable\":false,\"level\":\"overlay\",\"visible\":false,\"left_units\":\"canvas\",\"right_units\":\"canvas\",\"top_units\":\"canvas\",\"bottom_units\":\"canvas\",\"line_color\":\"black\",\"line_alpha\":1.0,\"line_width\":2,\"line_dash\":[4,4],\"fill_color\":\"lightgrey\",\"fill_alpha\":0.5}}}},{\"type\":\"object\",\"name\":\"SaveTool\",\"id\":\"p1072\"},{\"type\":\"object\",\"name\":\"ResetTool\",\"id\":\"p1073\"},{\"type\":\"object\",\"name\":\"HelpTool\",\"id\":\"p1074\"},{\"type\":\"object\",\"name\":\"HoverTool\",\"id\":\"p1084\",\"attributes\":{\"renderers\":\"auto\",\"tooltips\":[[\"phrase\",\"@phrase\"]]}}],\"active_scroll\":{\"id\":\"p1069\"}}},\"left\":[{\"type\":\"object\",\"name\":\"LinearAxis\",\"id\":\"p1063\",\"attributes\":{\"ticker\":{\"type\":\"object\",\"name\":\"BasicTicker\",\"id\":\"p1064\",\"attributes\":{\"mantissas\":[1,2,5]}},\"formatter\":{\"type\":\"object\",\"name\":\"BasicTickFormatter\",\"id\":\"p1065\"},\"major_label_policy\":{\"type\":\"object\",\"name\":\"AllLabels\",\"id\":\"p1066\"}}}],\"below\":[{\"type\":\"object\",\"name\":\"LinearAxis\",\"id\":\"p1058\",\"attributes\":{\"ticker\":{\"type\":\"object\",\"name\":\"BasicTicker\",\"id\":\"p1059\",\"attributes\":{\"mantissas\":[1,2,5]}},\"formatter\":{\"type\":\"object\",\"name\":\"BasicTickFormatter\",\"id\":\"p1060\"},\"major_label_policy\":{\"type\":\"object\",\"name\":\"AllLabels\",\"id\":\"p1061\"}}}],\"center\":[{\"type\":\"object\",\"name\":\"Grid\",\"id\":\"p1062\",\"attributes\":{\"axis\":{\"id\":\"p1058\"}}},{\"type\":\"object\",\"name\":\"Grid\",\"id\":\"p1067\",\"attributes\":{\"dimension\":1,\"axis\":{\"id\":\"p1063\"}}}]}}]}};\n",
              "  const render_items = [{\"docid\":\"0ae6e723-8651-4dd7-ae04-7c6c0199d9ee\",\"roots\":{\"p1047\":\"b6a6d937-1cc0-4805-b9c2-2799b7ab8bf4\"},\"root_ids\":[\"p1047\"]}];\n",
              "  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
              "  }\n",
              "  if (root.Bokeh !== undefined) {\n",
              "    embed_document(root);\n",
              "  } else {\n",
              "    let attempts = 0;\n",
              "    const timer = setInterval(function(root) {\n",
              "      if (root.Bokeh !== undefined) {\n",
              "        clearInterval(timer);\n",
              "        embed_document(root);\n",
              "      } else {\n",
              "        attempts++;\n",
              "        if (attempts > 100) {\n",
              "          clearInterval(timer);\n",
              "          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
              "        }\n",
              "      }\n",
              "    }, 10, root)\n",
              "  }\n",
              "})(window);"
            ],
            "application/vnd.bokehjs_exec.v0+json": ""
          },
          "metadata": {
            "application/vnd.bokehjs_exec.v0+json": {
              "id": "p1047"
            }
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div style=\"display: table;\"><div style=\"display: table-row;\"><div style=\"display: table-cell;\"><b title=\"bokeh.plotting._figure.figure\">figure</b>(</div><div style=\"display: table-cell;\">id&nbsp;=&nbsp;'p1047', <span id=\"p1088\" style=\"cursor: pointer;\">&hellip;)</span></div></div><div class=\"p1087\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">above&nbsp;=&nbsp;[],</div></div><div class=\"p1087\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">align&nbsp;=&nbsp;'auto',</div></div><div class=\"p1087\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">aspect_ratio&nbsp;=&nbsp;None,</div></div><div class=\"p1087\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">aspect_scale&nbsp;=&nbsp;1,</div></div><div class=\"p1087\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">background_fill_alpha&nbsp;=&nbsp;1.0,</div></div><div class=\"p1087\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">background_fill_color&nbsp;=&nbsp;'#ffffff',</div></div><div class=\"p1087\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">below&nbsp;=&nbsp;[LinearAxis(id='p1058', ...)],</div></div><div class=\"p1087\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">border_fill_alpha&nbsp;=&nbsp;1.0,</div></div><div class=\"p1087\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">border_fill_color&nbsp;=&nbsp;'#ffffff',</div></div><div class=\"p1087\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">center&nbsp;=&nbsp;[Grid(id='p1062', ...), Grid(id='p1067', ...)],</div></div><div class=\"p1087\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">context_menu&nbsp;=&nbsp;None,</div></div><div class=\"p1087\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">css_classes&nbsp;=&nbsp;[],</div></div><div class=\"p1087\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">disabled&nbsp;=&nbsp;False,</div></div><div class=\"p1087\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">extra_x_ranges&nbsp;=&nbsp;{},</div></div><div class=\"p1087\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">extra_x_scales&nbsp;=&nbsp;{},</div></div><div class=\"p1087\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">extra_y_ranges&nbsp;=&nbsp;{},</div></div><div class=\"p1087\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">extra_y_scales&nbsp;=&nbsp;{},</div></div><div class=\"p1087\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">flow_mode&nbsp;=&nbsp;'block',</div></div><div class=\"p1087\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">frame_align&nbsp;=&nbsp;True,</div></div><div class=\"p1087\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">frame_height&nbsp;=&nbsp;None,</div></div><div class=\"p1087\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">frame_width&nbsp;=&nbsp;None,</div></div><div class=\"p1087\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">height&nbsp;=&nbsp;400,</div></div><div class=\"p1087\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">height_policy&nbsp;=&nbsp;'auto',</div></div><div class=\"p1087\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">hidpi&nbsp;=&nbsp;True,</div></div><div class=\"p1087\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">hold_render&nbsp;=&nbsp;False,</div></div><div class=\"p1087\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">js_event_callbacks&nbsp;=&nbsp;{},</div></div><div class=\"p1087\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">js_property_callbacks&nbsp;=&nbsp;{},</div></div><div class=\"p1087\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">left&nbsp;=&nbsp;[LinearAxis(id='p1063', ...)],</div></div><div class=\"p1087\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">lod_factor&nbsp;=&nbsp;10,</div></div><div class=\"p1087\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">lod_interval&nbsp;=&nbsp;300,</div></div><div class=\"p1087\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">lod_threshold&nbsp;=&nbsp;2000,</div></div><div class=\"p1087\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">lod_timeout&nbsp;=&nbsp;500,</div></div><div class=\"p1087\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">margin&nbsp;=&nbsp;None,</div></div><div class=\"p1087\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">match_aspect&nbsp;=&nbsp;False,</div></div><div class=\"p1087\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">max_height&nbsp;=&nbsp;None,</div></div><div class=\"p1087\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">max_width&nbsp;=&nbsp;None,</div></div><div class=\"p1087\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">min_border&nbsp;=&nbsp;5,</div></div><div class=\"p1087\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">min_border_bottom&nbsp;=&nbsp;None,</div></div><div class=\"p1087\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">min_border_left&nbsp;=&nbsp;None,</div></div><div class=\"p1087\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">min_border_right&nbsp;=&nbsp;None,</div></div><div class=\"p1087\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">min_border_top&nbsp;=&nbsp;None,</div></div><div class=\"p1087\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">min_height&nbsp;=&nbsp;None,</div></div><div class=\"p1087\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">min_width&nbsp;=&nbsp;None,</div></div><div class=\"p1087\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">name&nbsp;=&nbsp;None,</div></div><div class=\"p1087\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">outline_line_alpha&nbsp;=&nbsp;1.0,</div></div><div class=\"p1087\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">outline_line_cap&nbsp;=&nbsp;'butt',</div></div><div class=\"p1087\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">outline_line_color&nbsp;=&nbsp;'#e5e5e5',</div></div><div class=\"p1087\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">outline_line_dash&nbsp;=&nbsp;[],</div></div><div class=\"p1087\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">outline_line_dash_offset&nbsp;=&nbsp;0,</div></div><div class=\"p1087\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">outline_line_join&nbsp;=&nbsp;'bevel',</div></div><div class=\"p1087\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">outline_line_width&nbsp;=&nbsp;1,</div></div><div class=\"p1087\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">output_backend&nbsp;=&nbsp;'canvas',</div></div><div class=\"p1087\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">renderers&nbsp;=&nbsp;[GlyphRenderer(id='p1081', ...)],</div></div><div class=\"p1087\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">reset_policy&nbsp;=&nbsp;'standard',</div></div><div class=\"p1087\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">resizable&nbsp;=&nbsp;False,</div></div><div class=\"p1087\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">right&nbsp;=&nbsp;[],</div></div><div class=\"p1087\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">sizing_mode&nbsp;=&nbsp;None,</div></div><div class=\"p1087\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">styles&nbsp;=&nbsp;{},</div></div><div class=\"p1087\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">stylesheets&nbsp;=&nbsp;[],</div></div><div class=\"p1087\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">subscribed_events&nbsp;=&nbsp;PropertyValueSet(),</div></div><div class=\"p1087\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">syncable&nbsp;=&nbsp;True,</div></div><div class=\"p1087\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">tags&nbsp;=&nbsp;[],</div></div><div class=\"p1087\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">title&nbsp;=&nbsp;Title(id='p1054', ...),</div></div><div class=\"p1087\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">title_location&nbsp;=&nbsp;'above',</div></div><div class=\"p1087\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">toolbar&nbsp;=&nbsp;Toolbar(id='p1055', ...),</div></div><div class=\"p1087\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">toolbar_inner&nbsp;=&nbsp;False,</div></div><div class=\"p1087\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">toolbar_location&nbsp;=&nbsp;'right',</div></div><div class=\"p1087\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">toolbar_sticky&nbsp;=&nbsp;True,</div></div><div class=\"p1087\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">visible&nbsp;=&nbsp;True,</div></div><div class=\"p1087\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">width&nbsp;=&nbsp;600,</div></div><div class=\"p1087\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">width_policy&nbsp;=&nbsp;'auto',</div></div><div class=\"p1087\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">x_range&nbsp;=&nbsp;DataRange1d(id='p1048', ...),</div></div><div class=\"p1087\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">x_scale&nbsp;=&nbsp;LinearScale(id='p1056', ...),</div></div><div class=\"p1087\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">y_range&nbsp;=&nbsp;DataRange1d(id='p1049', ...),</div></div><div class=\"p1087\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">y_scale&nbsp;=&nbsp;LinearScale(id='p1057', ...))</div></div></div>\n",
              "<script>\n",
              "(function() {\n",
              "  let expanded = false;\n",
              "  const ellipsis = document.getElementById(\"p1088\");\n",
              "  ellipsis.addEventListener(\"click\", function() {\n",
              "    const rows = document.getElementsByClassName(\"p1087\");\n",
              "    for (let i = 0; i < rows.length; i++) {\n",
              "      const el = rows[i];\n",
              "      el.style.display = expanded ? \"none\" : \"table-row\";\n",
              "    }\n",
              "    ellipsis.innerHTML = expanded ? \"&hellip;)\" : \"&lsaquo;&lsaquo;&lsaquo;\";\n",
              "    expanded = !expanded;\n",
              "  });\n",
              "})();\n",
              "</script>\n"
            ],
            "text/plain": [
              "figure(id='p1047', ...)"
            ]
          },
          "execution_count": 105,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "draw_vectors(phrase_vectors_2d[:, 0], phrase_vectors_2d[:, 1],\n",
        "             phrase=[phrase[:50] for phrase in chosen_phrases],\n",
        "             radius=20,)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qzz7jnvtNh8N"
      },
      "source": [
        "# Application Examples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oEDYH_kfW2qB"
      },
      "source": [
        "Now we gonna play with word embeddings: train our own little embedding with gensim.models package, load one from   gensim model zoo and use it to visualize text corpora.\n",
        "\n",
        "This whole thing is gonna happen on top of embedding dataset.\n",
        "\n",
        "__Requirements:__  `pip install --upgrade nltk gensim bokeh` , but only if you're running locally."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UreyRAMKJBBL"
      },
      "source": [
        "**Revision** of some code that could be missed to session and is useful for further steps:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bPxwymolJMuL"
      },
      "outputs": [],
      "source": [
        "def get_phrase_embedding(model, phrase):\n",
        "    \"\"\"\n",
        "    Convert phrase to a vector by aggregating it's word embeddings. See description above.\n",
        "    \"\"\"\n",
        "    # 1. lowercase phrase\n",
        "    # 2. tokenize phrase\n",
        "    # 3. average word vectors for all words in tokenized phrase\n",
        "    # skip words that are not in model's vocabulary\n",
        "    # if all words are missing from vocabulary, return zeros\n",
        "\n",
        "    vector = np.zeros([model.vector_size], dtype='float32')\n",
        "\n",
        "    phrase = phrase.lower()\n",
        "    tokens = tokenizer.tokenize(phrase)\n",
        "    used_words = 0\n",
        "\n",
        "    for word in tokens:\n",
        "        if word in model:\n",
        "            vector += model[word]\n",
        "            used_words += 1\n",
        "\n",
        "    if used_words > 0:\n",
        "        vector = vector / used_words\n",
        "\n",
        "    return vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Rl1ZXmfJAXl",
        "outputId": "450155fe-dff5-4289-eaa7-e125023e58e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 48.6 s, sys: 565 ms, total: 49.2 s\n",
            "Wall time: 49 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "from gensim.models.keyedvectors import KeyedVectors\n",
        "en_w2v_model = KeyedVectors.load_word2vec_format(\"gensim_glove_vectors.txt\", binary=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4xGWQ4DdxUV"
      },
      "source": [
        "### Search of Similar Reviews"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Yjo7LwCd8Nd"
      },
      "source": [
        "In case of kernel reconnection, for the data and preprocessing return to the **Count-based models: Data preparation** section."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R4240oTwd6pG"
      },
      "outputs": [],
      "source": [
        "from scipy.spatial.distance import cosine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dUAoLc8OeR9f"
      },
      "outputs": [],
      "source": [
        "def cosine_similarity_w2v(model, df, k, query):\n",
        "    \"\"\"\n",
        "    Search of the top-k similar texts from documents collection to the query based on cosine similarity.\n",
        "    However, now the vectors are calculated based on w2v representation of tokens.\n",
        "\n",
        "    collection: list of texts;\n",
        "    k: int, length of the result;\n",
        "    query: str, your text.\n",
        "\n",
        "    Return: list of most similar texts to the query;\n",
        "          each element of the list is prepresented as a tuple: (text_idx, sim_score)\n",
        "    \"\"\"\n",
        "\n",
        "    query2vec = get_phrase_embedding(model, query)\n",
        "\n",
        "    similarities = []\n",
        "    for index, row in df.iterrows():\n",
        "        similarities.append((index, cosine(query2vec, get_phrase_embedding(model, row['Processed Review']))))\n",
        "\n",
        "    similarities.sort(key=lambda tup: tup[1], reverse=True)\n",
        "    result = similarities[:k]\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "9dLEpAqNfIuf",
        "outputId": "61847fc8-824f-4f16-930e-a43a025178ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Query:  I really wanted this to work. alas, it had a strange fit for me. the straps would not stay up, and it had a weird fit under the breast. it worked standing up, but the minute i sat down it fell off my shoulders. the fabric was beautiful! and i loved that it had pockets. \n",
            "\n",
            "Index:  317  Similarity:  0.672203928232193  Text:  This dress is adorable. dress it up or dress it down\n",
            "Index:  440  Similarity:  0.584073930978775  Text:  Love the pattern of this tunic. it's comfy and unique.\n",
            "Index:  495  Similarity:  0.5620391368865967  Text:  Horrible fit. i do not understand why they but a aline dress with a skin non aline camisole under the dress.\n",
            "Index:  254  Similarity:  0.4566788077354431  Text:  Easy to take this dress from casual to dressy! super comfortable and cute!\n",
            "Index:  487  Similarity:  0.4554866552352905  Text:  This dress is great. wear now and into fall with boots and leggings. it seems to have structure with the seams and is nicley flowy.\n",
            "Index:  127  Similarity:  0.4473121166229248  Text:  Super cute, flowy, and flattering. i would buy again in a heartbeat.\n",
            "Index:  488  Similarity:  0.4450269341468811  Text:  This dress can be casual, or you can dress it up for going out. i just love this dress!\n",
            "Index:  875  Similarity:  0.4443308115005493  Text:  The turquoise print is absolutely stunning. i love the feel of the fabric, the drape\n",
            "Index:  771  Similarity:  0.43824678659439087  Text:  Bought this dress for an indian wedding- it was perfect!\n",
            "Index:  912  Similarity:  0.43698960542678833  Text:  This dress is versatile and cute! i purchased the xxs at 5'4\" 115lbs and it fit perfect. a steal at the sale price!\n"
          ]
        }
      ],
      "source": [
        "query = reviews_pr.iloc[0]['Review Text']\n",
        "print(\"Query: \", query, \"\\n\")\n",
        "\n",
        "result = cosine_similarity_w2v(en_w2v_model, reviews_pr, 10, query)\n",
        "\n",
        "for (text_idx, sim_score) in result:\n",
        "    print(\"Index: \", text_idx, \" Similarity: \", sim_score, \" Text: \", reviews_pr.iloc[text_idx][\"Review Text\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8Va31sdfrsh"
      },
      "source": [
        "Your conclusion: which method is better?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frvT-QoqvzYb"
      },
      "source": [
        "One more improvement that can be made: **w2v representation weighted with tf-idf score**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XldgMkeY2BiH"
      },
      "outputs": [],
      "source": [
        "dict_idf = dict(zip(vectorizer.get_feature_names_out(), list(vectorizer.idf_)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jivN68RRwGp3"
      },
      "outputs": [],
      "source": [
        "def get_phrase_embedding_w2v_tfidf(model, phrase, dict_idf):\n",
        "    \"\"\"\n",
        "    Convert phrase to a vector by aggregating it's word embeddings weighted with tf-idf score.\n",
        "    \"\"\"\n",
        "\n",
        "    vector = np.zeros([model.vector_size], dtype='float32')\n",
        "\n",
        "    phrase = phrase.lower()\n",
        "    tokens = tokenizer.tokenize(phrase)\n",
        "\n",
        "    weighted_sum = 0\n",
        "\n",
        "    for word in tokens:\n",
        "        if word in model and word in dict_idf.keys():\n",
        "            tf_idf = (tokens.count(word)/len(tokens)) * dict_idf[word]\n",
        "            vector += model[word] * tf_idf\n",
        "            weighted_sum += tf_idf\n",
        "\n",
        "    if weighted_sum > 0:\n",
        "        vector = vector / weighted_sum\n",
        "\n",
        "    return vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9k1ok-6jyz5l"
      },
      "outputs": [],
      "source": [
        "def cosine_similarity_w2v_tfidf(model, df, k, query, dict_idf):\n",
        "    \"\"\"\n",
        "    Search of the top-k similar texts from documents collection to the query based on cosine similarity.\n",
        "    However, now the vectors are calculated based on WEIGHTED with tfidf w2v representation of tokens.\n",
        "\n",
        "    collection: list of texts;\n",
        "    k: int, length of the result;\n",
        "    query: str, your text;\n",
        "    dict_idf: IDF of tokens;\n",
        "\n",
        "    Return: list of most similar texts to the query;\n",
        "          each element of the list is prepresented as a tuple: (text_idx, sim_score)\n",
        "    \"\"\"\n",
        "\n",
        "    query2vec = get_phrase_embedding_w2v_tfidf(model, query, dict_idf)\n",
        "\n",
        "    similarities = []\n",
        "    for index, row in df.iterrows():\n",
        "        similarities.append((index, cosine(query2vec, get_phrase_embedding(model, row['Processed Review']))))\n",
        "\n",
        "    similarities.sort(key=lambda tup: tup[1], reverse=True)\n",
        "    result = similarities[:k]\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vc9_bls-zCR2",
        "outputId": "d45efa4c-0e65-4cd7-e84c-d8efc2908712"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Query:  I really wanted this to work. alas, it had a strange fit for me. the straps would not stay up, and it had a weird fit under the breast. it worked standing up, but the minute i sat down it fell off my shoulders. the fabric was beautiful! and i loved that it had pockets. \n",
            "\n",
            "Index:  317  Similarity:  0.6033726334571838  Text:  This dress is adorable. dress it up or dress it down\n",
            "Index:  440  Similarity:  0.5167878568172455  Text:  Love the pattern of this tunic. it's comfy and unique.\n",
            "Index:  771  Similarity:  0.46498554944992065  Text:  Bought this dress for an indian wedding- it was perfect!\n",
            "Index:  495  Similarity:  0.44923317432403564  Text:  Horrible fit. i do not understand why they but a aline dress with a skin non aline camisole under the dress.\n",
            "Index:  488  Similarity:  0.4249442219734192  Text:  This dress can be casual, or you can dress it up for going out. i just love this dress!\n",
            "Index:  673  Similarity:  0.41793370246887207  Text:  Love this dress and the color\n",
            "Index:  748  Similarity:  0.4133181571960449  Text:  This dress is effortlessly chic. i wore it with black tights and booties and it was perfection. will definitely be a casual staple year around.\n",
            "Index:  649  Similarity:  0.40699338912963867  Text:  This tunic is lovely and versatile. looks great over a pair of jeans or as a dress!\n",
            "Index:  912  Similarity:  0.4059448838233948  Text:  This dress is versatile and cute! i purchased the xxs at 5'4\" 115lbs and it fit perfect. a steal at the sale price!\n",
            "Index:  400  Similarity:  0.4055953025817871  Text:  Love this dress! light and breezy, but i'm wearing it with tights and a jacket for a winter look.\n"
          ]
        }
      ],
      "source": [
        "query = reviews_pr.iloc[0]['Review Text']\n",
        "print(\"Query: \", query, \"\\n\")\n",
        "\n",
        "result = cosine_similarity_w2v_tfidf(en_w2v_model, reviews_pr, 10, query, dict_idf)\n",
        "\n",
        "for (text_idx, sim_score) in result:\n",
        "    print(\"Index: \", text_idx, \" Similarity: \", sim_score, \" Text: \", reviews_pr.iloc[text_idx][\"Review Text\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONaQn791Ugpr"
      },
      "source": [
        "Finally, which model works the best?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9Eva1R0n5bt"
      },
      "source": [
        "### Simple Question Answering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1z0DItFoFM3"
      },
      "source": [
        "We use phrase embeddings from the previous section."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YUgDIIhKeaCC"
      },
      "outputs": [],
      "source": [
        "# in case you session crashed\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from nltk.tokenize import WordPunctTokenizer\n",
        "tokenizer = WordPunctTokenizer()\n",
        "\n",
        "data = list(open(\"./quora.txt\", encoding=\"utf-8\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Wd17tPz4VGs4",
        "outputId": "a225d2cd-4f02-4d73-c88e-f1570afe7814"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"Can I get back with my ex even though she is pregnant with another guy's baby?\\n\""
            ]
          },
          "execution_count": 124,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "id": "a9KHGZYAoAdM",
        "outputId": "f0db3415-c644-4e19-b3d7-2f4ac7ec4c7c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 16.4 s, sys: 1.2 s, total: 17.6 s\n",
            "Wall time: 16.7 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "# compute vector embedding for all lines in data\n",
        "data_vectors = np.array([get_phrase_embedding(en_w2v_model, l) for l in data])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OuKoNoC7oEbl"
      },
      "outputs": [],
      "source": [
        "def find_nearest(model, query, k=10):\n",
        "    \"\"\"\n",
        "    given text line (query), return k most similar lines from data, sorted from most to least similar\n",
        "    similarity should be measured as cosine between query and line embedding vectors\n",
        "    hint: it's okay to use global variables: data and data_vectors. see also: np.argpartition, np.argsort\n",
        "    \"\"\"\n",
        "    ### SOLUTION ###\n",
        "    from sklearn.metrics.pairwise import cosine_similarity\n",
        "    from scipy.spatial import distance\n",
        "\n",
        "    query_emb = get_phrase_embedding(model, query)\n",
        "    distances = distance.cdist([query_emb], data_vectors, \"cosine\")[0]\n",
        "    ranged_vectors = np.argsort(distances)\n",
        "    ### SOLUTION ###\n",
        "\n",
        "    return [data[index] for index in ranged_vectors[:k]] #SOLUTION <YOUR CODE: top-k lines starting from most similar>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 150
        },
        "id": "dFwdXbKJqYzk",
        "outputId": "3a15410c-d520-4f4d-a6c2-fb9c45329d12"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 415 ms, sys: 305 ms, total: 720 ms\n",
            "Wall time: 719 ms\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['How do I do a matrix transpose in Go?\\n',\n",
              " 'Do you live in the matrix? Why?\\n',\n",
              " 'How can I do the impossible?\\n',\n",
              " 'How do you define the one?\\n',\n",
              " 'How can I do the right thing?\\n',\n",
              " 'How can I become the best in everything I do?\\n',\n",
              " 'How do you know if you are in the friendzone?\\n',\n",
              " 'If I want to start writing, where do I begin? How can I learn the structure of what I want to write?\\n',\n",
              " 'What can I do in the future?\\n',\n",
              " 'How do I can get .in domain?\\n']"
            ]
          },
          "execution_count": 127,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "find_nearest(en_w2v_model, query=\"How do i enter the matrix?\", k=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "id": "Jm7TxqmcqbTL",
        "outputId": "d3fd5431-f496-443a-beab-36870745ca65"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['What does Tiffany Trump do?\\n',\n",
              " 'How would you describe Donald Trump?\\n',\n",
              " 'What is Trump?\\n',\n",
              " 'Do you like Trump?\\n',\n",
              " 'Why does everybody hate Trump?\\n',\n",
              " 'How does it feel to date Ivanka Trump?\\n',\n",
              " 'What do you think Melania Trump really thinks of Donald?\\n',\n",
              " 'What do you think about Donald trump?\\n',\n",
              " 'What do you think about Donald Trump?\\n',\n",
              " 'Why is Trump bad?\\n']"
            ]
          },
          "execution_count": 128,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "find_nearest(en_w2v_model, query=\"How does Trump?\", k=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PR0xXnOZqdX6",
        "outputId": "1de748db-1957-4861-9d0c-f24240980e06"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[\"Why I don't believe in myself?\\n\",\n",
              " \"Why I don't get any answer on my question?\\n\",\n",
              " \"Why don't I get a job call?\\n\",\n",
              " \"How do I ask a girl I don't know to fuck?\\n\",\n",
              " \"Why don't I get a date?\\n\",\n",
              " \"Can I ask a girl out that I don't know?\\n\",\n",
              " \"Why do you always answer a question with a question? I don't, or do I?\\n\",\n",
              " \"Why don't I feel like talking to anyone?\\n\",\n",
              " \"Why do I love someone I don't know?\\n\",\n",
              " \"Why don't I get a girlfriend?\\n\"]"
            ]
          },
          "execution_count": 129,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "find_nearest(en_w2v_model, query=\"Why don't i ask a question myself?\", k=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dosdr9TfkAoy"
      },
      "source": [
        "More advanced vector indexing: [FAISS](https://github.com/facebookresearch/faiss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3UAVSS-OF_p"
      },
      "source": [
        "### Simple Machine Translation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yd-hgLThVaUY"
      },
      "source": [
        "Adopted from original material by YSDA."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbHpP6_dqokl"
      },
      "source": [
        "(_синій кіт_ vs. _синій кит_)\n",
        "\n",
        "![blue_cat_blue_whale.png](https://github.com/yandexdataschool/nlp_course/raw/master/resources/blue_cat_blue_whale.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9mIllDF3TkzI"
      },
      "source": [
        "**Frament of the Swadesh list for some slavic languages**\n",
        "\n",
        "The Swadesh list is a lexicostatistical stuff. It's named after American linguist Morris Swadesh and contains basic lexis. This list are used to define subgroupings of languages, its relatedness.\n",
        "\n",
        "So we can see some kind of word invariance for different Slavic languages.\n",
        "\n",
        "\n",
        "| Russian         | Belorussian              | Ukrainian               | Polish             | Czech                         | Bulgarian            |\n",
        "|-----------------|--------------------------|-------------------------|--------------------|-------------------------------|-----------------------|\n",
        "| женщина         | жанчына, кабета, баба    | жінка                   | kobieta            | žena                          | жена                  |\n",
        "| мужчина         | мужчына                  | чоловік, мужчина        | mężczyzna          | muž                           | мъж                   |\n",
        "| человек         | чалавек                  | людина, чоловік         | człowiek           | člověk                        | човек                 |\n",
        "| ребёнок, дитя   | дзіця, дзіцёнак, немаўля | дитина, дитя            | dziecko            | dítě                          | дете                  |\n",
        "| жена            | жонка                    | дружина, жінка          | żona               | žena, manželka, choť          | съпруга, жена         |\n",
        "| муж             | муж, гаспадар            | чоловiк, муж            | mąż                | muž, manžel, choť             | съпруг, мъж           |\n",
        "| мать, мама      | маці, матка              | мати, матір, неня, мама | matka              | matka, máma, 'стар.' mateř    | майка                 |\n",
        "| отец, тятя      | бацька, тата             | батько, тато, татусь    | ojciec             | otec                          | баща, татко           |\n",
        "| много           | шмат, багата             | багато                  | wiele              | mnoho, hodně                  | много                 |\n",
        "| несколько       | некалькі, колькі         | декілька, кілька        | kilka              | několik, pár, trocha          | няколко               |\n",
        "| другой, иной    | іншы                     | інший                   | inny               | druhý, jiný                   | друг                  |\n",
        "| зверь, животное | жывёла, звер, істота     | тварина, звір           | zwierzę            | zvíře                         | животно               |\n",
        "| рыба            | рыба                     | риба                    | ryba               | ryba                          | риба                  |\n",
        "| птица           | птушка                   | птах, птиця             | ptak               | pták                          | птица                 |\n",
        "| собака, пёс     | сабака                   | собака, пес             | pies               | pes                           | куче, пес             |\n",
        "| вошь            | вош                      | воша                    | wesz               | veš                           | въшка                 |\n",
        "| змея, гад       | змяя                     | змія, гад               | wąż                | had                           | змия                  |\n",
        "| червь, червяк   | чарвяк                   | хробак, черв'як         | robak              | červ                          | червей                |\n",
        "| дерево          | дрэва                    | дерево                  | drzewo             | strom, dřevo                  | дърво                 |\n",
        "| лес             | лес                      | ліс                     | las                | les                           | гора, лес             |\n",
        "| палка           | кій, палка               | палиця                  | patyk, pręt, pałka | hůl, klacek, prut, kůl, pálka | палка, пръчка, бастун |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VHJGHpIT0QQ"
      },
      "source": [
        "#### Data preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZVX1vL-1T2gS"
      },
      "outputs": [],
      "source": [
        "import gensim\n",
        "import numpy as np\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "import requests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pKWlZ90mT7Vh"
      },
      "source": [
        "Download all files using code below (if it doesn't work for some reason copy can be found here):\n",
        "\n",
        "Embeddings:\n",
        "* [cc.uk.300.vec.zip](https://yadi.sk/d/9CAeNsJiInoyUA)\n",
        "* [cc.ru.300.vec.zip](https://yadi.sk/d/3yG0-M4M8fypeQ)\n",
        "\n",
        "Corpuses of ukr-rus words' pairs:\n",
        "* [ukr_rus.test.txt](https://yadi.sk/i/uViaQLmdBy0Hag)\n",
        "* [ukr_rus.train.txt](https://yadi.sk/i/PEgqqvG1po-L9Q)\n",
        "\n",
        "Fairy tale for translation test:\n",
        "* [fairy_tale.txt](https://yadi.sk/d/baqp13Nb2QEoEw)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HtFYvu72UFe2",
        "outputId": "e20bc6fe-fd00-4f52-dc1b-fe1ff76d1654"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2022-11-21 22:20:29--  http://panchenko.me/slides/nnlp/data/cc.ru.300.vec.zip\n",
            "Resolving panchenko.me (panchenko.me)... 130.104.253.4\n",
            "Connecting to panchenko.me (panchenko.me)|130.104.253.4|:80... connected.\n",
            "HTTP request sent, awaiting response... 404 Not Found\n",
            "2022-11-21 22:20:29 ERROR 404: Not Found.\n",
            "\n",
            "unzip:  cannot find or open cc.ru.300.vec.zip, cc.ru.300.vec.zip.zip or cc.ru.300.vec.zip.ZIP.\n",
            "--2022-11-21 22:20:29--  http://panchenko.me/slides/nnlp/data/cc.uk.300.vec.zip\n",
            "Resolving panchenko.me (panchenko.me)... 130.104.253.4\n",
            "Connecting to panchenko.me (panchenko.me)|130.104.253.4|:80... connected.\n",
            "HTTP request sent, awaiting response... 404 Not Found\n",
            "2022-11-21 22:20:30 ERROR 404: Not Found.\n",
            "\n",
            "unzip:  cannot find or open cc.uk.300.vec.zip, cc.uk.300.vec.zip.zip or cc.uk.300.vec.zip.ZIP.\n",
            "--2022-11-21 22:20:30--  http://panchenko.me/slides/nnlp/data/ukr_rus.train.txt\n",
            "Resolving panchenko.me (panchenko.me)... 130.104.253.4\n",
            "Connecting to panchenko.me (panchenko.me)|130.104.253.4|:80... connected.\n",
            "HTTP request sent, awaiting response... 404 Not Found\n",
            "2022-11-21 22:20:30 ERROR 404: Not Found.\n",
            "\n",
            "--2022-11-21 22:20:30--  http://panchenko.me/slides/nnlp/data/ukr_rus.test.txt\n",
            "Resolving panchenko.me (panchenko.me)... 130.104.253.4\n",
            "Connecting to panchenko.me (panchenko.me)|130.104.253.4|:80... connected.\n",
            "HTTP request sent, awaiting response... 404 Not Found\n",
            "2022-11-21 22:20:30 ERROR 404: Not Found.\n",
            "\n",
            "--2022-11-21 22:20:31--  http://panchenko.me/slides/nnlp/data/fairy_tale.txt\n",
            "Resolving panchenko.me (panchenko.me)... 130.104.253.4\n",
            "Connecting to panchenko.me (panchenko.me)|130.104.253.4|:80... connected.\n",
            "HTTP request sent, awaiting response... 404 Not Found\n",
            "2022-11-21 22:20:31 ERROR 404: Not Found.\n",
            "\n",
            "CPU times: user 75 ms, sys: 62.1 ms, total: 137 ms\n",
            "Wall time: 1.95 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.ru.300.vec.gz\n",
        "!gunzip cc.ru.300.vec.gz\n",
        "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.uk.300.vec.gz\n",
        "!gunzip cc.uk.300.vec.gz\n",
        "!wget https://raw.githubusercontent.com/yandexdataschool/nlp_course/2022/week01_embeddings/ukr_rus.train.txt\n",
        "!wget https://raw.githubusercontent.com/yandexdataschool/nlp_course/2022/week01_embeddings/ukr_rus.test.txt\n",
        "!wget https://raw.githubusercontent.com/yandexdataschool/nlp_course/2022/week01_embeddings/fairy_tale.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "id": "BWRH9zPKUK5b",
        "outputId": "76dbe6a0-1f6c-4e94-e6f9-220edc1146c5"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mload_word2vec_format\u001b[0;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype)\u001b[0m\n\u001b[1;32m   1436\u001b[0m         return _load_word2vec_format(\n\u001b[1;32m   1437\u001b[0m             \u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfvocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0municode_errors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0municode_errors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1438\u001b[0;31m             limit=limit, datatype=datatype)\n\u001b[0m\u001b[1;32m   1439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1440\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_keras_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_embeddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/models/utils_any2vec.py\u001b[0m in \u001b[0;36m_load_word2vec_format\u001b[0;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loading projection weights from %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msmart_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m         \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_unicode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvector_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# throws for invalid file format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/smart_open/smart_open_lib.py\u001b[0m in \u001b[0;36msmart_open\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    496\u001b[0m     \u001b[0mignore_ext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mignore_extension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_extension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mlocals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/smart_open/smart_open_lib.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(uri, mode, buffering, encoding, errors, newline, closefd, opener, ignore_ext, compression, transport_params)\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnewline\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m     )\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/smart_open/smart_open_lib.py\u001b[0m in \u001b[0;36m_shortcut_open\u001b[0;34m(uri, mode, compression, buffering, encoding, errors, newline)\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[0mopen_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'errors'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 361\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_builtin_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffering\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mopen_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'cc.uk.300.vec'"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "uk_emb = KeyedVectors.load_word2vec_format(\"cc.uk.300.vec\")\n",
        "ru_emb = KeyedVectors.load_word2vec_format(\"cc.ru.300.vec\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qydrF63eUM5i"
      },
      "outputs": [],
      "source": [
        "ru_emb.most_similar([ru_emb[\"август\"]], topn=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oBIg3G3wUPMs"
      },
      "outputs": [],
      "source": [
        "uk_emb.most_similar([uk_emb[\"серпень\"]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HJejWCJXUSbK"
      },
      "outputs": [],
      "source": [
        "ru_emb.most_similar([uk_emb[\"серпень\"]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YrIuOV04UaSr"
      },
      "source": [
        "Load small dictionaries for correspoinding words pairs as trainset and testset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dlj5eh2iUby8"
      },
      "outputs": [],
      "source": [
        "def load_word_pairs(filename):\n",
        "    uk_ru_pairs = []\n",
        "    uk_vectors = []\n",
        "    ru_vectors = []\n",
        "    with open(filename, \"r\") as inpf:\n",
        "        for line in inpf:\n",
        "            uk, ru = line.rstrip().split(\"\\t\")\n",
        "            if uk not in uk_emb or ru not in ru_emb:\n",
        "                continue\n",
        "            uk_ru_pairs.append((uk, ru))\n",
        "            uk_vectors.append(uk_emb[uk])\n",
        "            ru_vectors.append(ru_emb[ru])\n",
        "    return uk_ru_pairs, np.array(uk_vectors), np.array(ru_vectors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BHdfPf-pUfqs"
      },
      "outputs": [],
      "source": [
        "uk_ru_train, X_train, Y_train = load_word_pairs(\"ukr_rus.train.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jdUSZ91vUgLE"
      },
      "outputs": [],
      "source": [
        "uk_ru_test, X_test, Y_test = load_word_pairs(\"ukr_rus.test.txt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNFKe4RFUiM4"
      },
      "source": [
        "#### Embedding space mapping"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3YIYlBkUtgb"
      },
      "source": [
        "Let $x_i \\in \\mathrm{R}^d$ be the distributed representation of word $i$ in the source language, and $y_i \\in \\mathrm{R}^d$ is the vector representation of its translation. Our purpose is to learn such linear transform $W$ that minimizes euclidian distance between $Wx_i$ and $y_i$ for some subset of word embeddings. Thus we can formulate so-called Procrustes problem:\n",
        "\n",
        "$$W^*= \\arg\\min_W \\sum_{i=1}^n||Wx_i - y_i||_2$$\n",
        "or\n",
        "$$W^*= \\arg\\min_W ||WX - Y||_F$$\n",
        "\n",
        "where $||*||_F$ - Frobenius norm.\n",
        "\n",
        "In Greek mythology, Procrustes or \"the stretcher\" was a rogue smith and bandit from Attica who attacked people by stretching them or cutting off their legs, so as to force them to fit the size of an iron bed. We make same bad things with source embedding space. Our Procrustean bed is target embedding space."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BC0ZhWvwUwxB"
      },
      "source": [
        "![embedding_mapping.png](https://github.com/yandexdataschool/nlp_course/raw/master/resources/embedding_mapping.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3akGpNz0UzrE"
      },
      "source": [
        "![procrustes.png](https://github.com/yandexdataschool/nlp_course/raw/master/resources/procrustes.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HJHaDAfU2wz"
      },
      "source": [
        "But wait...$W^*= \\arg\\min_W \\sum_{i=1}^n||Wx_i - y_i||_2$ looks like simple multiple linear regression (without intercept fit). So let's code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X-Ms2BJpU5MT"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "mapping = LinearRegression().fit(X_train, Y_train) # SOLUTION\n",
        "mapping.score(X_train, Y_train) # SOLUTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CKFy7x21U7KK"
      },
      "outputs": [],
      "source": [
        "august = mapping.predict(uk_emb[\"серпень\"].reshape(1, -1))\n",
        "ru_emb.most_similar(august)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5_gfTKAU-6P"
      },
      "source": [
        "We can see that neighbourhood of this embedding cosists of different months, but right variant is on the ninth place."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJnKkjcUVBir"
      },
      "source": [
        "As quality measure we will use precision top-1, top-5 and top-10 (for each transformed Ukrainian embedding we count how many right target pairs are found in top N nearest neighbours in Russian embedding space)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNYeyxTBVE_Z"
      },
      "source": [
        "#### Score the solution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MBpdCl6VVIpz"
      },
      "outputs": [],
      "source": [
        "def precision(pairs, mapped_vectors, topn=1):\n",
        "    \"\"\"\n",
        "    :args:\n",
        "        pairs = list of right word pairs [(uk_word_0, ru_word_0), ...]\n",
        "        mapped_vectors = list of embeddings after mapping from source embedding space to destination embedding space\n",
        "        topn = the number of nearest neighbours in destination embedding space to choose from\n",
        "    :returns:\n",
        "        precision_val, float number, total number of words for those we can find right translation at top K.\n",
        "    \"\"\"\n",
        "    assert len(pairs) == len(mapped_vectors)\n",
        "    num_matches = 0\n",
        "    similar_vectors = [ru_emb.most_similar([mapped_vector]) for mapped_vector in mapped_vectors] # SOLUTION\n",
        "\n",
        "    for i, (_, ru) in enumerate(pairs):\n",
        "        ### SOLUTION ###\n",
        "        if ru in [el[0] for el in similar_vectors[i]][:topn]:\n",
        "            num_matches += 1\n",
        "        ### SOLUTION ###\n",
        "    precision_val = num_matches / len(pairs)\n",
        "    return precision_val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZtJtPVBDVLTQ"
      },
      "outputs": [],
      "source": [
        "assert precision([(\"серпень\", \"август\")], august, topn=5) == 0.0\n",
        "assert precision([(\"серпень\", \"август\")], august, topn=9) == 1.0\n",
        "assert precision([(\"серпень\", \"август\")], august, topn=10) == 1.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Ux0CoDCVNRD"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "assert precision(uk_ru_test, X_test) == 0.0\n",
        "assert precision(uk_ru_test, Y_test) == 1.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JXhg1cnHVPRx"
      },
      "outputs": [],
      "source": [
        "precision_top1 = precision(uk_ru_test, mapping.predict(X_test), 1)\n",
        "precision_top5 = precision(uk_ru_test, mapping.predict(X_test), 5)\n",
        "\n",
        "assert precision_top1 >= 0.635\n",
        "assert precision_top5 >= 0.810"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3m65fDLVRsc"
      },
      "source": [
        "#### Make it better (orthogonal Procrustean problem)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ShJ8kzkPVY8R"
      },
      "source": [
        "It can be shown (see original paper) that a self-consistent linear mapping between semantic spaces should be orthogonal.\n",
        "We can restrict transform $W$ to be orthogonal. Then we will solve next problem:\n",
        "\n",
        "$$W^*= \\arg\\min_W ||WX - Y||_F \\text{, where: } W^TW = I$$\n",
        "\n",
        "$$I \\text{- identity matrix}$$\n",
        "\n",
        "Instead of making yet another regression problem we can find optimal orthogonal transformation using singular value decomposition. It turns out that optimal transformation $W^*$ can be expressed via SVD components:\n",
        "$$X^TY=U\\Sigma V^T\\text{, singular value decompostion}$$\n",
        "$$W^*=UV^T$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UZvhsz3eVgd8"
      },
      "outputs": [],
      "source": [
        "def learn_transform(X_train, Y_train):\n",
        "    \"\"\"\n",
        "    :returns: W* : float matrix[emb_dim x emb_dim] as defined in formulae above\n",
        "    \"\"\"\n",
        "    ### SOLUTION ###\n",
        "    U, s, Vt = np.linalg.svd(np.matmul(X_train.transpose(), Y_train))\n",
        "\n",
        "    return np.matmul(U, Vt)\n",
        "    ### SOLUTION ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "isw7WmMIVia5"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "W = learn_transform(X_train, Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BaR9RIJOVkGn"
      },
      "outputs": [],
      "source": [
        "ru_emb.most_similar([np.matmul(uk_emb[\"серпень\"], W)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TNn7XD7GVmVc"
      },
      "outputs": [],
      "source": [
        "assert precision(uk_ru_test, np.matmul(X_test, W)) >= 0.653\n",
        "assert precision(uk_ru_test, np.matmul(X_test, W), 5) >= 0.824"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZYgBIdIVoR2"
      },
      "source": [
        "#### Translation engine"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cdQf9lVVw0t"
      },
      "source": [
        "Now we are ready to make simple word-based translator: for earch word in source language in shared embedding space we find the nearest in target language."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3spIgJuFVtEX"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import WordPunctTokenizer\n",
        "tokenizer = WordPunctTokenizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5gbuVLMIVznw"
      },
      "outputs": [],
      "source": [
        "with open(\"fairy_tale.txt\", \"r\") as inpf:\n",
        "    uk_sentences = [line.rstrip().lower() for line in inpf]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zeJeYMy4V225"
      },
      "outputs": [],
      "source": [
        "def translate(sentence):\n",
        "    \"\"\"\n",
        "    :args:\n",
        "        sentence - sentence in Ukrainian (str)\n",
        "    :returns:\n",
        "        translation - sentence in Russian (str)\n",
        "\n",
        "    * find ukrainian embedding for each word in sentence\n",
        "    * transform ukrainian embedding vector\n",
        "    * find nearest russian word and replace\n",
        "    \"\"\"\n",
        "    ### SOLUTION ###\n",
        "    result = []\n",
        "\n",
        "    for word in tokenizer.tokenize(sentence):\n",
        "        if word not in uk_emb:\n",
        "            result.append(word)\n",
        "            continue\n",
        "        word_emb = uk_emb[word]\n",
        "        word_translation = ru_emb.most_similar([np.matmul(word_emb, W)])[0][0]\n",
        "        result.append(word_translation)\n",
        "\n",
        "    return ' '.join(result)\n",
        "    ### SOLUTION ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NUR2QPxcV4-S"
      },
      "outputs": [],
      "source": [
        "assert translate(\".\") == \".\"\n",
        "assert translate(\"1 , 3\") == \"1 , 3\"\n",
        "assert translate(\"кіт зловив мишу\") == \"кот поймал мышку\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WnrdZXzYV_LF"
      },
      "outputs": [],
      "source": [
        "for sentence in uk_sentences:\n",
        "    print(\"src: {}\\ndst: {}\\n\".format(sentence, translate(sentence)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oPp2_tv0WBsA"
      },
      "source": [
        "Not so bad, right? We can easily improve translation using language model and not one but several nearest neighbours in shared embedding space. But next time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7hZR0LSNYq2"
      },
      "source": [
        "# Bonus: Doc2Vec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwjmjK_VWr3K"
      },
      "source": [
        "<img src=\"https://github.com/dardem/word2vec_seminar/raw/master/img/doc2vec.png\" style=\"width:100%\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWtZ40zVW1bJ"
      },
      "source": [
        "The straightforward approach of averaging each of a text's words' word-vectors creates a quick and crude document-vector that can often be useful. However, Le and Mikolov in 2014 introduced the <i>Paragraph Vector</i>, which usually outperforms such simple-averaging.\n",
        "\n",
        "The basic idea is: act as if a document has another floating word-like vector, which contributes to all training predictions, and is updated like other word-vectors, but we will call it a doc-vector. Gensim's `Doc2Vec` class implements this algorithm.\n",
        "\n",
        "**Paragraph Vector - Distributed Memory (PV-DM)**\n",
        "This is the Paragraph Vector model analogous to Word2Vec CBOW. The doc-vectors are obtained by training a neural network on the synthetic task of predicting a center word based an average of both context word-vectors and the full document's doc-vector.\n",
        "\n",
        "**Paragraph Vector - Distributed Bag of Words (PV-DBOW)**\n",
        "This is the Paragraph Vector model analogous to Word2Vec SG. The doc-vectors are obtained by training a neural network on the synthetic task of predicting a target word just from the full document's doc-vector. (It is also common to combine this with skip-gram testing, using both the doc-vector and nearby word-vectors to predict a single target word, but only one at a time.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KmSRoDezW77W"
      },
      "source": [
        "### Requirements"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUHx2ld-W-5P"
      },
      "source": [
        "The following python modules are dependencies for this tutorial:\n",
        "* testfixtures ( `pip install testfixtures` )\n",
        "* statsmodels ( `pip install statsmodels` )\n",
        "\n",
        "Let's download the IMDB archive if it is not already downloaded (84 MB). This will be our text data for this tutorial.   \n",
        "The data can be found here: http://ai.stanford.edu/~amaas/data/sentiment/\n",
        "\n",
        "This cell will only reattempt steps (such as downloading the compressed data) if their output isn't already present, so it is safe to re-run until it completes successfully."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8GQaWaAGKoke"
      },
      "outputs": [],
      "source": [
        "# !pip install testfixtures\n",
        "# !pip install statsmodels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gfE2gJCXOOS"
      },
      "source": [
        "### Data preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2OOCVaJrXL0E",
        "outputId": "9be46dbe-de3b-46ab-875d-31525992dd40"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading IMDB archive...\n",
            "CPU times: user 136 ms, sys: 370 ms, total: 507 ms\n",
            "Wall time: 7.8 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "import locale\n",
        "import glob\n",
        "import os.path\n",
        "import requests\n",
        "import tarfile\n",
        "import sys\n",
        "import codecs\n",
        "import re\n",
        "\n",
        "dirname = 'aclImdb'\n",
        "filename = 'aclImdb_v1.tar.gz'\n",
        "locale.setlocale(locale.LC_ALL, 'C')\n",
        "all_lines = []\n",
        "\n",
        "if sys.version > '3':\n",
        "    control_chars = [chr(0x85)]\n",
        "else:\n",
        "    control_chars = [unichr(0x85)]\n",
        "\n",
        "# Convert text to lower-case and strip punctuation/symbols from words\n",
        "def normalize_text(text):\n",
        "    norm_text = text.lower()\n",
        "    # Replace breaks with spaces\n",
        "    norm_text = norm_text.replace('<br />', ' ')\n",
        "    # Pad punctuation with spaces on both sides\n",
        "    norm_text = re.sub(r\"([\\.\\\",\\(\\)!\\?;:])\", \" \\\\1 \", norm_text)\n",
        "    return norm_text\n",
        "\n",
        "\n",
        "# Download IMDB archive\n",
        "print(\"Downloading IMDB archive...\")\n",
        "url = u'http://ai.stanford.edu/~amaas/data/sentiment/' + filename\n",
        "r = requests.get(url, stream=True)\n",
        "with open(filename, 'wb') as f:\n",
        "    f.write(r.raw.read())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "_JKawIUfXVtu",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "fc36069d-ba06-4d94-ad20-9805e9afab9b",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "aclImdb/train/unsup/44983_0.txt\n",
            "aclImdb/train/unsup/44982_0.txt\n",
            "aclImdb/train/unsup/44981_0.txt\n",
            "aclImdb/train/unsup/44980_0.txt\n",
            "aclImdb/train/unsup/44979_0.txt\n",
            "aclImdb/train/unsup/44978_0.txt\n",
            "aclImdb/train/unsup/44977_0.txt\n",
            "aclImdb/train/unsup/44976_0.txt\n",
            "aclImdb/train/unsup/44975_0.txt\n",
            "aclImdb/train/unsup/44974_0.txt\n",
            "aclImdb/train/unsup/44973_0.txt\n",
            "aclImdb/train/unsup/44972_0.txt\n",
            "aclImdb/train/unsup/44971_0.txt\n",
            "aclImdb/train/unsup/44970_0.txt\n",
            "aclImdb/train/unsup/44969_0.txt\n",
            "aclImdb/train/unsup/44968_0.txt\n",
            "aclImdb/train/unsup/44967_0.txt\n",
            "aclImdb/train/unsup/44966_0.txt\n",
            "aclImdb/train/unsup/44965_0.txt\n",
            "aclImdb/train/unsup/44964_0.txt\n",
            "aclImdb/train/unsup/44963_0.txt\n",
            "aclImdb/train/unsup/44962_0.txt\n",
            "aclImdb/train/unsup/44961_0.txt\n",
            "aclImdb/train/unsup/44960_0.txt\n",
            "aclImdb/train/unsup/44959_0.txt\n",
            "aclImdb/train/unsup/44958_0.txt\n",
            "aclImdb/train/unsup/44957_0.txt\n",
            "aclImdb/train/unsup/44956_0.txt\n",
            "aclImdb/train/unsup/44955_0.txt\n",
            "aclImdb/train/unsup/44954_0.txt\n",
            "aclImdb/train/unsup/44953_0.txt\n",
            "aclImdb/train/unsup/44952_0.txt\n",
            "aclImdb/train/unsup/44951_0.txt\n",
            "aclImdb/train/unsup/44950_0.txt\n",
            "aclImdb/train/unsup/44949_0.txt\n",
            "aclImdb/train/unsup/44948_0.txt\n",
            "aclImdb/train/unsup/44947_0.txt\n",
            "aclImdb/train/unsup/44946_0.txt\n",
            "aclImdb/train/unsup/44945_0.txt\n",
            "aclImdb/train/unsup/44944_0.txt\n",
            "aclImdb/train/unsup/44943_0.txt\n",
            "aclImdb/train/unsup/44942_0.txt\n",
            "aclImdb/train/unsup/44941_0.txt\n",
            "aclImdb/train/unsup/44940_0.txt\n",
            "aclImdb/train/unsup/44939_0.txt\n",
            "aclImdb/train/unsup/44938_0.txt\n",
            "aclImdb/train/unsup/44937_0.txt\n",
            "aclImdb/train/unsup/44936_0.txt\n",
            "aclImdb/train/unsup/44935_0.txt\n",
            "aclImdb/train/unsup/44934_0.txt\n",
            "aclImdb/train/unsup/44933_0.txt\n",
            "aclImdb/train/unsup/44932_0.txt\n",
            "aclImdb/train/unsup/44931_0.txt\n",
            "aclImdb/train/unsup/44930_0.txt\n",
            "aclImdb/train/unsup/44929_0.txt\n",
            "aclImdb/train/unsup/44928_0.txt\n",
            "aclImdb/train/unsup/45183_0.txt\n",
            "aclImdb/train/unsup/45182_0.txt\n",
            "aclImdb/train/unsup/45181_0.txt\n",
            "aclImdb/train/unsup/45180_0.txt\n",
            "aclImdb/train/unsup/45179_0.txt\n",
            "aclImdb/train/unsup/45178_0.txt\n",
            "aclImdb/train/unsup/45177_0.txt\n",
            "aclImdb/train/unsup/45176_0.txt\n",
            "aclImdb/train/unsup/45175_0.txt\n",
            "aclImdb/train/unsup/45174_0.txt\n",
            "aclImdb/train/unsup/45173_0.txt\n",
            "aclImdb/train/unsup/45172_0.txt\n",
            "aclImdb/train/unsup/45171_0.txt\n",
            "aclImdb/train/unsup/45170_0.txt\n",
            "aclImdb/train/unsup/45169_0.txt\n",
            "aclImdb/train/unsup/45168_0.txt\n",
            "aclImdb/train/unsup/45167_0.txt\n",
            "aclImdb/train/unsup/45166_0.txt\n",
            "aclImdb/train/unsup/45165_0.txt\n",
            "aclImdb/train/unsup/45164_0.txt\n",
            "aclImdb/train/unsup/45163_0.txt\n",
            "aclImdb/train/unsup/45162_0.txt\n",
            "aclImdb/train/unsup/45161_0.txt\n",
            "aclImdb/train/unsup/45160_0.txt\n",
            "aclImdb/train/unsup/45159_0.txt\n",
            "aclImdb/train/unsup/45158_0.txt\n",
            "aclImdb/train/unsup/45157_0.txt\n",
            "aclImdb/train/unsup/45156_0.txt\n",
            "aclImdb/train/unsup/45155_0.txt\n",
            "aclImdb/train/unsup/45154_0.txt\n",
            "aclImdb/train/unsup/45153_0.txt\n",
            "aclImdb/train/unsup/45152_0.txt\n",
            "aclImdb/train/unsup/45151_0.txt\n",
            "aclImdb/train/unsup/45150_0.txt\n",
            "aclImdb/train/unsup/45149_0.txt\n",
            "aclImdb/train/unsup/45148_0.txt\n",
            "aclImdb/train/unsup/45147_0.txt\n",
            "aclImdb/train/unsup/45146_0.txt\n",
            "aclImdb/train/unsup/45145_0.txt\n",
            "aclImdb/train/unsup/45144_0.txt\n",
            "aclImdb/train/unsup/45143_0.txt\n",
            "aclImdb/train/unsup/45142_0.txt\n",
            "aclImdb/train/unsup/45141_0.txt\n",
            "aclImdb/train/unsup/45140_0.txt\n",
            "aclImdb/train/unsup/45139_0.txt\n",
            "aclImdb/train/unsup/45138_0.txt\n",
            "aclImdb/train/unsup/45137_0.txt\n",
            "aclImdb/train/unsup/45136_0.txt\n",
            "aclImdb/train/unsup/45135_0.txt\n",
            "aclImdb/train/unsup/45134_0.txt\n",
            "aclImdb/train/unsup/45133_0.txt\n",
            "aclImdb/train/unsup/45132_0.txt\n",
            "aclImdb/train/unsup/45131_0.txt\n",
            "aclImdb/train/unsup/45130_0.txt\n",
            "aclImdb/train/unsup/45129_0.txt\n",
            "aclImdb/train/unsup/45128_0.txt\n",
            "aclImdb/train/unsup/45127_0.txt\n",
            "aclImdb/train/unsup/45126_0.txt\n",
            "aclImdb/train/unsup/45125_0.txt\n",
            "aclImdb/train/unsup/45124_0.txt\n",
            "aclImdb/train/unsup/45123_0.txt\n",
            "aclImdb/train/unsup/45122_0.txt\n",
            "aclImdb/train/unsup/45121_0.txt\n",
            "aclImdb/train/unsup/45120_0.txt\n",
            "aclImdb/train/unsup/45119_0.txt\n",
            "aclImdb/train/unsup/45118_0.txt\n",
            "aclImdb/train/unsup/45117_0.txt\n",
            "aclImdb/train/unsup/45116_0.txt\n",
            "aclImdb/train/unsup/45115_0.txt\n",
            "aclImdb/train/unsup/45114_0.txt\n",
            "aclImdb/train/unsup/45113_0.txt\n",
            "aclImdb/train/unsup/45112_0.txt\n",
            "aclImdb/train/unsup/45111_0.txt\n",
            "aclImdb/train/unsup/45110_0.txt\n",
            "aclImdb/train/unsup/45109_0.txt\n",
            "aclImdb/train/unsup/45108_0.txt\n",
            "aclImdb/train/unsup/45107_0.txt\n",
            "aclImdb/train/unsup/45106_0.txt\n",
            "aclImdb/train/unsup/45105_0.txt\n",
            "aclImdb/train/unsup/45104_0.txt\n",
            "aclImdb/train/unsup/45103_0.txt\n",
            "aclImdb/train/unsup/45102_0.txt\n",
            "aclImdb/train/unsup/45101_0.txt\n",
            "aclImdb/train/unsup/45100_0.txt\n",
            "aclImdb/train/unsup/45099_0.txt\n",
            "aclImdb/train/unsup/45098_0.txt\n",
            "aclImdb/train/unsup/45097_0.txt\n",
            "aclImdb/train/unsup/45096_0.txt\n",
            "aclImdb/train/unsup/45095_0.txt\n",
            "aclImdb/train/unsup/45094_0.txt\n",
            "aclImdb/train/unsup/45093_0.txt\n",
            "aclImdb/train/unsup/45092_0.txt\n",
            "aclImdb/train/unsup/45091_0.txt\n",
            "aclImdb/train/unsup/45090_0.txt\n",
            "aclImdb/train/unsup/45089_0.txt\n",
            "aclImdb/train/unsup/45088_0.txt\n",
            "aclImdb/train/unsup/45087_0.txt\n",
            "aclImdb/train/unsup/45086_0.txt\n",
            "aclImdb/train/unsup/45085_0.txt\n",
            "aclImdb/train/unsup/45084_0.txt\n",
            "aclImdb/train/unsup/45083_0.txt\n",
            "aclImdb/train/unsup/45082_0.txt\n",
            "aclImdb/train/unsup/45081_0.txt\n",
            "aclImdb/train/unsup/45080_0.txt\n",
            "aclImdb/train/unsup/45079_0.txt\n",
            "aclImdb/train/unsup/45078_0.txt\n",
            "aclImdb/train/unsup/45077_0.txt\n",
            "aclImdb/train/unsup/45076_0.txt\n",
            "aclImdb/train/unsup/45075_0.txt\n",
            "aclImdb/train/unsup/45074_0.txt\n",
            "aclImdb/train/unsup/45073_0.txt\n",
            "aclImdb/train/unsup/45072_0.txt\n",
            "aclImdb/train/unsup/45071_0.txt\n",
            "aclImdb/train/unsup/45070_0.txt\n",
            "aclImdb/train/unsup/45069_0.txt\n",
            "aclImdb/train/unsup/45068_0.txt\n",
            "aclImdb/train/unsup/45067_0.txt\n",
            "aclImdb/train/unsup/45066_0.txt\n",
            "aclImdb/train/unsup/45065_0.txt\n",
            "aclImdb/train/unsup/45064_0.txt\n",
            "aclImdb/train/unsup/45063_0.txt\n",
            "aclImdb/train/unsup/45062_0.txt\n",
            "aclImdb/train/unsup/45061_0.txt\n",
            "aclImdb/train/unsup/45060_0.txt\n",
            "aclImdb/train/unsup/45059_0.txt\n",
            "aclImdb/train/unsup/45058_0.txt\n",
            "aclImdb/train/unsup/45057_0.txt\n",
            "aclImdb/train/unsup/45056_0.txt\n",
            "aclImdb/train/unsup/45311_0.txt\n",
            "aclImdb/train/unsup/45310_0.txt\n",
            "aclImdb/train/unsup/45309_0.txt\n",
            "aclImdb/train/unsup/45308_0.txt\n",
            "aclImdb/train/unsup/45307_0.txt\n",
            "aclImdb/train/unsup/45306_0.txt\n",
            "aclImdb/train/unsup/45305_0.txt\n",
            "aclImdb/train/unsup/45304_0.txt\n",
            "aclImdb/train/unsup/45303_0.txt\n",
            "aclImdb/train/unsup/45302_0.txt\n",
            "aclImdb/train/unsup/45301_0.txt\n",
            "aclImdb/train/unsup/45300_0.txt\n",
            "aclImdb/train/unsup/45299_0.txt\n",
            "aclImdb/train/unsup/45298_0.txt\n",
            "aclImdb/train/unsup/45297_0.txt\n",
            "aclImdb/train/unsup/45296_0.txt\n",
            "aclImdb/train/unsup/45295_0.txt\n",
            "aclImdb/train/unsup/45294_0.txt\n",
            "aclImdb/train/unsup/45293_0.txt\n",
            "aclImdb/train/unsup/45292_0.txt\n",
            "aclImdb/train/unsup/45291_0.txt\n",
            "aclImdb/train/unsup/45290_0.txt\n",
            "aclImdb/train/unsup/45289_0.txt\n",
            "aclImdb/train/unsup/45288_0.txt\n",
            "aclImdb/train/unsup/45287_0.txt\n",
            "aclImdb/train/unsup/45286_0.txt\n",
            "aclImdb/train/unsup/45285_0.txt\n",
            "aclImdb/train/unsup/45284_0.txt\n",
            "aclImdb/train/unsup/45283_0.txt\n",
            "aclImdb/train/unsup/45282_0.txt\n",
            "aclImdb/train/unsup/45281_0.txt\n",
            "aclImdb/train/unsup/45280_0.txt\n",
            "aclImdb/train/unsup/45279_0.txt\n",
            "aclImdb/train/unsup/45278_0.txt\n",
            "aclImdb/train/unsup/45277_0.txt\n",
            "aclImdb/train/unsup/45276_0.txt\n",
            "aclImdb/train/unsup/45275_0.txt\n",
            "aclImdb/train/unsup/45274_0.txt\n",
            "aclImdb/train/unsup/45273_0.txt\n",
            "aclImdb/train/unsup/45272_0.txt\n",
            "aclImdb/train/unsup/45271_0.txt\n",
            "aclImdb/train/unsup/45270_0.txt\n",
            "aclImdb/train/unsup/45269_0.txt\n",
            "aclImdb/train/unsup/45268_0.txt\n",
            "aclImdb/train/unsup/45267_0.txt\n",
            "aclImdb/train/unsup/45266_0.txt\n",
            "aclImdb/train/unsup/45265_0.txt\n",
            "aclImdb/train/unsup/45264_0.txt\n",
            "aclImdb/train/unsup/45263_0.txt\n",
            "aclImdb/train/unsup/45262_0.txt\n",
            "aclImdb/train/unsup/45261_0.txt\n",
            "aclImdb/train/unsup/45260_0.txt\n",
            "aclImdb/train/unsup/45259_0.txt\n",
            "aclImdb/train/unsup/45258_0.txt\n",
            "aclImdb/train/unsup/45257_0.txt\n",
            "aclImdb/train/unsup/45256_0.txt\n",
            "aclImdb/train/unsup/45255_0.txt\n",
            "aclImdb/train/unsup/45254_0.txt\n",
            "aclImdb/train/unsup/45253_0.txt\n",
            "aclImdb/train/unsup/45252_0.txt\n",
            "aclImdb/train/unsup/45251_0.txt\n",
            "aclImdb/train/unsup/45250_0.txt\n",
            "aclImdb/train/unsup/45249_0.txt\n",
            "aclImdb/train/unsup/45248_0.txt\n",
            "aclImdb/train/unsup/45247_0.txt\n",
            "aclImdb/train/unsup/45246_0.txt\n",
            "aclImdb/train/unsup/45245_0.txt\n",
            "aclImdb/train/unsup/45244_0.txt\n",
            "aclImdb/train/unsup/45243_0.txt\n",
            "aclImdb/train/unsup/45242_0.txt\n",
            "aclImdb/train/unsup/45241_0.txt\n",
            "aclImdb/train/unsup/45240_0.txt\n",
            "aclImdb/train/unsup/45239_0.txt\n",
            "aclImdb/train/unsup/45238_0.txt\n",
            "aclImdb/train/unsup/45237_0.txt\n",
            "aclImdb/train/unsup/45236_0.txt\n",
            "aclImdb/train/unsup/45235_0.txt\n",
            "aclImdb/train/unsup/45234_0.txt\n",
            "aclImdb/train/unsup/45233_0.txt\n",
            "aclImdb/train/unsup/45232_0.txt\n",
            "aclImdb/train/unsup/45231_0.txt\n",
            "aclImdb/train/unsup/45230_0.txt\n",
            "aclImdb/train/unsup/45229_0.txt\n",
            "aclImdb/train/unsup/45228_0.txt\n",
            "aclImdb/train/unsup/45227_0.txt\n",
            "aclImdb/train/unsup/45226_0.txt\n",
            "aclImdb/train/unsup/45225_0.txt\n",
            "aclImdb/train/unsup/45224_0.txt\n",
            "aclImdb/train/unsup/45223_0.txt\n",
            "aclImdb/train/unsup/45222_0.txt\n",
            "aclImdb/train/unsup/45221_0.txt\n",
            "aclImdb/train/unsup/45220_0.txt\n",
            "aclImdb/train/unsup/45219_0.txt\n",
            "aclImdb/train/unsup/45218_0.txt\n",
            "aclImdb/train/unsup/45217_0.txt\n",
            "aclImdb/train/unsup/45216_0.txt\n",
            "aclImdb/train/unsup/45215_0.txt\n",
            "aclImdb/train/unsup/45214_0.txt\n",
            "aclImdb/train/unsup/45213_0.txt\n",
            "aclImdb/train/unsup/45212_0.txt\n",
            "aclImdb/train/unsup/45211_0.txt\n",
            "aclImdb/train/unsup/45210_0.txt\n",
            "aclImdb/train/unsup/45209_0.txt\n",
            "aclImdb/train/unsup/45208_0.txt\n",
            "aclImdb/train/unsup/45207_0.txt\n",
            "aclImdb/train/unsup/45206_0.txt\n",
            "aclImdb/train/unsup/45205_0.txt\n",
            "aclImdb/train/unsup/45204_0.txt\n",
            "aclImdb/train/unsup/45203_0.txt\n",
            "aclImdb/train/unsup/45202_0.txt\n",
            "aclImdb/train/unsup/45201_0.txt\n",
            "aclImdb/train/unsup/45200_0.txt\n",
            "aclImdb/train/unsup/45199_0.txt\n",
            "aclImdb/train/unsup/45198_0.txt\n",
            "aclImdb/train/unsup/45197_0.txt\n",
            "aclImdb/train/unsup/45196_0.txt\n",
            "aclImdb/train/unsup/45195_0.txt\n",
            "aclImdb/train/unsup/45194_0.txt\n",
            "aclImdb/train/unsup/45193_0.txt\n",
            "aclImdb/train/unsup/45192_0.txt\n",
            "aclImdb/train/unsup/45191_0.txt\n",
            "aclImdb/train/unsup/45190_0.txt\n",
            "aclImdb/train/unsup/45189_0.txt\n",
            "aclImdb/train/unsup/45188_0.txt\n",
            "aclImdb/train/unsup/45187_0.txt\n",
            "aclImdb/train/unsup/45186_0.txt\n",
            "aclImdb/train/unsup/45185_0.txt\n",
            "aclImdb/train/unsup/45184_0.txt\n",
            "aclImdb/train/unsup/45439_0.txt\n",
            "aclImdb/train/unsup/45438_0.txt\n",
            "aclImdb/train/unsup/45437_0.txt\n",
            "aclImdb/train/unsup/45436_0.txt\n",
            "aclImdb/train/unsup/45435_0.txt\n",
            "aclImdb/train/unsup/45434_0.txt\n",
            "aclImdb/train/unsup/45433_0.txt\n",
            "aclImdb/train/unsup/45432_0.txt\n",
            "aclImdb/train/unsup/45431_0.txt\n",
            "aclImdb/train/unsup/45430_0.txt\n",
            "aclImdb/train/unsup/45429_0.txt\n",
            "aclImdb/train/unsup/45428_0.txt\n",
            "aclImdb/train/unsup/45427_0.txt\n",
            "aclImdb/train/unsup/45426_0.txt\n",
            "aclImdb/train/unsup/45425_0.txt\n",
            "aclImdb/train/unsup/45424_0.txt\n",
            "aclImdb/train/unsup/45423_0.txt\n",
            "aclImdb/train/unsup/45422_0.txt\n",
            "aclImdb/train/unsup/45421_0.txt\n",
            "aclImdb/train/unsup/45420_0.txt\n",
            "aclImdb/train/unsup/45419_0.txt\n",
            "aclImdb/train/unsup/45418_0.txt\n",
            "aclImdb/train/unsup/45417_0.txt\n",
            "aclImdb/train/unsup/45416_0.txt\n",
            "aclImdb/train/unsup/45415_0.txt\n",
            "aclImdb/train/unsup/45414_0.txt\n",
            "aclImdb/train/unsup/45413_0.txt\n",
            "aclImdb/train/unsup/45412_0.txt\n",
            "aclImdb/train/unsup/45411_0.txt\n",
            "aclImdb/train/unsup/45410_0.txt\n",
            "aclImdb/train/unsup/45409_0.txt\n",
            "aclImdb/train/unsup/45408_0.txt\n",
            "aclImdb/train/unsup/45407_0.txt\n",
            "aclImdb/train/unsup/45406_0.txt\n",
            "aclImdb/train/unsup/45405_0.txt\n",
            "aclImdb/train/unsup/45404_0.txt\n",
            "aclImdb/train/unsup/45403_0.txt\n",
            "aclImdb/train/unsup/45402_0.txt\n",
            "aclImdb/train/unsup/45401_0.txt\n",
            "aclImdb/train/unsup/45400_0.txt\n",
            "aclImdb/train/unsup/45399_0.txt\n",
            "aclImdb/train/unsup/45398_0.txt\n",
            "aclImdb/train/unsup/45397_0.txt\n",
            "aclImdb/train/unsup/45396_0.txt\n",
            "aclImdb/train/unsup/45395_0.txt\n",
            "aclImdb/train/unsup/45394_0.txt\n",
            "aclImdb/train/unsup/45393_0.txt\n",
            "aclImdb/train/unsup/45392_0.txt\n",
            "aclImdb/train/unsup/45391_0.txt\n",
            "aclImdb/train/unsup/45390_0.txt\n",
            "aclImdb/train/unsup/45389_0.txt\n",
            "aclImdb/train/unsup/45388_0.txt\n",
            "aclImdb/train/unsup/45387_0.txt\n",
            "aclImdb/train/unsup/45386_0.txt\n",
            "aclImdb/train/unsup/45385_0.txt\n",
            "aclImdb/train/unsup/45384_0.txt\n",
            "aclImdb/train/unsup/45383_0.txt\n",
            "aclImdb/train/unsup/45382_0.txt\n",
            "aclImdb/train/unsup/45381_0.txt\n",
            "aclImdb/train/unsup/45380_0.txt\n",
            "aclImdb/train/unsup/45379_0.txt\n",
            "aclImdb/train/unsup/45378_0.txt\n",
            "aclImdb/train/unsup/45377_0.txt\n",
            "aclImdb/train/unsup/45376_0.txt\n",
            "aclImdb/train/unsup/45375_0.txt\n",
            "aclImdb/train/unsup/45374_0.txt\n",
            "aclImdb/train/unsup/45373_0.txt\n",
            "aclImdb/train/unsup/45372_0.txt\n",
            "aclImdb/train/unsup/45371_0.txt\n",
            "aclImdb/train/unsup/45370_0.txt\n",
            "aclImdb/train/unsup/45369_0.txt\n",
            "aclImdb/train/unsup/45368_0.txt\n",
            "aclImdb/train/unsup/45367_0.txt\n",
            "aclImdb/train/unsup/45366_0.txt\n",
            "aclImdb/train/unsup/45365_0.txt\n",
            "aclImdb/train/unsup/45364_0.txt\n",
            "aclImdb/train/unsup/45363_0.txt\n",
            "aclImdb/train/unsup/45362_0.txt\n",
            "aclImdb/train/unsup/45361_0.txt\n",
            "aclImdb/train/unsup/45360_0.txt\n",
            "aclImdb/train/unsup/45359_0.txt\n",
            "aclImdb/train/unsup/45358_0.txt\n",
            "aclImdb/train/unsup/45357_0.txt\n",
            "aclImdb/train/unsup/45356_0.txt\n",
            "aclImdb/train/unsup/45355_0.txt\n",
            "aclImdb/train/unsup/45354_0.txt\n",
            "aclImdb/train/unsup/45353_0.txt\n",
            "aclImdb/train/unsup/45352_0.txt\n",
            "aclImdb/train/unsup/45351_0.txt\n",
            "aclImdb/train/unsup/45350_0.txt\n",
            "aclImdb/train/unsup/45349_0.txt\n",
            "aclImdb/train/unsup/45348_0.txt\n",
            "aclImdb/train/unsup/45347_0.txt\n",
            "aclImdb/train/unsup/45346_0.txt\n",
            "aclImdb/train/unsup/45345_0.txt\n",
            "aclImdb/train/unsup/45344_0.txt\n",
            "aclImdb/train/unsup/45343_0.txt\n",
            "aclImdb/train/unsup/45342_0.txt\n",
            "aclImdb/train/unsup/45341_0.txt\n",
            "aclImdb/train/unsup/45340_0.txt\n",
            "aclImdb/train/unsup/45339_0.txt\n",
            "aclImdb/train/unsup/45338_0.txt\n",
            "aclImdb/train/unsup/45337_0.txt\n",
            "aclImdb/train/unsup/45336_0.txt\n",
            "aclImdb/train/unsup/45335_0.txt\n",
            "aclImdb/train/unsup/45334_0.txt\n",
            "aclImdb/train/unsup/45333_0.txt\n",
            "aclImdb/train/unsup/45332_0.txt\n",
            "aclImdb/train/unsup/45331_0.txt\n",
            "aclImdb/train/unsup/45330_0.txt\n",
            "aclImdb/train/unsup/45329_0.txt\n",
            "aclImdb/train/unsup/45328_0.txt\n",
            "aclImdb/train/unsup/45327_0.txt\n",
            "aclImdb/train/unsup/45326_0.txt\n",
            "aclImdb/train/unsup/45325_0.txt\n",
            "aclImdb/train/unsup/45324_0.txt\n",
            "aclImdb/train/unsup/45323_0.txt\n",
            "aclImdb/train/unsup/45322_0.txt\n",
            "aclImdb/train/unsup/45321_0.txt\n",
            "aclImdb/train/unsup/45320_0.txt\n",
            "aclImdb/train/unsup/45319_0.txt\n",
            "aclImdb/train/unsup/45318_0.txt\n",
            "aclImdb/train/unsup/45317_0.txt\n",
            "aclImdb/train/unsup/45316_0.txt\n",
            "aclImdb/train/unsup/45315_0.txt\n",
            "aclImdb/train/unsup/45314_0.txt\n",
            "aclImdb/train/unsup/45313_0.txt\n",
            "aclImdb/train/unsup/45312_0.txt\n",
            "aclImdb/train/unsup/45567_0.txt\n",
            "aclImdb/train/unsup/45566_0.txt\n",
            "aclImdb/train/unsup/45565_0.txt\n",
            "aclImdb/train/unsup/45564_0.txt\n",
            "aclImdb/train/unsup/45563_0.txt\n",
            "aclImdb/train/unsup/45562_0.txt\n",
            "aclImdb/train/unsup/45561_0.txt\n",
            "aclImdb/train/unsup/45560_0.txt\n",
            "aclImdb/train/unsup/45559_0.txt\n",
            "aclImdb/train/unsup/45558_0.txt\n",
            "aclImdb/train/unsup/45557_0.txt\n",
            "aclImdb/train/unsup/45556_0.txt\n",
            "aclImdb/train/unsup/45555_0.txt\n",
            "aclImdb/train/unsup/45554_0.txt\n",
            "aclImdb/train/unsup/45553_0.txt\n",
            "aclImdb/train/unsup/45552_0.txt\n",
            "aclImdb/train/unsup/45551_0.txt\n",
            "aclImdb/train/unsup/45550_0.txt\n",
            "aclImdb/train/unsup/45549_0.txt\n",
            "aclImdb/train/unsup/45548_0.txt\n",
            "aclImdb/train/unsup/45547_0.txt\n",
            "aclImdb/train/unsup/45546_0.txt\n",
            "aclImdb/train/unsup/45545_0.txt\n",
            "aclImdb/train/unsup/45544_0.txt\n",
            "aclImdb/train/unsup/45543_0.txt\n",
            "aclImdb/train/unsup/45542_0.txt\n",
            "aclImdb/train/unsup/45541_0.txt\n",
            "aclImdb/train/unsup/45540_0.txt\n",
            "aclImdb/train/unsup/45539_0.txt\n",
            "aclImdb/train/unsup/45538_0.txt\n",
            "aclImdb/train/unsup/45537_0.txt\n",
            "aclImdb/train/unsup/45536_0.txt\n",
            "aclImdb/train/unsup/45535_0.txt\n",
            "aclImdb/train/unsup/45534_0.txt\n",
            "aclImdb/train/unsup/45533_0.txt\n",
            "aclImdb/train/unsup/45532_0.txt\n",
            "aclImdb/train/unsup/45531_0.txt\n",
            "aclImdb/train/unsup/45530_0.txt\n",
            "aclImdb/train/unsup/45529_0.txt\n",
            "aclImdb/train/unsup/45528_0.txt\n",
            "aclImdb/train/unsup/45527_0.txt\n",
            "aclImdb/train/unsup/45526_0.txt\n",
            "aclImdb/train/unsup/45525_0.txt\n",
            "aclImdb/train/unsup/45524_0.txt\n",
            "aclImdb/train/unsup/45523_0.txt\n",
            "aclImdb/train/unsup/45522_0.txt\n",
            "aclImdb/train/unsup/45521_0.txt\n",
            "aclImdb/train/unsup/45520_0.txt\n",
            "aclImdb/train/unsup/45519_0.txt\n",
            "aclImdb/train/unsup/45518_0.txt\n",
            "aclImdb/train/unsup/45517_0.txt\n",
            "aclImdb/train/unsup/45516_0.txt\n",
            "aclImdb/train/unsup/45515_0.txt\n",
            "aclImdb/train/unsup/45514_0.txt\n",
            "aclImdb/train/unsup/45513_0.txt\n",
            "aclImdb/train/unsup/45512_0.txt\n",
            "aclImdb/train/unsup/45511_0.txt\n",
            "aclImdb/train/unsup/45510_0.txt\n",
            "aclImdb/train/unsup/45509_0.txt\n",
            "aclImdb/train/unsup/45508_0.txt\n",
            "aclImdb/train/unsup/45507_0.txt\n",
            "aclImdb/train/unsup/45506_0.txt\n",
            "aclImdb/train/unsup/45505_0.txt\n",
            "aclImdb/train/unsup/45504_0.txt\n",
            "aclImdb/train/unsup/45503_0.txt\n",
            "aclImdb/train/unsup/45502_0.txt\n",
            "aclImdb/train/unsup/45501_0.txt\n",
            "aclImdb/train/unsup/45500_0.txt\n",
            "aclImdb/train/unsup/45499_0.txt\n",
            "aclImdb/train/unsup/45498_0.txt\n",
            "aclImdb/train/unsup/45497_0.txt\n",
            "aclImdb/train/unsup/45496_0.txt\n",
            "aclImdb/train/unsup/45495_0.txt\n",
            "aclImdb/train/unsup/45494_0.txt\n",
            "aclImdb/train/unsup/45493_0.txt\n",
            "aclImdb/train/unsup/45492_0.txt\n",
            "aclImdb/train/unsup/45491_0.txt\n",
            "aclImdb/train/unsup/45490_0.txt\n",
            "aclImdb/train/unsup/45489_0.txt\n",
            "aclImdb/train/unsup/45488_0.txt\n",
            "aclImdb/train/unsup/45487_0.txt\n",
            "aclImdb/train/unsup/45486_0.txt\n",
            "aclImdb/train/unsup/45485_0.txt\n",
            "aclImdb/train/unsup/45484_0.txt\n",
            "aclImdb/train/unsup/45483_0.txt\n",
            "aclImdb/train/unsup/45482_0.txt\n",
            "aclImdb/train/unsup/45481_0.txt\n",
            "aclImdb/train/unsup/45480_0.txt\n",
            "aclImdb/train/unsup/45479_0.txt\n",
            "aclImdb/train/unsup/45478_0.txt\n",
            "aclImdb/train/unsup/45477_0.txt\n",
            "aclImdb/train/unsup/45476_0.txt\n",
            "aclImdb/train/unsup/45475_0.txt\n",
            "aclImdb/train/unsup/45474_0.txt\n",
            "aclImdb/train/unsup/45473_0.txt\n",
            "aclImdb/train/unsup/45472_0.txt\n",
            "aclImdb/train/unsup/45471_0.txt\n",
            "aclImdb/train/unsup/45470_0.txt\n",
            "aclImdb/train/unsup/45469_0.txt\n",
            "aclImdb/train/unsup/45468_0.txt\n",
            "aclImdb/train/unsup/45467_0.txt\n",
            "aclImdb/train/unsup/45466_0.txt\n",
            "aclImdb/train/unsup/45465_0.txt\n",
            "aclImdb/train/unsup/45464_0.txt\n",
            "aclImdb/train/unsup/45463_0.txt\n",
            "aclImdb/train/unsup/45462_0.txt\n",
            "aclImdb/train/unsup/45461_0.txt\n",
            "aclImdb/train/unsup/45460_0.txt\n",
            "aclImdb/train/unsup/45459_0.txt\n",
            "aclImdb/train/unsup/45458_0.txt\n",
            "aclImdb/train/unsup/45457_0.txt\n",
            "aclImdb/train/unsup/45456_0.txt\n",
            "aclImdb/train/unsup/45455_0.txt\n",
            "aclImdb/train/unsup/45454_0.txt\n",
            "aclImdb/train/unsup/45453_0.txt\n",
            "aclImdb/train/unsup/45452_0.txt\n",
            "aclImdb/train/unsup/45451_0.txt\n",
            "aclImdb/train/unsup/45450_0.txt\n",
            "aclImdb/train/unsup/45449_0.txt\n",
            "aclImdb/train/unsup/45448_0.txt\n",
            "aclImdb/train/unsup/45447_0.txt\n",
            "aclImdb/train/unsup/45446_0.txt\n",
            "aclImdb/train/unsup/45445_0.txt\n",
            "aclImdb/train/unsup/45444_0.txt\n",
            "aclImdb/train/unsup/45443_0.txt\n",
            "aclImdb/train/unsup/45442_0.txt\n",
            "aclImdb/train/unsup/45441_0.txt\n",
            "aclImdb/train/unsup/45440_0.txt\n",
            "aclImdb/train/unsup/45695_0.txt\n",
            "aclImdb/train/unsup/45694_0.txt\n",
            "aclImdb/train/unsup/45693_0.txt\n",
            "aclImdb/train/unsup/45692_0.txt\n",
            "aclImdb/train/unsup/45691_0.txt\n",
            "aclImdb/train/unsup/45690_0.txt\n",
            "aclImdb/train/unsup/45689_0.txt\n",
            "aclImdb/train/unsup/45688_0.txt\n",
            "aclImdb/train/unsup/45687_0.txt\n",
            "aclImdb/train/unsup/45686_0.txt\n",
            "aclImdb/train/unsup/45685_0.txt\n",
            "aclImdb/train/unsup/45684_0.txt\n",
            "aclImdb/train/unsup/45683_0.txt\n",
            "aclImdb/train/unsup/45682_0.txt\n",
            "aclImdb/train/unsup/45681_0.txt\n",
            "aclImdb/train/unsup/45680_0.txt\n",
            "aclImdb/train/unsup/45679_0.txt\n",
            "aclImdb/train/unsup/45678_0.txt\n",
            "aclImdb/train/unsup/45677_0.txt\n",
            "aclImdb/train/unsup/45676_0.txt\n",
            "aclImdb/train/unsup/45675_0.txt\n",
            "aclImdb/train/unsup/45674_0.txt\n",
            "aclImdb/train/unsup/45673_0.txt\n",
            "aclImdb/train/unsup/45672_0.txt\n",
            "aclImdb/train/unsup/45671_0.txt\n",
            "aclImdb/train/unsup/45670_0.txt\n",
            "aclImdb/train/unsup/45669_0.txt\n",
            "aclImdb/train/unsup/45668_0.txt\n",
            "aclImdb/train/unsup/45667_0.txt\n",
            "aclImdb/train/unsup/45666_0.txt\n",
            "aclImdb/train/unsup/45665_0.txt\n",
            "aclImdb/train/unsup/45664_0.txt\n",
            "aclImdb/train/unsup/45663_0.txt\n",
            "aclImdb/train/unsup/45662_0.txt\n",
            "aclImdb/train/unsup/45661_0.txt\n",
            "aclImdb/train/unsup/45660_0.txt\n",
            "aclImdb/train/unsup/45659_0.txt\n",
            "aclImdb/train/unsup/45658_0.txt\n",
            "aclImdb/train/unsup/45657_0.txt\n",
            "aclImdb/train/unsup/45656_0.txt\n",
            "aclImdb/train/unsup/45655_0.txt\n",
            "aclImdb/train/unsup/45654_0.txt\n",
            "aclImdb/train/unsup/45653_0.txt\n",
            "aclImdb/train/unsup/45652_0.txt\n",
            "aclImdb/train/unsup/45651_0.txt\n",
            "aclImdb/train/unsup/45650_0.txt\n",
            "aclImdb/train/unsup/45649_0.txt\n",
            "aclImdb/train/unsup/45648_0.txt\n",
            "aclImdb/train/unsup/45647_0.txt\n",
            "aclImdb/train/unsup/45646_0.txt\n",
            "aclImdb/train/unsup/45645_0.txt\n",
            "aclImdb/train/unsup/45644_0.txt\n",
            "aclImdb/train/unsup/45643_0.txt\n",
            "aclImdb/train/unsup/45642_0.txt\n",
            "aclImdb/train/unsup/45641_0.txt\n",
            "aclImdb/train/unsup/45640_0.txt\n",
            "aclImdb/train/unsup/45639_0.txt\n",
            "aclImdb/train/unsup/45638_0.txt\n",
            "aclImdb/train/unsup/45637_0.txt\n",
            "aclImdb/train/unsup/45636_0.txt\n",
            "aclImdb/train/unsup/45635_0.txt\n",
            "aclImdb/train/unsup/45634_0.txt\n",
            "aclImdb/train/unsup/45633_0.txt\n",
            "aclImdb/train/unsup/45632_0.txt\n",
            "aclImdb/train/unsup/45631_0.txt\n",
            "aclImdb/train/unsup/45630_0.txt\n",
            "aclImdb/train/unsup/45629_0.txt\n",
            "aclImdb/train/unsup/45628_0.txt\n",
            "aclImdb/train/unsup/45627_0.txt\n",
            "aclImdb/train/unsup/45626_0.txt\n",
            "aclImdb/train/unsup/45625_0.txt\n",
            "aclImdb/train/unsup/45624_0.txt\n",
            "aclImdb/train/unsup/45623_0.txt\n",
            "aclImdb/train/unsup/45622_0.txt\n",
            "aclImdb/train/unsup/45621_0.txt\n",
            "aclImdb/train/unsup/45620_0.txt\n",
            "aclImdb/train/unsup/45619_0.txt\n",
            "aclImdb/train/unsup/45618_0.txt\n",
            "aclImdb/train/unsup/45617_0.txt\n",
            "aclImdb/train/unsup/45616_0.txt\n",
            "aclImdb/train/unsup/45615_0.txt\n",
            "aclImdb/train/unsup/45614_0.txt\n",
            "aclImdb/train/unsup/45613_0.txt\n",
            "aclImdb/train/unsup/45612_0.txt\n",
            "aclImdb/train/unsup/45611_0.txt\n",
            "aclImdb/train/unsup/45610_0.txt\n",
            "aclImdb/train/unsup/45609_0.txt\n",
            "aclImdb/train/unsup/45608_0.txt\n",
            "aclImdb/train/unsup/45607_0.txt\n",
            "aclImdb/train/unsup/45606_0.txt\n",
            "aclImdb/train/unsup/45605_0.txt\n",
            "aclImdb/train/unsup/45604_0.txt\n",
            "aclImdb/train/unsup/45603_0.txt\n",
            "aclImdb/train/unsup/45602_0.txt\n",
            "aclImdb/train/unsup/45601_0.txt\n",
            "aclImdb/train/unsup/45600_0.txt\n",
            "aclImdb/train/unsup/45599_0.txt\n",
            "aclImdb/train/unsup/45598_0.txt\n",
            "aclImdb/train/unsup/45597_0.txt\n",
            "aclImdb/train/unsup/45596_0.txt\n",
            "aclImdb/train/unsup/45595_0.txt\n",
            "aclImdb/train/unsup/45594_0.txt\n",
            "aclImdb/train/unsup/45593_0.txt\n",
            "aclImdb/train/unsup/45592_0.txt\n",
            "aclImdb/train/unsup/45591_0.txt\n",
            "aclImdb/train/unsup/45590_0.txt\n",
            "aclImdb/train/unsup/45589_0.txt\n",
            "aclImdb/train/unsup/45588_0.txt\n",
            "aclImdb/train/unsup/45587_0.txt\n",
            "aclImdb/train/unsup/45586_0.txt\n",
            "aclImdb/train/unsup/45585_0.txt\n",
            "aclImdb/train/unsup/45584_0.txt\n",
            "aclImdb/train/unsup/45583_0.txt\n",
            "aclImdb/train/unsup/45582_0.txt\n",
            "aclImdb/train/unsup/45581_0.txt\n",
            "aclImdb/train/unsup/45580_0.txt\n",
            "aclImdb/train/unsup/45579_0.txt\n",
            "aclImdb/train/unsup/45578_0.txt\n",
            "aclImdb/train/unsup/45577_0.txt\n",
            "aclImdb/train/unsup/45576_0.txt\n",
            "aclImdb/train/unsup/45575_0.txt\n",
            "aclImdb/train/unsup/45574_0.txt\n",
            "aclImdb/train/unsup/45573_0.txt\n",
            "aclImdb/train/unsup/45572_0.txt\n",
            "aclImdb/train/unsup/45571_0.txt\n",
            "aclImdb/train/unsup/45570_0.txt\n",
            "aclImdb/train/unsup/45569_0.txt\n",
            "aclImdb/train/unsup/45568_0.txt\n",
            "aclImdb/train/unsup/45823_0.txt\n",
            "aclImdb/train/unsup/45822_0.txt\n",
            "aclImdb/train/unsup/45821_0.txt\n",
            "aclImdb/train/unsup/45820_0.txt\n",
            "aclImdb/train/unsup/45819_0.txt\n",
            "aclImdb/train/unsup/45818_0.txt\n",
            "aclImdb/train/unsup/45817_0.txt\n",
            "aclImdb/train/unsup/45816_0.txt\n",
            "aclImdb/train/unsup/45815_0.txt\n",
            "aclImdb/train/unsup/45814_0.txt\n",
            "aclImdb/train/unsup/45813_0.txt\n",
            "aclImdb/train/unsup/45812_0.txt\n",
            "aclImdb/train/unsup/45811_0.txt\n",
            "aclImdb/train/unsup/45810_0.txt\n",
            "aclImdb/train/unsup/45809_0.txt\n",
            "aclImdb/train/unsup/45808_0.txt\n",
            "aclImdb/train/unsup/45807_0.txt\n",
            "aclImdb/train/unsup/45806_0.txt\n",
            "aclImdb/train/unsup/45805_0.txt\n",
            "aclImdb/train/unsup/45804_0.txt\n",
            "aclImdb/train/unsup/45803_0.txt\n",
            "aclImdb/train/unsup/45802_0.txt\n",
            "aclImdb/train/unsup/45801_0.txt\n",
            "aclImdb/train/unsup/45800_0.txt\n",
            "aclImdb/train/unsup/45799_0.txt\n",
            "aclImdb/train/unsup/45798_0.txt\n",
            "aclImdb/train/unsup/45797_0.txt\n",
            "aclImdb/train/unsup/45796_0.txt\n",
            "aclImdb/train/unsup/45795_0.txt\n",
            "aclImdb/train/unsup/45794_0.txt\n",
            "aclImdb/train/unsup/45793_0.txt\n",
            "aclImdb/train/unsup/45792_0.txt\n",
            "aclImdb/train/unsup/45791_0.txt\n",
            "aclImdb/train/unsup/45790_0.txt\n",
            "aclImdb/train/unsup/45789_0.txt\n",
            "aclImdb/train/unsup/45788_0.txt\n",
            "aclImdb/train/unsup/45787_0.txt\n",
            "aclImdb/train/unsup/45786_0.txt\n",
            "aclImdb/train/unsup/45785_0.txt\n",
            "aclImdb/train/unsup/45784_0.txt\n",
            "aclImdb/train/unsup/45783_0.txt\n",
            "aclImdb/train/unsup/45782_0.txt\n",
            "aclImdb/train/unsup/45781_0.txt\n",
            "aclImdb/train/unsup/45780_0.txt\n",
            "aclImdb/train/unsup/45779_0.txt\n",
            "aclImdb/train/unsup/45778_0.txt\n",
            "aclImdb/train/unsup/45777_0.txt\n",
            "aclImdb/train/unsup/45776_0.txt\n",
            "aclImdb/train/unsup/45775_0.txt\n",
            "aclImdb/train/unsup/45774_0.txt\n",
            "aclImdb/train/unsup/45773_0.txt\n",
            "aclImdb/train/unsup/45772_0.txt\n",
            "aclImdb/train/unsup/45771_0.txt\n",
            "aclImdb/train/unsup/45770_0.txt\n",
            "aclImdb/train/unsup/45769_0.txt\n",
            "aclImdb/train/unsup/45768_0.txt\n",
            "aclImdb/train/unsup/45767_0.txt\n",
            "aclImdb/train/unsup/45766_0.txt\n",
            "aclImdb/train/unsup/45765_0.txt\n",
            "aclImdb/train/unsup/45764_0.txt\n",
            "aclImdb/train/unsup/45763_0.txt\n",
            "aclImdb/train/unsup/45762_0.txt\n",
            "aclImdb/train/unsup/45761_0.txt\n",
            "aclImdb/train/unsup/45760_0.txt\n",
            "aclImdb/train/unsup/45759_0.txt\n",
            "aclImdb/train/unsup/45758_0.txt\n",
            "aclImdb/train/unsup/45757_0.txt\n",
            "aclImdb/train/unsup/45756_0.txt\n",
            "aclImdb/train/unsup/45755_0.txt\n",
            "aclImdb/train/unsup/45754_0.txt\n",
            "aclImdb/train/unsup/45753_0.txt\n",
            "aclImdb/train/unsup/45752_0.txt\n",
            "aclImdb/train/unsup/45751_0.txt\n",
            "aclImdb/train/unsup/45750_0.txt\n",
            "aclImdb/train/unsup/45749_0.txt\n",
            "aclImdb/train/unsup/45748_0.txt\n",
            "aclImdb/train/unsup/45747_0.txt\n",
            "aclImdb/train/unsup/45746_0.txt\n",
            "aclImdb/train/unsup/45745_0.txt\n",
            "aclImdb/train/unsup/45744_0.txt\n",
            "aclImdb/train/unsup/45743_0.txt\n",
            "aclImdb/train/unsup/45742_0.txt\n",
            "aclImdb/train/unsup/45741_0.txt\n",
            "aclImdb/train/unsup/45740_0.txt\n",
            "aclImdb/train/unsup/45739_0.txt\n",
            "aclImdb/train/unsup/45738_0.txt\n",
            "aclImdb/train/unsup/45737_0.txt\n",
            "aclImdb/train/unsup/45736_0.txt\n",
            "aclImdb/train/unsup/45735_0.txt\n",
            "aclImdb/train/unsup/45734_0.txt\n",
            "aclImdb/train/unsup/45733_0.txt\n",
            "aclImdb/train/unsup/45732_0.txt\n",
            "aclImdb/train/unsup/45731_0.txt\n",
            "aclImdb/train/unsup/45730_0.txt\n",
            "aclImdb/train/unsup/45729_0.txt\n",
            "aclImdb/train/unsup/45728_0.txt\n",
            "aclImdb/train/unsup/45727_0.txt\n",
            "aclImdb/train/unsup/45726_0.txt\n",
            "aclImdb/train/unsup/45725_0.txt\n",
            "aclImdb/train/unsup/45724_0.txt\n",
            "aclImdb/train/unsup/45723_0.txt\n",
            "aclImdb/train/unsup/45722_0.txt\n",
            "aclImdb/train/unsup/45721_0.txt\n",
            "aclImdb/train/unsup/45720_0.txt\n",
            "aclImdb/train/unsup/45719_0.txt\n",
            "aclImdb/train/unsup/45718_0.txt\n",
            "aclImdb/train/unsup/45717_0.txt\n",
            "aclImdb/train/unsup/45716_0.txt\n",
            "aclImdb/train/unsup/45715_0.txt\n",
            "aclImdb/train/unsup/45714_0.txt\n",
            "aclImdb/train/unsup/45713_0.txt\n",
            "aclImdb/train/unsup/45712_0.txt\n",
            "aclImdb/train/unsup/45711_0.txt\n",
            "aclImdb/train/unsup/45710_0.txt\n",
            "aclImdb/train/unsup/45709_0.txt\n",
            "aclImdb/train/unsup/45708_0.txt\n",
            "aclImdb/train/unsup/45707_0.txt\n",
            "aclImdb/train/unsup/45706_0.txt\n",
            "aclImdb/train/unsup/45705_0.txt\n",
            "aclImdb/train/unsup/45704_0.txt\n",
            "aclImdb/train/unsup/45703_0.txt\n",
            "aclImdb/train/unsup/45702_0.txt\n",
            "aclImdb/train/unsup/45701_0.txt\n",
            "aclImdb/train/unsup/45700_0.txt\n",
            "aclImdb/train/unsup/45699_0.txt\n",
            "aclImdb/train/unsup/45698_0.txt\n",
            "aclImdb/train/unsup/45697_0.txt\n",
            "aclImdb/train/unsup/45696_0.txt\n",
            "aclImdb/train/unsup/45951_0.txt\n",
            "aclImdb/train/unsup/45950_0.txt\n",
            "aclImdb/train/unsup/45949_0.txt\n",
            "aclImdb/train/unsup/45948_0.txt\n",
            "aclImdb/train/unsup/45947_0.txt\n",
            "aclImdb/train/unsup/45946_0.txt\n",
            "aclImdb/train/unsup/45945_0.txt\n",
            "aclImdb/train/unsup/45944_0.txt\n",
            "aclImdb/train/unsup/45943_0.txt\n",
            "aclImdb/train/unsup/45942_0.txt\n",
            "aclImdb/train/unsup/45941_0.txt\n",
            "aclImdb/train/unsup/45940_0.txt\n",
            "aclImdb/train/unsup/45939_0.txt\n",
            "aclImdb/train/unsup/45938_0.txt\n",
            "aclImdb/train/unsup/45937_0.txt\n",
            "aclImdb/train/unsup/45936_0.txt\n",
            "aclImdb/train/unsup/45935_0.txt\n",
            "aclImdb/train/unsup/45934_0.txt\n",
            "aclImdb/train/unsup/45933_0.txt\n",
            "aclImdb/train/unsup/45932_0.txt\n",
            "aclImdb/train/unsup/45931_0.txt\n",
            "aclImdb/train/unsup/45930_0.txt\n",
            "aclImdb/train/unsup/45929_0.txt\n",
            "aclImdb/train/unsup/45928_0.txt\n",
            "aclImdb/train/unsup/45927_0.txt\n",
            "aclImdb/train/unsup/45926_0.txt\n",
            "aclImdb/train/unsup/45925_0.txt\n",
            "aclImdb/train/unsup/45924_0.txt\n",
            "aclImdb/train/unsup/45923_0.txt\n",
            "aclImdb/train/unsup/45922_0.txt\n",
            "aclImdb/train/unsup/45921_0.txt\n",
            "aclImdb/train/unsup/45920_0.txt\n",
            "aclImdb/train/unsup/45919_0.txt\n",
            "aclImdb/train/unsup/45918_0.txt\n",
            "aclImdb/train/unsup/45917_0.txt\n",
            "aclImdb/train/unsup/45916_0.txt\n",
            "aclImdb/train/unsup/45915_0.txt\n",
            "aclImdb/train/unsup/45914_0.txt\n",
            "aclImdb/train/unsup/45913_0.txt\n",
            "aclImdb/train/unsup/45912_0.txt\n",
            "aclImdb/train/unsup/45911_0.txt\n",
            "aclImdb/train/unsup/45910_0.txt\n",
            "aclImdb/train/unsup/45909_0.txt\n",
            "aclImdb/train/unsup/45908_0.txt\n",
            "aclImdb/train/unsup/45907_0.txt\n",
            "aclImdb/train/unsup/45906_0.txt\n",
            "aclImdb/train/unsup/45905_0.txt\n",
            "aclImdb/train/unsup/45904_0.txt\n",
            "aclImdb/train/unsup/45903_0.txt\n",
            "aclImdb/train/unsup/45902_0.txt\n",
            "aclImdb/train/unsup/45901_0.txt\n",
            "aclImdb/train/unsup/45900_0.txt\n",
            "aclImdb/train/unsup/45899_0.txt\n",
            "aclImdb/train/unsup/45898_0.txt\n",
            "aclImdb/train/unsup/45897_0.txt\n",
            "aclImdb/train/unsup/45896_0.txt\n",
            "aclImdb/train/unsup/45895_0.txt\n",
            "aclImdb/train/unsup/45894_0.txt\n",
            "aclImdb/train/unsup/45893_0.txt\n",
            "aclImdb/train/unsup/45892_0.txt\n",
            "aclImdb/train/unsup/45891_0.txt\n",
            "aclImdb/train/unsup/45890_0.txt\n",
            "aclImdb/train/unsup/45889_0.txt\n",
            "aclImdb/train/unsup/45888_0.txt\n",
            "aclImdb/train/unsup/45887_0.txt\n",
            "aclImdb/train/unsup/45886_0.txt\n",
            "aclImdb/train/unsup/45885_0.txt\n",
            "aclImdb/train/unsup/45884_0.txt\n",
            "aclImdb/train/unsup/45883_0.txt\n",
            "aclImdb/train/unsup/45882_0.txt\n",
            "aclImdb/train/unsup/45881_0.txt\n",
            "aclImdb/train/unsup/45880_0.txt\n",
            "aclImdb/train/unsup/45879_0.txt\n",
            "aclImdb/train/unsup/45878_0.txt\n",
            "aclImdb/train/unsup/45877_0.txt\n",
            "aclImdb/train/unsup/45876_0.txt\n",
            "aclImdb/train/unsup/45875_0.txt\n",
            "aclImdb/train/unsup/45874_0.txt\n",
            "aclImdb/train/unsup/45873_0.txt\n",
            "aclImdb/train/unsup/45872_0.txt\n",
            "aclImdb/train/unsup/45871_0.txt\n",
            "aclImdb/train/unsup/45870_0.txt\n",
            "aclImdb/train/unsup/45869_0.txt\n",
            "aclImdb/train/unsup/45868_0.txt\n",
            "aclImdb/train/unsup/45867_0.txt\n",
            "aclImdb/train/unsup/45866_0.txt\n",
            "aclImdb/train/unsup/45865_0.txt\n",
            "aclImdb/train/unsup/45864_0.txt\n",
            "aclImdb/train/unsup/45863_0.txt\n",
            "aclImdb/train/unsup/45862_0.txt\n",
            "aclImdb/train/unsup/45861_0.txt\n",
            "aclImdb/train/unsup/45860_0.txt\n",
            "aclImdb/train/unsup/45859_0.txt\n",
            "aclImdb/train/unsup/45858_0.txt\n",
            "aclImdb/train/unsup/45857_0.txt\n",
            "aclImdb/train/unsup/45856_0.txt\n",
            "aclImdb/train/unsup/45855_0.txt\n",
            "aclImdb/train/unsup/45854_0.txt\n",
            "aclImdb/train/unsup/45853_0.txt\n",
            "aclImdb/train/unsup/45852_0.txt\n",
            "aclImdb/train/unsup/45851_0.txt\n",
            "aclImdb/train/unsup/45850_0.txt\n",
            "aclImdb/train/unsup/45849_0.txt\n",
            "aclImdb/train/unsup/45848_0.txt\n",
            "aclImdb/train/unsup/45847_0.txt\n",
            "aclImdb/train/unsup/45846_0.txt\n",
            "aclImdb/train/unsup/45845_0.txt\n",
            "aclImdb/train/unsup/45844_0.txt\n",
            "aclImdb/train/unsup/45843_0.txt\n",
            "aclImdb/train/unsup/45842_0.txt\n",
            "aclImdb/train/unsup/45841_0.txt\n",
            "aclImdb/train/unsup/45840_0.txt\n",
            "aclImdb/train/unsup/45839_0.txt\n",
            "aclImdb/train/unsup/45838_0.txt\n",
            "aclImdb/train/unsup/45837_0.txt\n",
            "aclImdb/train/unsup/45836_0.txt\n",
            "aclImdb/train/unsup/45835_0.txt\n",
            "aclImdb/train/unsup/45834_0.txt\n",
            "aclImdb/train/unsup/45833_0.txt\n",
            "aclImdb/train/unsup/45832_0.txt\n",
            "aclImdb/train/unsup/45831_0.txt\n",
            "aclImdb/train/unsup/45830_0.txt\n",
            "aclImdb/train/unsup/45829_0.txt\n",
            "aclImdb/train/unsup/45828_0.txt\n",
            "aclImdb/train/unsup/45827_0.txt\n",
            "aclImdb/train/unsup/45826_0.txt\n",
            "aclImdb/train/unsup/45825_0.txt\n",
            "aclImdb/train/unsup/45824_0.txt\n",
            "aclImdb/train/unsup/46079_0.txt\n",
            "aclImdb/train/unsup/46078_0.txt\n",
            "aclImdb/train/unsup/46077_0.txt\n",
            "aclImdb/train/unsup/46076_0.txt\n",
            "aclImdb/train/unsup/46075_0.txt\n",
            "aclImdb/train/unsup/46074_0.txt\n",
            "aclImdb/train/unsup/46073_0.txt\n",
            "aclImdb/train/unsup/46072_0.txt\n",
            "aclImdb/train/unsup/46071_0.txt\n",
            "aclImdb/train/unsup/46070_0.txt\n",
            "aclImdb/train/unsup/46069_0.txt\n",
            "aclImdb/train/unsup/46068_0.txt\n",
            "aclImdb/train/unsup/46067_0.txt\n",
            "aclImdb/train/unsup/46066_0.txt\n",
            "aclImdb/train/unsup/46065_0.txt\n",
            "aclImdb/train/unsup/46064_0.txt\n",
            "aclImdb/train/unsup/46063_0.txt\n",
            "aclImdb/train/unsup/46062_0.txt\n",
            "aclImdb/train/unsup/46061_0.txt\n",
            "aclImdb/train/unsup/46060_0.txt\n",
            "aclImdb/train/unsup/46059_0.txt\n",
            "aclImdb/train/unsup/46058_0.txt\n",
            "aclImdb/train/unsup/46057_0.txt\n",
            "aclImdb/train/unsup/46056_0.txt\n",
            "aclImdb/train/unsup/46055_0.txt\n",
            "aclImdb/train/unsup/46054_0.txt\n",
            "aclImdb/train/unsup/46053_0.txt\n",
            "aclImdb/train/unsup/46052_0.txt\n",
            "aclImdb/train/unsup/46051_0.txt\n",
            "aclImdb/train/unsup/46050_0.txt\n",
            "aclImdb/train/unsup/46049_0.txt\n",
            "aclImdb/train/unsup/46048_0.txt\n",
            "aclImdb/train/unsup/46047_0.txt\n",
            "aclImdb/train/unsup/46046_0.txt\n",
            "aclImdb/train/unsup/46045_0.txt\n",
            "aclImdb/train/unsup/46044_0.txt\n",
            "aclImdb/train/unsup/46043_0.txt\n",
            "aclImdb/train/unsup/46042_0.txt\n",
            "aclImdb/train/unsup/46041_0.txt\n",
            "aclImdb/train/unsup/46040_0.txt\n",
            "aclImdb/train/unsup/46039_0.txt\n",
            "aclImdb/train/unsup/46038_0.txt\n",
            "aclImdb/train/unsup/46037_0.txt\n",
            "aclImdb/train/unsup/46036_0.txt\n",
            "aclImdb/train/unsup/46035_0.txt\n",
            "aclImdb/train/unsup/46034_0.txt\n",
            "aclImdb/train/unsup/46033_0.txt\n",
            "aclImdb/train/unsup/46032_0.txt\n",
            "aclImdb/train/unsup/46031_0.txt\n",
            "aclImdb/train/unsup/46030_0.txt\n",
            "aclImdb/train/unsup/46029_0.txt\n",
            "aclImdb/train/unsup/46028_0.txt\n",
            "aclImdb/train/unsup/46027_0.txt\n",
            "aclImdb/train/unsup/46026_0.txt\n",
            "aclImdb/train/unsup/46025_0.txt\n",
            "aclImdb/train/unsup/46024_0.txt\n",
            "aclImdb/train/unsup/46023_0.txt\n",
            "aclImdb/train/unsup/46022_0.txt\n",
            "aclImdb/train/unsup/46021_0.txt\n",
            "aclImdb/train/unsup/46020_0.txt\n",
            "aclImdb/train/unsup/46019_0.txt\n",
            "aclImdb/train/unsup/46018_0.txt\n",
            "aclImdb/train/unsup/46017_0.txt\n",
            "aclImdb/train/unsup/46016_0.txt\n",
            "aclImdb/train/unsup/46015_0.txt\n",
            "aclImdb/train/unsup/46014_0.txt\n",
            "aclImdb/train/unsup/46013_0.txt\n",
            "aclImdb/train/unsup/46012_0.txt\n",
            "aclImdb/train/unsup/46011_0.txt\n",
            "aclImdb/train/unsup/46010_0.txt\n",
            "aclImdb/train/unsup/46009_0.txt\n",
            "aclImdb/train/unsup/46008_0.txt\n",
            "aclImdb/train/unsup/46007_0.txt\n",
            "aclImdb/train/unsup/46006_0.txt\n",
            "aclImdb/train/unsup/46005_0.txt\n",
            "aclImdb/train/unsup/46004_0.txt\n",
            "aclImdb/train/unsup/46003_0.txt\n",
            "aclImdb/train/unsup/46002_0.txt\n",
            "aclImdb/train/unsup/46001_0.txt\n",
            "aclImdb/train/unsup/46000_0.txt\n",
            "aclImdb/train/unsup/45999_0.txt\n",
            "aclImdb/train/unsup/45998_0.txt\n",
            "aclImdb/train/unsup/45997_0.txt\n",
            "aclImdb/train/unsup/45996_0.txt\n",
            "aclImdb/train/unsup/45995_0.txt\n",
            "aclImdb/train/unsup/45994_0.txt\n",
            "aclImdb/train/unsup/45993_0.txt\n",
            "aclImdb/train/unsup/45992_0.txt\n",
            "aclImdb/train/unsup/45991_0.txt\n",
            "aclImdb/train/unsup/45990_0.txt\n",
            "aclImdb/train/unsup/45989_0.txt\n",
            "aclImdb/train/unsup/45988_0.txt\n",
            "aclImdb/train/unsup/45987_0.txt\n",
            "aclImdb/train/unsup/45986_0.txt\n",
            "aclImdb/train/unsup/45985_0.txt\n",
            "aclImdb/train/unsup/45984_0.txt\n",
            "aclImdb/train/unsup/45983_0.txt\n",
            "aclImdb/train/unsup/45982_0.txt\n",
            "aclImdb/train/unsup/45981_0.txt\n",
            "aclImdb/train/unsup/45980_0.txt\n",
            "aclImdb/train/unsup/45979_0.txt\n",
            "aclImdb/train/unsup/45978_0.txt\n",
            "aclImdb/train/unsup/45977_0.txt\n",
            "aclImdb/train/unsup/45976_0.txt\n",
            "aclImdb/train/unsup/45975_0.txt\n",
            "aclImdb/train/unsup/45974_0.txt\n",
            "aclImdb/train/unsup/45973_0.txt\n",
            "aclImdb/train/unsup/45972_0.txt\n",
            "aclImdb/train/unsup/45971_0.txt\n",
            "aclImdb/train/unsup/45970_0.txt\n",
            "aclImdb/train/unsup/45969_0.txt\n",
            "aclImdb/train/unsup/45968_0.txt\n",
            "aclImdb/train/unsup/45967_0.txt\n",
            "aclImdb/train/unsup/45966_0.txt\n",
            "aclImdb/train/unsup/45965_0.txt\n",
            "aclImdb/train/unsup/45964_0.txt\n",
            "aclImdb/train/unsup/45963_0.txt\n",
            "aclImdb/train/unsup/45962_0.txt\n",
            "aclImdb/train/unsup/45961_0.txt\n",
            "aclImdb/train/unsup/45960_0.txt\n",
            "aclImdb/train/unsup/45959_0.txt\n",
            "aclImdb/train/unsup/45958_0.txt\n",
            "aclImdb/train/unsup/45957_0.txt\n",
            "aclImdb/train/unsup/45956_0.txt\n",
            "aclImdb/train/unsup/45955_0.txt\n",
            "aclImdb/train/unsup/45954_0.txt\n",
            "aclImdb/train/unsup/45953_0.txt\n",
            "aclImdb/train/unsup/45952_0.txt\n",
            "aclImdb/train/unsup/46207_0.txt\n",
            "aclImdb/train/unsup/46206_0.txt\n",
            "aclImdb/train/unsup/46205_0.txt\n",
            "aclImdb/train/unsup/46204_0.txt\n",
            "aclImdb/train/unsup/46203_0.txt\n",
            "aclImdb/train/unsup/46202_0.txt\n",
            "aclImdb/train/unsup/46201_0.txt\n",
            "aclImdb/train/unsup/46200_0.txt\n",
            "aclImdb/train/unsup/46199_0.txt\n",
            "aclImdb/train/unsup/46198_0.txt\n",
            "aclImdb/train/unsup/46197_0.txt\n",
            "aclImdb/train/unsup/46196_0.txt\n",
            "aclImdb/train/unsup/46195_0.txt\n",
            "aclImdb/train/unsup/46194_0.txt\n",
            "aclImdb/train/unsup/46193_0.txt\n",
            "aclImdb/train/unsup/46192_0.txt\n",
            "aclImdb/train/unsup/46191_0.txt\n",
            "aclImdb/train/unsup/46190_0.txt\n",
            "aclImdb/train/unsup/46189_0.txt\n",
            "aclImdb/train/unsup/46188_0.txt\n",
            "aclImdb/train/unsup/46187_0.txt\n",
            "aclImdb/train/unsup/46186_0.txt\n",
            "aclImdb/train/unsup/46185_0.txt\n",
            "aclImdb/train/unsup/46184_0.txt\n",
            "aclImdb/train/unsup/46183_0.txt\n",
            "aclImdb/train/unsup/46182_0.txt\n",
            "aclImdb/train/unsup/46181_0.txt\n",
            "aclImdb/train/unsup/46180_0.txt\n",
            "aclImdb/train/unsup/46179_0.txt\n",
            "aclImdb/train/unsup/46178_0.txt\n",
            "aclImdb/train/unsup/46177_0.txt\n",
            "aclImdb/train/unsup/46176_0.txt\n",
            "aclImdb/train/unsup/46175_0.txt\n",
            "aclImdb/train/unsup/46174_0.txt\n",
            "aclImdb/train/unsup/46173_0.txt\n",
            "aclImdb/train/unsup/46172_0.txt\n",
            "aclImdb/train/unsup/46171_0.txt\n",
            "aclImdb/train/unsup/46170_0.txt\n",
            "aclImdb/train/unsup/46169_0.txt\n",
            "aclImdb/train/unsup/46168_0.txt\n",
            "aclImdb/train/unsup/46167_0.txt\n",
            "aclImdb/train/unsup/46166_0.txt\n",
            "aclImdb/train/unsup/46165_0.txt\n",
            "aclImdb/train/unsup/46164_0.txt\n",
            "aclImdb/train/unsup/46163_0.txt\n",
            "aclImdb/train/unsup/46162_0.txt\n",
            "aclImdb/train/unsup/46161_0.txt\n",
            "aclImdb/train/unsup/46160_0.txt\n",
            "aclImdb/train/unsup/46159_0.txt\n",
            "aclImdb/train/unsup/46158_0.txt\n",
            "aclImdb/train/unsup/46157_0.txt\n",
            "aclImdb/train/unsup/46156_0.txt\n",
            "aclImdb/train/unsup/46155_0.txt\n",
            "aclImdb/train/unsup/46154_0.txt\n",
            "aclImdb/train/unsup/46153_0.txt\n",
            "aclImdb/train/unsup/46152_0.txt\n",
            "aclImdb/train/unsup/46151_0.txt\n",
            "aclImdb/train/unsup/46150_0.txt\n",
            "aclImdb/train/unsup/46149_0.txt\n",
            "aclImdb/train/unsup/46148_0.txt\n",
            "aclImdb/train/unsup/46147_0.txt\n",
            "aclImdb/train/unsup/46146_0.txt\n",
            "aclImdb/train/unsup/46145_0.txt\n",
            "aclImdb/train/unsup/46144_0.txt\n",
            "aclImdb/train/unsup/46143_0.txt\n",
            "aclImdb/train/unsup/46142_0.txt\n",
            "aclImdb/train/unsup/46141_0.txt\n",
            "aclImdb/train/unsup/46140_0.txt\n",
            "aclImdb/train/unsup/46139_0.txt\n",
            "aclImdb/train/unsup/46138_0.txt\n",
            "aclImdb/train/unsup/46137_0.txt\n",
            "aclImdb/train/unsup/46136_0.txt\n",
            "aclImdb/train/unsup/46135_0.txt\n",
            "aclImdb/train/unsup/46134_0.txt\n",
            "aclImdb/train/unsup/46133_0.txt\n",
            "aclImdb/train/unsup/46132_0.txt\n",
            "aclImdb/train/unsup/46131_0.txt\n",
            "aclImdb/train/unsup/46130_0.txt\n",
            "aclImdb/train/unsup/46129_0.txt\n",
            "aclImdb/train/unsup/46128_0.txt\n",
            "aclImdb/train/unsup/46127_0.txt\n",
            "aclImdb/train/unsup/46126_0.txt\n",
            "aclImdb/train/unsup/46125_0.txt\n",
            "aclImdb/train/unsup/46124_0.txt\n",
            "aclImdb/train/unsup/46123_0.txt\n",
            "aclImdb/train/unsup/46122_0.txt\n",
            "aclImdb/train/unsup/46121_0.txt\n",
            "aclImdb/train/unsup/46120_0.txt\n",
            "aclImdb/train/unsup/46119_0.txt\n",
            "aclImdb/train/unsup/46118_0.txt\n",
            "aclImdb/train/unsup/46117_0.txt\n",
            "aclImdb/train/unsup/46116_0.txt\n",
            "aclImdb/train/unsup/46115_0.txt\n",
            "aclImdb/train/unsup/46114_0.txt\n",
            "aclImdb/train/unsup/46113_0.txt\n",
            "aclImdb/train/unsup/46112_0.txt\n",
            "aclImdb/train/unsup/46111_0.txt\n",
            "aclImdb/train/unsup/46110_0.txt\n",
            "aclImdb/train/unsup/46109_0.txt\n",
            "aclImdb/train/unsup/46108_0.txt\n",
            "aclImdb/train/unsup/46107_0.txt\n",
            "aclImdb/train/unsup/46106_0.txt\n",
            "aclImdb/train/unsup/46105_0.txt\n",
            "aclImdb/train/unsup/46104_0.txt\n",
            "aclImdb/train/unsup/46103_0.txt\n",
            "aclImdb/train/unsup/46102_0.txt\n",
            "aclImdb/train/unsup/46101_0.txt\n",
            "aclImdb/train/unsup/46100_0.txt\n",
            "aclImdb/train/unsup/46099_0.txt\n",
            "aclImdb/train/unsup/46098_0.txt\n",
            "aclImdb/train/unsup/46097_0.txt\n",
            "aclImdb/train/unsup/46096_0.txt\n",
            "aclImdb/train/unsup/46095_0.txt\n",
            "aclImdb/train/unsup/46094_0.txt\n",
            "aclImdb/train/unsup/46093_0.txt\n",
            "aclImdb/train/unsup/46092_0.txt\n",
            "aclImdb/train/unsup/46091_0.txt\n",
            "aclImdb/train/unsup/46090_0.txt\n",
            "aclImdb/train/unsup/46089_0.txt\n",
            "aclImdb/train/unsup/46088_0.txt\n",
            "aclImdb/train/unsup/46087_0.txt\n",
            "aclImdb/train/unsup/46086_0.txt\n",
            "aclImdb/train/unsup/46085_0.txt\n",
            "aclImdb/train/unsup/46084_0.txt\n",
            "aclImdb/train/unsup/46083_0.txt\n",
            "aclImdb/train/unsup/46082_0.txt\n",
            "aclImdb/train/unsup/46081_0.txt\n",
            "aclImdb/train/unsup/46080_0.txt\n",
            "aclImdb/train/unsup/46335_0.txt\n",
            "aclImdb/train/unsup/46334_0.txt\n",
            "aclImdb/train/unsup/46333_0.txt\n",
            "aclImdb/train/unsup/46332_0.txt\n",
            "aclImdb/train/unsup/46331_0.txt\n",
            "aclImdb/train/unsup/46330_0.txt\n",
            "aclImdb/train/unsup/46329_0.txt\n",
            "aclImdb/train/unsup/46328_0.txt\n",
            "aclImdb/train/unsup/46327_0.txt\n",
            "aclImdb/train/unsup/46326_0.txt\n",
            "aclImdb/train/unsup/46325_0.txt\n",
            "aclImdb/train/unsup/46324_0.txt\n",
            "aclImdb/train/unsup/46323_0.txt\n",
            "aclImdb/train/unsup/46322_0.txt\n",
            "aclImdb/train/unsup/46321_0.txt\n",
            "aclImdb/train/unsup/46320_0.txt\n",
            "aclImdb/train/unsup/46319_0.txt\n",
            "aclImdb/train/unsup/46318_0.txt\n",
            "aclImdb/train/unsup/46317_0.txt\n",
            "aclImdb/train/unsup/46316_0.txt\n",
            "aclImdb/train/unsup/46315_0.txt\n",
            "aclImdb/train/unsup/46314_0.txt\n",
            "aclImdb/train/unsup/46313_0.txt\n",
            "aclImdb/train/unsup/46312_0.txt\n",
            "aclImdb/train/unsup/46311_0.txt\n",
            "aclImdb/train/unsup/46310_0.txt\n",
            "aclImdb/train/unsup/46309_0.txt\n",
            "aclImdb/train/unsup/46308_0.txt\n",
            "aclImdb/train/unsup/46307_0.txt\n",
            "aclImdb/train/unsup/46306_0.txt\n",
            "aclImdb/train/unsup/46305_0.txt\n",
            "aclImdb/train/unsup/46304_0.txt\n",
            "aclImdb/train/unsup/46303_0.txt\n",
            "aclImdb/train/unsup/46302_0.txt\n",
            "aclImdb/train/unsup/46301_0.txt\n",
            "aclImdb/train/unsup/46300_0.txt\n",
            "aclImdb/train/unsup/46299_0.txt\n",
            "aclImdb/train/unsup/46298_0.txt\n",
            "aclImdb/train/unsup/46297_0.txt\n",
            "aclImdb/train/unsup/46296_0.txt\n",
            "aclImdb/train/unsup/46295_0.txt\n",
            "aclImdb/train/unsup/46294_0.txt\n",
            "aclImdb/train/unsup/46293_0.txt\n",
            "aclImdb/train/unsup/46292_0.txt\n",
            "aclImdb/train/unsup/46291_0.txt\n",
            "aclImdb/train/unsup/46290_0.txt\n",
            "aclImdb/train/unsup/46289_0.txt\n",
            "aclImdb/train/unsup/46288_0.txt\n",
            "aclImdb/train/unsup/46287_0.txt\n",
            "aclImdb/train/unsup/46286_0.txt\n",
            "aclImdb/train/unsup/46285_0.txt\n",
            "aclImdb/train/unsup/46284_0.txt\n",
            "aclImdb/train/unsup/46283_0.txt\n",
            "aclImdb/train/unsup/46282_0.txt\n",
            "aclImdb/train/unsup/46281_0.txt\n",
            "aclImdb/train/unsup/46280_0.txt\n",
            "aclImdb/train/unsup/46279_0.txt\n",
            "aclImdb/train/unsup/46278_0.txt\n",
            "aclImdb/train/unsup/46277_0.txt\n",
            "aclImdb/train/unsup/46276_0.txt\n",
            "aclImdb/train/unsup/46275_0.txt\n",
            "aclImdb/train/unsup/46274_0.txt\n",
            "aclImdb/train/unsup/46273_0.txt\n",
            "aclImdb/train/unsup/46272_0.txt\n",
            "aclImdb/train/unsup/46271_0.txt\n",
            "aclImdb/train/unsup/46270_0.txt\n",
            "aclImdb/train/unsup/46269_0.txt\n",
            "aclImdb/train/unsup/46268_0.txt\n",
            "aclImdb/train/unsup/46267_0.txt\n",
            "aclImdb/train/unsup/46266_0.txt\n",
            "aclImdb/train/unsup/46265_0.txt\n",
            "aclImdb/train/unsup/46264_0.txt\n",
            "aclImdb/train/unsup/46263_0.txt\n",
            "aclImdb/train/unsup/46262_0.txt\n",
            "aclImdb/train/unsup/46261_0.txt\n",
            "aclImdb/train/unsup/46260_0.txt\n",
            "aclImdb/train/unsup/46259_0.txt\n",
            "aclImdb/train/unsup/46258_0.txt\n",
            "aclImdb/train/unsup/46257_0.txt\n",
            "aclImdb/train/unsup/46256_0.txt\n",
            "aclImdb/train/unsup/46255_0.txt\n",
            "aclImdb/train/unsup/46254_0.txt\n",
            "aclImdb/train/unsup/46253_0.txt\n",
            "aclImdb/train/unsup/46252_0.txt\n",
            "aclImdb/train/unsup/46251_0.txt\n",
            "aclImdb/train/unsup/46250_0.txt\n",
            "aclImdb/train/unsup/46249_0.txt\n",
            "aclImdb/train/unsup/46248_0.txt\n",
            "aclImdb/train/unsup/46247_0.txt\n",
            "aclImdb/train/unsup/46246_0.txt\n",
            "aclImdb/train/unsup/46245_0.txt\n",
            "aclImdb/train/unsup/46244_0.txt\n",
            "aclImdb/train/unsup/46243_0.txt\n",
            "aclImdb/train/unsup/46242_0.txt\n",
            "aclImdb/train/unsup/46241_0.txt\n",
            "aclImdb/train/unsup/46240_0.txt\n",
            "aclImdb/train/unsup/46239_0.txt\n",
            "aclImdb/train/unsup/46238_0.txt\n",
            "aclImdb/train/unsup/46237_0.txt\n",
            "aclImdb/train/unsup/46236_0.txt\n",
            "aclImdb/train/unsup/46235_0.txt\n",
            "aclImdb/train/unsup/46234_0.txt\n",
            "aclImdb/train/unsup/46233_0.txt\n",
            "aclImdb/train/unsup/46232_0.txt\n",
            "aclImdb/train/unsup/46231_0.txt\n",
            "aclImdb/train/unsup/46230_0.txt\n",
            "aclImdb/train/unsup/46229_0.txt\n",
            "aclImdb/train/unsup/46228_0.txt\n",
            "aclImdb/train/unsup/46227_0.txt\n",
            "aclImdb/train/unsup/46226_0.txt\n",
            "aclImdb/train/unsup/46225_0.txt\n",
            "aclImdb/train/unsup/46224_0.txt\n",
            "aclImdb/train/unsup/46223_0.txt\n",
            "aclImdb/train/unsup/46222_0.txt\n",
            "aclImdb/train/unsup/46221_0.txt\n",
            "aclImdb/train/unsup/46220_0.txt\n",
            "aclImdb/train/unsup/46219_0.txt\n",
            "aclImdb/train/unsup/46218_0.txt\n",
            "aclImdb/train/unsup/46217_0.txt\n",
            "aclImdb/train/unsup/46216_0.txt\n",
            "aclImdb/train/unsup/46215_0.txt\n",
            "aclImdb/train/unsup/46214_0.txt\n",
            "aclImdb/train/unsup/46213_0.txt\n",
            "aclImdb/train/unsup/46212_0.txt\n",
            "aclImdb/train/unsup/46211_0.txt\n",
            "aclImdb/train/unsup/46210_0.txt\n",
            "aclImdb/train/unsup/46209_0.txt\n",
            "aclImdb/train/unsup/46208_0.txt\n",
            "aclImdb/train/unsup/46463_0.txt\n",
            "aclImdb/train/unsup/46462_0.txt\n",
            "aclImdb/train/unsup/46461_0.txt\n",
            "aclImdb/train/unsup/46460_0.txt\n",
            "aclImdb/train/unsup/46459_0.txt\n",
            "aclImdb/train/unsup/46458_0.txt\n",
            "aclImdb/train/unsup/46457_0.txt\n",
            "aclImdb/train/unsup/46456_0.txt\n",
            "aclImdb/train/unsup/46455_0.txt\n",
            "aclImdb/train/unsup/46454_0.txt\n",
            "aclImdb/train/unsup/46453_0.txt\n",
            "aclImdb/train/unsup/46452_0.txt\n",
            "aclImdb/train/unsup/46451_0.txt\n",
            "aclImdb/train/unsup/46450_0.txt\n",
            "aclImdb/train/unsup/46449_0.txt\n",
            "aclImdb/train/unsup/46448_0.txt\n",
            "aclImdb/train/unsup/46447_0.txt\n",
            "aclImdb/train/unsup/46446_0.txt\n",
            "aclImdb/train/unsup/46445_0.txt\n",
            "aclImdb/train/unsup/46444_0.txt\n",
            "aclImdb/train/unsup/46443_0.txt\n",
            "aclImdb/train/unsup/46442_0.txt\n",
            "aclImdb/train/unsup/46441_0.txt\n",
            "aclImdb/train/unsup/46440_0.txt\n",
            "aclImdb/train/unsup/46439_0.txt\n",
            "aclImdb/train/unsup/46438_0.txt\n",
            "aclImdb/train/unsup/46437_0.txt\n",
            "aclImdb/train/unsup/46436_0.txt\n",
            "aclImdb/train/unsup/46435_0.txt\n",
            "aclImdb/train/unsup/46434_0.txt\n",
            "aclImdb/train/unsup/46433_0.txt\n",
            "aclImdb/train/unsup/46432_0.txt\n",
            "aclImdb/train/unsup/46431_0.txt\n",
            "aclImdb/train/unsup/46430_0.txt\n",
            "aclImdb/train/unsup/46429_0.txt\n",
            "aclImdb/train/unsup/46428_0.txt\n",
            "aclImdb/train/unsup/46427_0.txt\n",
            "aclImdb/train/unsup/46426_0.txt\n",
            "aclImdb/train/unsup/46425_0.txt\n",
            "aclImdb/train/unsup/46424_0.txt\n",
            "aclImdb/train/unsup/46423_0.txt\n",
            "aclImdb/train/unsup/46422_0.txt\n",
            "aclImdb/train/unsup/46421_0.txt\n",
            "aclImdb/train/unsup/46420_0.txt\n",
            "aclImdb/train/unsup/46419_0.txt\n",
            "aclImdb/train/unsup/46418_0.txt\n",
            "aclImdb/train/unsup/46417_0.txt\n",
            "aclImdb/train/unsup/46416_0.txt\n",
            "aclImdb/train/unsup/46415_0.txt\n",
            "aclImdb/train/unsup/46414_0.txt\n",
            "aclImdb/train/unsup/46413_0.txt\n",
            "aclImdb/train/unsup/46412_0.txt\n",
            "aclImdb/train/unsup/46411_0.txt\n",
            "aclImdb/train/unsup/46410_0.txt\n",
            "aclImdb/train/unsup/46409_0.txt\n",
            "aclImdb/train/unsup/46408_0.txt\n",
            "aclImdb/train/unsup/46407_0.txt\n",
            "aclImdb/train/unsup/46406_0.txt\n",
            "aclImdb/train/unsup/46405_0.txt\n",
            "aclImdb/train/unsup/46404_0.txt\n",
            "aclImdb/train/unsup/46403_0.txt\n",
            "aclImdb/train/unsup/46402_0.txt\n",
            "aclImdb/train/unsup/46401_0.txt\n",
            "aclImdb/train/unsup/46400_0.txt\n",
            "aclImdb/train/unsup/46399_0.txt\n",
            "aclImdb/train/unsup/46398_0.txt\n",
            "aclImdb/train/unsup/46397_0.txt\n",
            "aclImdb/train/unsup/46396_0.txt\n",
            "aclImdb/train/unsup/46395_0.txt\n",
            "aclImdb/train/unsup/46394_0.txt\n",
            "aclImdb/train/unsup/46393_0.txt\n",
            "aclImdb/train/unsup/46392_0.txt\n",
            "aclImdb/train/unsup/46391_0.txt\n",
            "aclImdb/train/unsup/46390_0.txt\n",
            "aclImdb/train/unsup/46389_0.txt\n",
            "aclImdb/train/unsup/46388_0.txt\n",
            "aclImdb/train/unsup/46387_0.txt\n",
            "aclImdb/train/unsup/46386_0.txt\n",
            "aclImdb/train/unsup/46385_0.txt\n",
            "aclImdb/train/unsup/46384_0.txt\n",
            "aclImdb/train/unsup/46383_0.txt\n",
            "aclImdb/train/unsup/46382_0.txt\n",
            "aclImdb/train/unsup/46381_0.txt\n",
            "aclImdb/train/unsup/46380_0.txt\n",
            "aclImdb/train/unsup/46379_0.txt\n",
            "aclImdb/train/unsup/46378_0.txt\n",
            "aclImdb/train/unsup/46377_0.txt\n",
            "aclImdb/train/unsup/46376_0.txt\n",
            "aclImdb/train/unsup/46375_0.txt\n",
            "aclImdb/train/unsup/46374_0.txt\n",
            "aclImdb/train/unsup/46373_0.txt\n",
            "aclImdb/train/unsup/46372_0.txt\n",
            "aclImdb/train/unsup/46371_0.txt\n",
            "aclImdb/train/unsup/46370_0.txt\n",
            "aclImdb/train/unsup/46369_0.txt\n",
            "aclImdb/train/unsup/46368_0.txt\n",
            "aclImdb/train/unsup/46367_0.txt\n",
            "aclImdb/train/unsup/46366_0.txt\n",
            "aclImdb/train/unsup/46365_0.txt\n",
            "aclImdb/train/unsup/46364_0.txt\n",
            "aclImdb/train/unsup/46363_0.txt\n",
            "aclImdb/train/unsup/46362_0.txt\n",
            "aclImdb/train/unsup/46361_0.txt\n",
            "aclImdb/train/unsup/46360_0.txt\n",
            "aclImdb/train/unsup/46359_0.txt\n",
            "aclImdb/train/unsup/46358_0.txt\n",
            "aclImdb/train/unsup/46357_0.txt\n",
            "aclImdb/train/unsup/46356_0.txt\n",
            "aclImdb/train/unsup/46355_0.txt\n",
            "aclImdb/train/unsup/46354_0.txt\n",
            "aclImdb/train/unsup/46353_0.txt\n",
            "aclImdb/train/unsup/46352_0.txt\n",
            "aclImdb/train/unsup/46351_0.txt\n",
            "aclImdb/train/unsup/46350_0.txt\n",
            "aclImdb/train/unsup/46349_0.txt\n",
            "aclImdb/train/unsup/46348_0.txt\n",
            "aclImdb/train/unsup/46347_0.txt\n",
            "aclImdb/train/unsup/46346_0.txt\n",
            "aclImdb/train/unsup/46345_0.txt\n",
            "aclImdb/train/unsup/46344_0.txt\n",
            "aclImdb/train/unsup/46343_0.txt\n",
            "aclImdb/train/unsup/46342_0.txt\n",
            "aclImdb/train/unsup/46341_0.txt\n",
            "aclImdb/train/unsup/46340_0.txt\n",
            "aclImdb/train/unsup/46339_0.txt\n",
            "aclImdb/train/unsup/46338_0.txt\n",
            "aclImdb/train/unsup/46337_0.txt\n",
            "aclImdb/train/unsup/46336_0.txt\n",
            "aclImdb/train/unsup/46591_0.txt\n",
            "aclImdb/train/unsup/46590_0.txt\n",
            "aclImdb/train/unsup/46589_0.txt\n",
            "aclImdb/train/unsup/46588_0.txt\n",
            "aclImdb/train/unsup/46587_0.txt\n",
            "aclImdb/train/unsup/46586_0.txt\n",
            "aclImdb/train/unsup/46585_0.txt\n",
            "aclImdb/train/unsup/46584_0.txt\n",
            "aclImdb/train/unsup/46583_0.txt\n",
            "aclImdb/train/unsup/46582_0.txt\n",
            "aclImdb/train/unsup/46581_0.txt\n",
            "aclImdb/train/unsup/46580_0.txt\n",
            "aclImdb/train/unsup/46579_0.txt\n",
            "aclImdb/train/unsup/46578_0.txt\n",
            "aclImdb/train/unsup/46577_0.txt\n",
            "aclImdb/train/unsup/46576_0.txt\n",
            "aclImdb/train/unsup/46575_0.txt\n",
            "aclImdb/train/unsup/46574_0.txt\n",
            "aclImdb/train/unsup/46573_0.txt\n",
            "aclImdb/train/unsup/46572_0.txt\n",
            "aclImdb/train/unsup/46571_0.txt\n",
            "aclImdb/train/unsup/46570_0.txt\n",
            "aclImdb/train/unsup/46569_0.txt\n",
            "aclImdb/train/unsup/46568_0.txt\n",
            "aclImdb/train/unsup/46567_0.txt\n",
            "aclImdb/train/unsup/46566_0.txt\n",
            "aclImdb/train/unsup/46565_0.txt\n",
            "aclImdb/train/unsup/46564_0.txt\n",
            "aclImdb/train/unsup/46563_0.txt\n",
            "aclImdb/train/unsup/46562_0.txt\n",
            "aclImdb/train/unsup/46561_0.txt\n",
            "aclImdb/train/unsup/46560_0.txt\n",
            "aclImdb/train/unsup/46559_0.txt\n",
            "aclImdb/train/unsup/46558_0.txt\n",
            "aclImdb/train/unsup/46557_0.txt\n",
            "aclImdb/train/unsup/46556_0.txt\n",
            "aclImdb/train/unsup/46555_0.txt\n",
            "aclImdb/train/unsup/46554_0.txt\n",
            "aclImdb/train/unsup/46553_0.txt\n",
            "aclImdb/train/unsup/46552_0.txt\n",
            "aclImdb/train/unsup/46551_0.txt\n",
            "aclImdb/train/unsup/46550_0.txt\n",
            "aclImdb/train/unsup/46549_0.txt\n",
            "aclImdb/train/unsup/46548_0.txt\n",
            "aclImdb/train/unsup/46547_0.txt\n",
            "aclImdb/train/unsup/46546_0.txt\n",
            "aclImdb/train/unsup/46545_0.txt\n",
            "aclImdb/train/unsup/46544_0.txt\n",
            "aclImdb/train/unsup/46543_0.txt\n",
            "aclImdb/train/unsup/46542_0.txt\n",
            "aclImdb/train/unsup/46541_0.txt\n",
            "aclImdb/train/unsup/46540_0.txt\n",
            "aclImdb/train/unsup/46539_0.txt\n",
            "aclImdb/train/unsup/46538_0.txt\n",
            "aclImdb/train/unsup/46537_0.txt\n",
            "aclImdb/train/unsup/46536_0.txt\n",
            "aclImdb/train/unsup/46535_0.txt\n",
            "aclImdb/train/unsup/46534_0.txt\n",
            "aclImdb/train/unsup/46533_0.txt\n",
            "aclImdb/train/unsup/46532_0.txt\n",
            "aclImdb/train/unsup/46531_0.txt\n",
            "aclImdb/train/unsup/46530_0.txt\n",
            "aclImdb/train/unsup/46529_0.txt\n",
            "aclImdb/train/unsup/46528_0.txt\n",
            "aclImdb/train/unsup/46527_0.txt\n",
            "aclImdb/train/unsup/46526_0.txt\n",
            "aclImdb/train/unsup/46525_0.txt\n",
            "aclImdb/train/unsup/46524_0.txt\n",
            "aclImdb/train/unsup/46523_0.txt\n",
            "aclImdb/train/unsup/46522_0.txt\n",
            "aclImdb/train/unsup/46521_0.txt\n",
            "aclImdb/train/unsup/46520_0.txt\n",
            "aclImdb/train/unsup/46519_0.txt\n",
            "aclImdb/train/unsup/46518_0.txt\n",
            "aclImdb/train/unsup/46517_0.txt\n",
            "aclImdb/train/unsup/46516_0.txt\n",
            "aclImdb/train/unsup/46515_0.txt\n",
            "aclImdb/train/unsup/46514_0.txt\n",
            "aclImdb/train/unsup/46513_0.txt\n",
            "aclImdb/train/unsup/46512_0.txt\n",
            "aclImdb/train/unsup/46511_0.txt\n",
            "aclImdb/train/unsup/46510_0.txt\n",
            "aclImdb/train/unsup/46509_0.txt\n",
            "aclImdb/train/unsup/46508_0.txt\n",
            "aclImdb/train/unsup/46507_0.txt\n",
            "aclImdb/train/unsup/46506_0.txt\n",
            "aclImdb/train/unsup/46505_0.txt\n",
            "aclImdb/train/unsup/46504_0.txt\n",
            "aclImdb/train/unsup/46503_0.txt\n",
            "aclImdb/train/unsup/46502_0.txt\n",
            "aclImdb/train/unsup/46501_0.txt\n",
            "aclImdb/train/unsup/46500_0.txt\n",
            "aclImdb/train/unsup/46499_0.txt\n",
            "aclImdb/train/unsup/46498_0.txt\n",
            "aclImdb/train/unsup/46497_0.txt\n",
            "aclImdb/train/unsup/46496_0.txt\n",
            "aclImdb/train/unsup/46495_0.txt\n",
            "aclImdb/train/unsup/46494_0.txt\n",
            "aclImdb/train/unsup/46493_0.txt\n",
            "aclImdb/train/unsup/46492_0.txt\n",
            "aclImdb/train/unsup/46491_0.txt\n",
            "aclImdb/train/unsup/46490_0.txt\n",
            "aclImdb/train/unsup/46489_0.txt\n",
            "aclImdb/train/unsup/46488_0.txt\n",
            "aclImdb/train/unsup/46487_0.txt\n",
            "aclImdb/train/unsup/46486_0.txt\n",
            "aclImdb/train/unsup/46485_0.txt\n",
            "aclImdb/train/unsup/46484_0.txt\n",
            "aclImdb/train/unsup/46483_0.txt\n",
            "aclImdb/train/unsup/46482_0.txt\n",
            "aclImdb/train/unsup/46481_0.txt\n",
            "aclImdb/train/unsup/46480_0.txt\n",
            "aclImdb/train/unsup/46479_0.txt\n",
            "aclImdb/train/unsup/46478_0.txt\n",
            "aclImdb/train/unsup/46477_0.txt\n",
            "aclImdb/train/unsup/46476_0.txt\n",
            "aclImdb/train/unsup/46475_0.txt\n",
            "aclImdb/train/unsup/46474_0.txt\n",
            "aclImdb/train/unsup/46473_0.txt\n",
            "aclImdb/train/unsup/46472_0.txt\n",
            "aclImdb/train/unsup/46471_0.txt\n",
            "aclImdb/train/unsup/46470_0.txt\n",
            "aclImdb/train/unsup/46469_0.txt\n",
            "aclImdb/train/unsup/46468_0.txt\n",
            "aclImdb/train/unsup/46467_0.txt\n",
            "aclImdb/train/unsup/46466_0.txt\n",
            "aclImdb/train/unsup/46465_0.txt\n",
            "aclImdb/train/unsup/46464_0.txt\n",
            "aclImdb/train/unsup/46719_0.txt\n",
            "aclImdb/train/unsup/46718_0.txt\n",
            "aclImdb/train/unsup/46717_0.txt\n",
            "aclImdb/train/unsup/46716_0.txt\n",
            "aclImdb/train/unsup/46715_0.txt\n",
            "aclImdb/train/unsup/46714_0.txt\n",
            "aclImdb/train/unsup/46713_0.txt\n",
            "aclImdb/train/unsup/46712_0.txt\n",
            "aclImdb/train/unsup/46711_0.txt\n",
            "aclImdb/train/unsup/46710_0.txt\n",
            "aclImdb/train/unsup/46709_0.txt\n",
            "aclImdb/train/unsup/46708_0.txt\n",
            "aclImdb/train/unsup/46707_0.txt\n",
            "aclImdb/train/unsup/46706_0.txt\n",
            "aclImdb/train/unsup/46705_0.txt\n",
            "aclImdb/train/unsup/46704_0.txt\n",
            "aclImdb/train/unsup/46703_0.txt\n",
            "aclImdb/train/unsup/46702_0.txt\n",
            "aclImdb/train/unsup/46701_0.txt\n",
            "aclImdb/train/unsup/46700_0.txt\n",
            "aclImdb/train/unsup/46699_0.txt\n",
            "aclImdb/train/unsup/46698_0.txt\n",
            "aclImdb/train/unsup/46697_0.txt\n",
            "aclImdb/train/unsup/46696_0.txt\n",
            "aclImdb/train/unsup/46695_0.txt\n",
            "aclImdb/train/unsup/46694_0.txt\n",
            "aclImdb/train/unsup/46693_0.txt\n",
            "aclImdb/train/unsup/46692_0.txt\n",
            "aclImdb/train/unsup/46691_0.txt\n",
            "aclImdb/train/unsup/46690_0.txt\n",
            "aclImdb/train/unsup/46689_0.txt\n",
            "aclImdb/train/unsup/46688_0.txt\n",
            "aclImdb/train/unsup/46687_0.txt\n",
            "aclImdb/train/unsup/46686_0.txt\n",
            "aclImdb/train/unsup/46685_0.txt\n",
            "aclImdb/train/unsup/46684_0.txt\n",
            "aclImdb/train/unsup/46683_0.txt\n",
            "aclImdb/train/unsup/46682_0.txt\n",
            "aclImdb/train/unsup/46681_0.txt\n",
            "aclImdb/train/unsup/46680_0.txt\n",
            "aclImdb/train/unsup/46679_0.txt\n",
            "aclImdb/train/unsup/46678_0.txt\n",
            "aclImdb/train/unsup/46677_0.txt\n",
            "aclImdb/train/unsup/46676_0.txt\n",
            "aclImdb/train/unsup/46675_0.txt\n",
            "aclImdb/train/unsup/46674_0.txt\n",
            "aclImdb/train/unsup/46673_0.txt\n",
            "aclImdb/train/unsup/46672_0.txt\n",
            "aclImdb/train/unsup/46671_0.txt\n",
            "aclImdb/train/unsup/46670_0.txt\n",
            "aclImdb/train/unsup/46669_0.txt\n",
            "aclImdb/train/unsup/46668_0.txt\n",
            "aclImdb/train/unsup/46667_0.txt\n",
            "aclImdb/train/unsup/46666_0.txt\n",
            "aclImdb/train/unsup/46665_0.txt\n",
            "aclImdb/train/unsup/46664_0.txt\n",
            "aclImdb/train/unsup/46663_0.txt\n",
            "aclImdb/train/unsup/46662_0.txt\n",
            "aclImdb/train/unsup/46661_0.txt\n",
            "aclImdb/train/unsup/46660_0.txt\n",
            "aclImdb/train/unsup/46659_0.txt\n",
            "aclImdb/train/unsup/46658_0.txt\n",
            "aclImdb/train/unsup/46657_0.txt\n",
            "aclImdb/train/unsup/46656_0.txt\n",
            "aclImdb/train/unsup/46655_0.txt\n",
            "aclImdb/train/unsup/46654_0.txt\n",
            "aclImdb/train/unsup/46653_0.txt\n",
            "aclImdb/train/unsup/46652_0.txt\n",
            "aclImdb/train/unsup/46651_0.txt\n",
            "aclImdb/train/unsup/46650_0.txt\n",
            "aclImdb/train/unsup/46649_0.txt\n",
            "aclImdb/train/unsup/46648_0.txt\n",
            "aclImdb/train/unsup/46647_0.txt\n",
            "aclImdb/train/unsup/46646_0.txt\n",
            "aclImdb/train/unsup/46645_0.txt\n",
            "aclImdb/train/unsup/46644_0.txt\n",
            "aclImdb/train/unsup/46643_0.txt\n",
            "aclImdb/train/unsup/46642_0.txt\n",
            "aclImdb/train/unsup/46641_0.txt\n",
            "aclImdb/train/unsup/46640_0.txt\n",
            "aclImdb/train/unsup/46639_0.txt\n",
            "aclImdb/train/unsup/46638_0.txt\n",
            "aclImdb/train/unsup/46637_0.txt\n",
            "aclImdb/train/unsup/46636_0.txt\n",
            "aclImdb/train/unsup/46635_0.txt\n",
            "aclImdb/train/unsup/46634_0.txt\n",
            "aclImdb/train/unsup/46633_0.txt\n",
            "aclImdb/train/unsup/46632_0.txt\n",
            "aclImdb/train/unsup/46631_0.txt\n",
            "aclImdb/train/unsup/46630_0.txt\n",
            "aclImdb/train/unsup/46629_0.txt\n",
            "aclImdb/train/unsup/46628_0.txt\n",
            "aclImdb/train/unsup/46627_0.txt\n",
            "aclImdb/train/unsup/46626_0.txt\n",
            "aclImdb/train/unsup/46625_0.txt\n",
            "aclImdb/train/unsup/46624_0.txt\n",
            "aclImdb/train/unsup/46623_0.txt\n",
            "aclImdb/train/unsup/46622_0.txt\n",
            "aclImdb/train/unsup/46621_0.txt\n",
            "aclImdb/train/unsup/46620_0.txt\n",
            "aclImdb/train/unsup/46619_0.txt\n",
            "aclImdb/train/unsup/46618_0.txt\n",
            "aclImdb/train/unsup/46617_0.txt\n",
            "aclImdb/train/unsup/46616_0.txt\n",
            "aclImdb/train/unsup/46615_0.txt\n",
            "aclImdb/train/unsup/46614_0.txt\n",
            "aclImdb/train/unsup/46613_0.txt\n",
            "aclImdb/train/unsup/46612_0.txt\n",
            "aclImdb/train/unsup/46611_0.txt\n",
            "aclImdb/train/unsup/46610_0.txt\n",
            "aclImdb/train/unsup/46609_0.txt\n",
            "aclImdb/train/unsup/46608_0.txt\n",
            "aclImdb/train/unsup/46607_0.txt\n",
            "aclImdb/train/unsup/46606_0.txt\n",
            "aclImdb/train/unsup/46605_0.txt\n",
            "aclImdb/train/unsup/46604_0.txt\n",
            "aclImdb/train/unsup/46603_0.txt\n",
            "aclImdb/train/unsup/46602_0.txt\n",
            "aclImdb/train/unsup/46601_0.txt\n",
            "aclImdb/train/unsup/46600_0.txt\n",
            "aclImdb/train/unsup/46599_0.txt\n",
            "aclImdb/train/unsup/46598_0.txt\n",
            "aclImdb/train/unsup/46597_0.txt\n",
            "aclImdb/train/unsup/46596_0.txt\n",
            "aclImdb/train/unsup/46595_0.txt\n",
            "aclImdb/train/unsup/46594_0.txt\n",
            "aclImdb/train/unsup/46593_0.txt\n",
            "aclImdb/train/unsup/46592_0.txt\n",
            "aclImdb/train/unsup/46847_0.txt\n",
            "aclImdb/train/unsup/46846_0.txt\n",
            "aclImdb/train/unsup/46845_0.txt\n",
            "aclImdb/train/unsup/46844_0.txt\n",
            "aclImdb/train/unsup/46843_0.txt\n",
            "aclImdb/train/unsup/46842_0.txt\n",
            "aclImdb/train/unsup/46841_0.txt\n",
            "aclImdb/train/unsup/46840_0.txt\n",
            "aclImdb/train/unsup/46839_0.txt\n",
            "aclImdb/train/unsup/46838_0.txt\n",
            "aclImdb/train/unsup/46837_0.txt\n",
            "aclImdb/train/unsup/46836_0.txt\n",
            "aclImdb/train/unsup/46835_0.txt\n",
            "aclImdb/train/unsup/46834_0.txt\n",
            "aclImdb/train/unsup/46833_0.txt\n",
            "aclImdb/train/unsup/46832_0.txt\n",
            "aclImdb/train/unsup/46831_0.txt\n",
            "aclImdb/train/unsup/46830_0.txt\n",
            "aclImdb/train/unsup/46829_0.txt\n",
            "aclImdb/train/unsup/46828_0.txt\n",
            "aclImdb/train/unsup/46827_0.txt\n",
            "aclImdb/train/unsup/46826_0.txt\n",
            "aclImdb/train/unsup/46825_0.txt\n",
            "aclImdb/train/unsup/46824_0.txt\n",
            "aclImdb/train/unsup/46823_0.txt\n",
            "aclImdb/train/unsup/46822_0.txt\n",
            "aclImdb/train/unsup/46821_0.txt\n",
            "aclImdb/train/unsup/46820_0.txt\n",
            "aclImdb/train/unsup/46819_0.txt\n",
            "aclImdb/train/unsup/46818_0.txt\n",
            "aclImdb/train/unsup/46817_0.txt\n",
            "aclImdb/train/unsup/46816_0.txt\n",
            "aclImdb/train/unsup/46815_0.txt\n",
            "aclImdb/train/unsup/46814_0.txt\n",
            "aclImdb/train/unsup/46813_0.txt\n",
            "aclImdb/train/unsup/46812_0.txt\n",
            "aclImdb/train/unsup/46811_0.txt\n",
            "aclImdb/train/unsup/46810_0.txt\n",
            "aclImdb/train/unsup/46809_0.txt\n",
            "aclImdb/train/unsup/46808_0.txt\n",
            "aclImdb/train/unsup/46807_0.txt\n",
            "aclImdb/train/unsup/46806_0.txt\n",
            "aclImdb/train/unsup/46805_0.txt\n",
            "aclImdb/train/unsup/46804_0.txt\n",
            "aclImdb/train/unsup/46803_0.txt\n",
            "aclImdb/train/unsup/46802_0.txt\n",
            "aclImdb/train/unsup/46801_0.txt\n",
            "aclImdb/train/unsup/46800_0.txt\n",
            "aclImdb/train/unsup/46799_0.txt\n",
            "aclImdb/train/unsup/46798_0.txt\n",
            "aclImdb/train/unsup/46797_0.txt\n",
            "aclImdb/train/unsup/46796_0.txt\n",
            "aclImdb/train/unsup/46795_0.txt\n",
            "aclImdb/train/unsup/46794_0.txt\n",
            "aclImdb/train/unsup/46793_0.txt\n",
            "aclImdb/train/unsup/46792_0.txt\n",
            "aclImdb/train/unsup/46791_0.txt\n",
            "aclImdb/train/unsup/46790_0.txt\n",
            "aclImdb/train/unsup/46789_0.txt\n",
            "aclImdb/train/unsup/46788_0.txt\n",
            "aclImdb/train/unsup/46787_0.txt\n",
            "aclImdb/train/unsup/46786_0.txt\n",
            "aclImdb/train/unsup/46785_0.txt\n",
            "aclImdb/train/unsup/46784_0.txt\n",
            "aclImdb/train/unsup/46783_0.txt\n",
            "aclImdb/train/unsup/46782_0.txt\n",
            "aclImdb/train/unsup/46781_0.txt\n",
            "aclImdb/train/unsup/46780_0.txt\n",
            "aclImdb/train/unsup/46779_0.txt\n",
            "aclImdb/train/unsup/46778_0.txt\n",
            "aclImdb/train/unsup/46777_0.txt\n",
            "aclImdb/train/unsup/46776_0.txt\n",
            "aclImdb/train/unsup/46775_0.txt\n",
            "aclImdb/train/unsup/46774_0.txt\n",
            "aclImdb/train/unsup/46773_0.txt\n",
            "aclImdb/train/unsup/46772_0.txt\n",
            "aclImdb/train/unsup/46771_0.txt\n",
            "aclImdb/train/unsup/46770_0.txt\n",
            "aclImdb/train/unsup/46769_0.txt\n",
            "aclImdb/train/unsup/46768_0.txt\n",
            "aclImdb/train/unsup/46767_0.txt\n",
            "aclImdb/train/unsup/46766_0.txt\n",
            "aclImdb/train/unsup/46765_0.txt\n",
            "aclImdb/train/unsup/46764_0.txt\n",
            "aclImdb/train/unsup/46763_0.txt\n",
            "aclImdb/train/unsup/46762_0.txt\n",
            "aclImdb/train/unsup/46761_0.txt\n",
            "aclImdb/train/unsup/46760_0.txt\n",
            "aclImdb/train/unsup/46759_0.txt\n",
            "aclImdb/train/unsup/46758_0.txt\n",
            "aclImdb/train/unsup/46757_0.txt\n",
            "aclImdb/train/unsup/46756_0.txt\n",
            "aclImdb/train/unsup/46755_0.txt\n",
            "aclImdb/train/unsup/46754_0.txt\n",
            "aclImdb/train/unsup/46753_0.txt\n",
            "aclImdb/train/unsup/46752_0.txt\n",
            "aclImdb/train/unsup/46751_0.txt\n",
            "aclImdb/train/unsup/46750_0.txt\n",
            "aclImdb/train/unsup/46749_0.txt\n",
            "aclImdb/train/unsup/46748_0.txt\n",
            "aclImdb/train/unsup/46747_0.txt\n",
            "aclImdb/train/unsup/46746_0.txt\n",
            "aclImdb/train/unsup/46745_0.txt\n",
            "aclImdb/train/unsup/46744_0.txt\n",
            "aclImdb/train/unsup/46743_0.txt\n",
            "aclImdb/train/unsup/46742_0.txt\n",
            "aclImdb/train/unsup/46741_0.txt\n",
            "aclImdb/train/unsup/46740_0.txt\n",
            "aclImdb/train/unsup/46739_0.txt\n",
            "aclImdb/train/unsup/46738_0.txt\n",
            "aclImdb/train/unsup/46737_0.txt\n",
            "aclImdb/train/unsup/46736_0.txt\n",
            "aclImdb/train/unsup/46735_0.txt\n",
            "aclImdb/train/unsup/46734_0.txt\n",
            "aclImdb/train/unsup/46733_0.txt\n",
            "aclImdb/train/unsup/46732_0.txt\n",
            "aclImdb/train/unsup/46731_0.txt\n",
            "aclImdb/train/unsup/46730_0.txt\n",
            "aclImdb/train/unsup/46729_0.txt\n",
            "aclImdb/train/unsup/46728_0.txt\n",
            "aclImdb/train/unsup/46727_0.txt\n",
            "aclImdb/train/unsup/46726_0.txt\n",
            "aclImdb/train/unsup/46725_0.txt\n",
            "aclImdb/train/unsup/46724_0.txt\n",
            "aclImdb/train/unsup/46723_0.txt\n",
            "aclImdb/train/unsup/46722_0.txt\n",
            "aclImdb/train/unsup/46721_0.txt\n",
            "aclImdb/train/unsup/46720_0.txt\n",
            "aclImdb/train/unsup/46975_0.txt\n",
            "aclImdb/train/unsup/46974_0.txt\n",
            "aclImdb/train/unsup/46973_0.txt\n",
            "aclImdb/train/unsup/46972_0.txt\n",
            "aclImdb/train/unsup/46971_0.txt\n",
            "aclImdb/train/unsup/46970_0.txt\n",
            "aclImdb/train/unsup/46969_0.txt\n",
            "aclImdb/train/unsup/46968_0.txt\n",
            "aclImdb/train/unsup/46967_0.txt\n",
            "aclImdb/train/unsup/46966_0.txt\n",
            "aclImdb/train/unsup/46965_0.txt\n",
            "aclImdb/train/unsup/46964_0.txt\n",
            "aclImdb/train/unsup/46963_0.txt\n",
            "aclImdb/train/unsup/46962_0.txt\n",
            "aclImdb/train/unsup/46961_0.txt\n",
            "aclImdb/train/unsup/46960_0.txt\n",
            "aclImdb/train/unsup/46959_0.txt\n",
            "aclImdb/train/unsup/46958_0.txt\n",
            "aclImdb/train/unsup/46957_0.txt\n",
            "aclImdb/train/unsup/46956_0.txt\n",
            "aclImdb/train/unsup/46955_0.txt\n",
            "aclImdb/train/unsup/46954_0.txt\n",
            "aclImdb/train/unsup/46953_0.txt\n",
            "aclImdb/train/unsup/46952_0.txt\n",
            "aclImdb/train/unsup/46951_0.txt\n",
            "aclImdb/train/unsup/46950_0.txt\n",
            "aclImdb/train/unsup/46949_0.txt\n",
            "aclImdb/train/unsup/46948_0.txt\n",
            "aclImdb/train/unsup/46947_0.txt\n",
            "aclImdb/train/unsup/46946_0.txt\n",
            "aclImdb/train/unsup/46945_0.txt\n",
            "aclImdb/train/unsup/46944_0.txt\n",
            "aclImdb/train/unsup/46943_0.txt\n",
            "aclImdb/train/unsup/46942_0.txt\n",
            "aclImdb/train/unsup/46941_0.txt\n",
            "aclImdb/train/unsup/46940_0.txt\n",
            "aclImdb/train/unsup/46939_0.txt\n",
            "aclImdb/train/unsup/46938_0.txt\n",
            "aclImdb/train/unsup/46937_0.txt\n",
            "aclImdb/train/unsup/46936_0.txt\n",
            "aclImdb/train/unsup/46935_0.txt\n",
            "aclImdb/train/unsup/46934_0.txt\n",
            "aclImdb/train/unsup/46933_0.txt\n",
            "aclImdb/train/unsup/46932_0.txt\n",
            "aclImdb/train/unsup/46931_0.txt\n",
            "aclImdb/train/unsup/46930_0.txt\n",
            "aclImdb/train/unsup/46929_0.txt\n",
            "aclImdb/train/unsup/46928_0.txt\n",
            "aclImdb/train/unsup/46927_0.txt\n",
            "aclImdb/train/unsup/46926_0.txt\n",
            "aclImdb/train/unsup/46925_0.txt\n",
            "aclImdb/train/unsup/46924_0.txt\n",
            "aclImdb/train/unsup/46923_0.txt\n",
            "aclImdb/train/unsup/46922_0.txt\n",
            "aclImdb/train/unsup/46921_0.txt\n",
            "aclImdb/train/unsup/46920_0.txt\n",
            "aclImdb/train/unsup/46919_0.txt\n",
            "aclImdb/train/unsup/46918_0.txt\n",
            "aclImdb/train/unsup/46917_0.txt\n",
            "aclImdb/train/unsup/46916_0.txt\n",
            "aclImdb/train/unsup/46915_0.txt\n",
            "aclImdb/train/unsup/46914_0.txt\n",
            "aclImdb/train/unsup/46913_0.txt\n",
            "aclImdb/train/unsup/46912_0.txt\n",
            "aclImdb/train/unsup/46911_0.txt\n",
            "aclImdb/train/unsup/46910_0.txt\n",
            "aclImdb/train/unsup/46909_0.txt\n",
            "aclImdb/train/unsup/46908_0.txt\n",
            "aclImdb/train/unsup/46907_0.txt\n",
            "aclImdb/train/unsup/46906_0.txt\n",
            "aclImdb/train/unsup/46905_0.txt\n",
            "aclImdb/train/unsup/46904_0.txt\n",
            "aclImdb/train/unsup/46903_0.txt\n",
            "aclImdb/train/unsup/46902_0.txt\n",
            "aclImdb/train/unsup/46901_0.txt\n",
            "aclImdb/train/unsup/46900_0.txt\n",
            "aclImdb/train/unsup/46899_0.txt\n",
            "aclImdb/train/unsup/46898_0.txt\n",
            "aclImdb/train/unsup/46897_0.txt\n",
            "aclImdb/train/unsup/46896_0.txt\n",
            "aclImdb/train/unsup/46895_0.txt\n",
            "aclImdb/train/unsup/46894_0.txt\n",
            "aclImdb/train/unsup/46893_0.txt\n",
            "aclImdb/train/unsup/46892_0.txt\n",
            "aclImdb/train/unsup/46891_0.txt\n",
            "aclImdb/train/unsup/46890_0.txt\n",
            "aclImdb/train/unsup/46889_0.txt\n",
            "aclImdb/train/unsup/46888_0.txt\n",
            "aclImdb/train/unsup/46887_0.txt\n",
            "aclImdb/train/unsup/46886_0.txt\n",
            "aclImdb/train/unsup/46885_0.txt\n",
            "aclImdb/train/unsup/46884_0.txt\n",
            "aclImdb/train/unsup/46883_0.txt\n",
            "aclImdb/train/unsup/46882_0.txt\n",
            "aclImdb/train/unsup/46881_0.txt\n",
            "aclImdb/train/unsup/46880_0.txt\n",
            "aclImdb/train/unsup/46879_0.txt\n",
            "aclImdb/train/unsup/46878_0.txt\n",
            "aclImdb/train/unsup/46877_0.txt\n",
            "aclImdb/train/unsup/46876_0.txt\n",
            "aclImdb/train/unsup/46875_0.txt\n",
            "aclImdb/train/unsup/46874_0.txt\n",
            "aclImdb/train/unsup/46873_0.txt\n",
            "aclImdb/train/unsup/46872_0.txt\n",
            "aclImdb/train/unsup/46871_0.txt\n",
            "aclImdb/train/unsup/46870_0.txt\n",
            "aclImdb/train/unsup/46869_0.txt\n",
            "aclImdb/train/unsup/46868_0.txt\n",
            "aclImdb/train/unsup/46867_0.txt\n",
            "aclImdb/train/unsup/46866_0.txt\n",
            "aclImdb/train/unsup/46865_0.txt\n",
            "aclImdb/train/unsup/46864_0.txt\n",
            "aclImdb/train/unsup/46863_0.txt\n",
            "aclImdb/train/unsup/46862_0.txt\n",
            "aclImdb/train/unsup/46861_0.txt\n",
            "aclImdb/train/unsup/46860_0.txt\n",
            "aclImdb/train/unsup/46859_0.txt\n",
            "aclImdb/train/unsup/46858_0.txt\n",
            "aclImdb/train/unsup/46857_0.txt\n",
            "aclImdb/train/unsup/46856_0.txt\n",
            "aclImdb/train/unsup/46855_0.txt\n",
            "aclImdb/train/unsup/46854_0.txt\n",
            "aclImdb/train/unsup/46853_0.txt\n",
            "aclImdb/train/unsup/46852_0.txt\n",
            "aclImdb/train/unsup/46851_0.txt\n",
            "aclImdb/train/unsup/46850_0.txt\n",
            "aclImdb/train/unsup/46849_0.txt\n",
            "aclImdb/train/unsup/46848_0.txt\n",
            "aclImdb/train/unsup/47103_0.txt\n",
            "aclImdb/train/unsup/47102_0.txt\n",
            "aclImdb/train/unsup/47101_0.txt\n",
            "aclImdb/train/unsup/47100_0.txt\n",
            "aclImdb/train/unsup/47099_0.txt\n",
            "aclImdb/train/unsup/47098_0.txt\n",
            "aclImdb/train/unsup/47097_0.txt\n",
            "aclImdb/train/unsup/47096_0.txt\n",
            "aclImdb/train/unsup/47095_0.txt\n",
            "aclImdb/train/unsup/47094_0.txt\n",
            "aclImdb/train/unsup/47093_0.txt\n",
            "aclImdb/train/unsup/47092_0.txt\n",
            "aclImdb/train/unsup/47091_0.txt\n",
            "aclImdb/train/unsup/47090_0.txt\n",
            "aclImdb/train/unsup/47089_0.txt\n",
            "aclImdb/train/unsup/47088_0.txt\n",
            "aclImdb/train/unsup/47087_0.txt\n",
            "aclImdb/train/unsup/47086_0.txt\n",
            "aclImdb/train/unsup/47085_0.txt\n",
            "aclImdb/train/unsup/47084_0.txt\n",
            "aclImdb/train/unsup/47083_0.txt\n",
            "aclImdb/train/unsup/47082_0.txt\n",
            "aclImdb/train/unsup/47081_0.txt\n",
            "aclImdb/train/unsup/47080_0.txt\n",
            "aclImdb/train/unsup/47079_0.txt\n",
            "aclImdb/train/unsup/47078_0.txt\n",
            "aclImdb/train/unsup/47077_0.txt\n",
            "aclImdb/train/unsup/47076_0.txt\n",
            "aclImdb/train/unsup/47075_0.txt\n",
            "aclImdb/train/unsup/47074_0.txt\n",
            "aclImdb/train/unsup/47073_0.txt\n",
            "aclImdb/train/unsup/47072_0.txt\n",
            "aclImdb/train/unsup/47071_0.txt\n",
            "aclImdb/train/unsup/47070_0.txt\n",
            "aclImdb/train/unsup/47069_0.txt\n",
            "aclImdb/train/unsup/47068_0.txt\n",
            "aclImdb/train/unsup/47067_0.txt\n",
            "aclImdb/train/unsup/47066_0.txt\n",
            "aclImdb/train/unsup/47065_0.txt\n",
            "aclImdb/train/unsup/47064_0.txt\n",
            "aclImdb/train/unsup/47063_0.txt\n",
            "aclImdb/train/unsup/47062_0.txt\n",
            "aclImdb/train/unsup/47061_0.txt\n",
            "aclImdb/train/unsup/47060_0.txt\n",
            "aclImdb/train/unsup/47059_0.txt\n",
            "aclImdb/train/unsup/47058_0.txt\n",
            "aclImdb/train/unsup/47057_0.txt\n",
            "aclImdb/train/unsup/47056_0.txt\n",
            "aclImdb/train/unsup/47055_0.txt\n",
            "aclImdb/train/unsup/47054_0.txt\n",
            "aclImdb/train/unsup/47053_0.txt\n",
            "aclImdb/train/unsup/47052_0.txt\n",
            "aclImdb/train/unsup/47051_0.txt\n",
            "aclImdb/train/unsup/47050_0.txt\n",
            "aclImdb/train/unsup/47049_0.txt\n",
            "aclImdb/train/unsup/47048_0.txt\n",
            "aclImdb/train/unsup/47047_0.txt\n",
            "aclImdb/train/unsup/47046_0.txt\n",
            "aclImdb/train/unsup/47045_0.txt\n",
            "aclImdb/train/unsup/47044_0.txt\n",
            "aclImdb/train/unsup/47043_0.txt\n",
            "aclImdb/train/unsup/47042_0.txt\n",
            "aclImdb/train/unsup/47041_0.txt\n",
            "aclImdb/train/unsup/47040_0.txt\n",
            "aclImdb/train/unsup/47039_0.txt\n",
            "aclImdb/train/unsup/47038_0.txt\n",
            "aclImdb/train/unsup/47037_0.txt\n",
            "aclImdb/train/unsup/47036_0.txt\n",
            "aclImdb/train/unsup/47035_0.txt\n",
            "aclImdb/train/unsup/47034_0.txt\n",
            "aclImdb/train/unsup/47033_0.txt\n",
            "aclImdb/train/unsup/47032_0.txt\n",
            "aclImdb/train/unsup/47031_0.txt\n",
            "aclImdb/train/unsup/47030_0.txt\n",
            "aclImdb/train/unsup/47029_0.txt\n",
            "aclImdb/train/unsup/47028_0.txt\n",
            "aclImdb/train/unsup/47027_0.txt\n",
            "aclImdb/train/unsup/47026_0.txt\n",
            "aclImdb/train/unsup/47025_0.txt\n",
            "aclImdb/train/unsup/47024_0.txt\n",
            "aclImdb/train/unsup/47023_0.txt\n",
            "aclImdb/train/unsup/47022_0.txt\n",
            "aclImdb/train/unsup/47021_0.txt\n",
            "aclImdb/train/unsup/47020_0.txt\n",
            "aclImdb/train/unsup/47019_0.txt\n",
            "aclImdb/train/unsup/47018_0.txt\n",
            "aclImdb/train/unsup/47017_0.txt\n",
            "aclImdb/train/unsup/47016_0.txt\n",
            "aclImdb/train/unsup/47015_0.txt\n",
            "aclImdb/train/unsup/47014_0.txt\n",
            "aclImdb/train/unsup/47013_0.txt\n",
            "aclImdb/train/unsup/47012_0.txt\n",
            "aclImdb/train/unsup/47011_0.txt\n",
            "aclImdb/train/unsup/47010_0.txt\n",
            "aclImdb/train/unsup/47009_0.txt\n",
            "aclImdb/train/unsup/47008_0.txt\n",
            "aclImdb/train/unsup/47007_0.txt\n",
            "aclImdb/train/unsup/47006_0.txt\n",
            "aclImdb/train/unsup/47005_0.txt\n",
            "aclImdb/train/unsup/47004_0.txt\n",
            "aclImdb/train/unsup/47003_0.txt\n",
            "aclImdb/train/unsup/47002_0.txt\n",
            "aclImdb/train/unsup/47001_0.txt\n",
            "aclImdb/train/unsup/47000_0.txt\n",
            "aclImdb/train/unsup/46999_0.txt\n",
            "aclImdb/train/unsup/46998_0.txt\n",
            "aclImdb/train/unsup/46997_0.txt\n",
            "aclImdb/train/unsup/46996_0.txt\n",
            "aclImdb/train/unsup/46995_0.txt\n",
            "aclImdb/train/unsup/46994_0.txt\n",
            "aclImdb/train/unsup/46993_0.txt\n",
            "aclImdb/train/unsup/46992_0.txt\n",
            "aclImdb/train/unsup/46991_0.txt\n",
            "aclImdb/train/unsup/46990_0.txt\n",
            "aclImdb/train/unsup/46989_0.txt\n",
            "aclImdb/train/unsup/46988_0.txt\n",
            "aclImdb/train/unsup/46987_0.txt\n",
            "aclImdb/train/unsup/46986_0.txt\n",
            "aclImdb/train/unsup/46985_0.txt\n",
            "aclImdb/train/unsup/46984_0.txt\n",
            "aclImdb/train/unsup/46983_0.txt\n",
            "aclImdb/train/unsup/46982_0.txt\n",
            "aclImdb/train/unsup/46981_0.txt\n",
            "aclImdb/train/unsup/46980_0.txt\n",
            "aclImdb/train/unsup/46979_0.txt\n",
            "aclImdb/train/unsup/46978_0.txt\n",
            "aclImdb/train/unsup/46977_0.txt\n",
            "aclImdb/train/unsup/46976_0.txt\n",
            "aclImdb/train/unsup/47231_0.txt\n",
            "aclImdb/train/unsup/47230_0.txt\n",
            "aclImdb/train/unsup/47229_0.txt\n",
            "aclImdb/train/unsup/47228_0.txt\n",
            "aclImdb/train/unsup/47227_0.txt\n",
            "aclImdb/train/unsup/47226_0.txt\n",
            "aclImdb/train/unsup/47225_0.txt\n",
            "aclImdb/train/unsup/47224_0.txt\n",
            "aclImdb/train/unsup/47223_0.txt\n",
            "aclImdb/train/unsup/47222_0.txt\n",
            "aclImdb/train/unsup/47221_0.txt\n",
            "aclImdb/train/unsup/47220_0.txt\n",
            "aclImdb/train/unsup/47219_0.txt\n",
            "aclImdb/train/unsup/47218_0.txt\n",
            "aclImdb/train/unsup/47217_0.txt\n",
            "aclImdb/train/unsup/47216_0.txt\n",
            "aclImdb/train/unsup/47215_0.txt\n",
            "aclImdb/train/unsup/47214_0.txt\n",
            "aclImdb/train/unsup/47213_0.txt\n",
            "aclImdb/train/unsup/47212_0.txt\n",
            "aclImdb/train/unsup/47211_0.txt\n",
            "aclImdb/train/unsup/47210_0.txt\n",
            "aclImdb/train/unsup/47209_0.txt\n",
            "aclImdb/train/unsup/47208_0.txt\n",
            "aclImdb/train/unsup/47207_0.txt\n",
            "aclImdb/train/unsup/47206_0.txt\n",
            "aclImdb/train/unsup/47205_0.txt\n",
            "aclImdb/train/unsup/47204_0.txt\n",
            "aclImdb/train/unsup/47203_0.txt\n",
            "aclImdb/train/unsup/47202_0.txt\n",
            "aclImdb/train/unsup/47201_0.txt\n",
            "aclImdb/train/unsup/47200_0.txt\n",
            "aclImdb/train/unsup/47199_0.txt\n",
            "aclImdb/train/unsup/47198_0.txt\n",
            "aclImdb/train/unsup/47197_0.txt\n",
            "aclImdb/train/unsup/47196_0.txt\n",
            "aclImdb/train/unsup/47195_0.txt\n",
            "aclImdb/train/unsup/47194_0.txt\n",
            "aclImdb/train/unsup/47193_0.txt\n",
            "aclImdb/train/unsup/47192_0.txt\n",
            "aclImdb/train/unsup/47191_0.txt\n",
            "aclImdb/train/unsup/47190_0.txt\n",
            "aclImdb/train/unsup/47189_0.txt\n",
            "aclImdb/train/unsup/47188_0.txt\n",
            "aclImdb/train/unsup/47187_0.txt\n",
            "aclImdb/train/unsup/47186_0.txt\n",
            "aclImdb/train/unsup/47185_0.txt\n",
            "aclImdb/train/unsup/47184_0.txt\n",
            "aclImdb/train/unsup/47183_0.txt\n",
            "aclImdb/train/unsup/47182_0.txt\n",
            "aclImdb/train/unsup/47181_0.txt\n",
            "aclImdb/train/unsup/47180_0.txt\n",
            "aclImdb/train/unsup/47179_0.txt\n",
            "aclImdb/train/unsup/47178_0.txt\n",
            "aclImdb/train/unsup/47177_0.txt\n",
            "aclImdb/train/unsup/47176_0.txt\n",
            "aclImdb/train/unsup/47175_0.txt\n",
            "aclImdb/train/unsup/47174_0.txt\n",
            "aclImdb/train/unsup/47173_0.txt\n",
            "aclImdb/train/unsup/47172_0.txt\n",
            "aclImdb/train/unsup/47171_0.txt\n",
            "aclImdb/train/unsup/47170_0.txt\n",
            "aclImdb/train/unsup/47169_0.txt\n",
            "aclImdb/train/unsup/47168_0.txt\n",
            "aclImdb/train/unsup/47167_0.txt\n",
            "aclImdb/train/unsup/47166_0.txt\n",
            "aclImdb/train/unsup/47165_0.txt\n",
            "aclImdb/train/unsup/47164_0.txt\n",
            "aclImdb/train/unsup/47163_0.txt\n",
            "aclImdb/train/unsup/47162_0.txt\n",
            "aclImdb/train/unsup/47161_0.txt\n",
            "aclImdb/train/unsup/47160_0.txt\n",
            "aclImdb/train/unsup/47159_0.txt\n",
            "aclImdb/train/unsup/47158_0.txt\n",
            "aclImdb/train/unsup/47157_0.txt\n",
            "aclImdb/train/unsup/47156_0.txt\n",
            "aclImdb/train/unsup/47155_0.txt\n",
            "aclImdb/train/unsup/47154_0.txt\n",
            "aclImdb/train/unsup/47153_0.txt\n",
            "aclImdb/train/unsup/47152_0.txt\n",
            "aclImdb/train/unsup/47151_0.txt\n",
            "aclImdb/train/unsup/47150_0.txt\n",
            "aclImdb/train/unsup/47149_0.txt\n",
            "aclImdb/train/unsup/47148_0.txt\n",
            "aclImdb/train/unsup/47147_0.txt\n",
            "aclImdb/train/unsup/47146_0.txt\n",
            "aclImdb/train/unsup/47145_0.txt\n",
            "aclImdb/train/unsup/47144_0.txt\n",
            "aclImdb/train/unsup/47143_0.txt\n",
            "aclImdb/train/unsup/47142_0.txt\n",
            "aclImdb/train/unsup/47141_0.txt\n",
            "aclImdb/train/unsup/47140_0.txt\n",
            "aclImdb/train/unsup/47139_0.txt\n",
            "aclImdb/train/unsup/47138_0.txt\n",
            "aclImdb/train/unsup/47137_0.txt\n",
            "aclImdb/train/unsup/47136_0.txt\n",
            "aclImdb/train/unsup/47135_0.txt\n",
            "aclImdb/train/unsup/47134_0.txt\n",
            "aclImdb/train/unsup/47133_0.txt\n",
            "aclImdb/train/unsup/47132_0.txt\n",
            "aclImdb/train/unsup/47131_0.txt\n",
            "aclImdb/train/unsup/47130_0.txt\n",
            "aclImdb/train/unsup/47129_0.txt\n",
            "aclImdb/train/unsup/47128_0.txt\n",
            "aclImdb/train/unsup/47127_0.txt\n",
            "aclImdb/train/unsup/47126_0.txt\n",
            "aclImdb/train/unsup/47125_0.txt\n",
            "aclImdb/train/unsup/47124_0.txt\n",
            "aclImdb/train/unsup/47123_0.txt\n",
            "aclImdb/train/unsup/47122_0.txt\n",
            "aclImdb/train/unsup/47121_0.txt\n",
            "aclImdb/train/unsup/47120_0.txt\n",
            "aclImdb/train/unsup/47119_0.txt\n",
            "aclImdb/train/unsup/47118_0.txt\n",
            "aclImdb/train/unsup/47117_0.txt\n",
            "aclImdb/train/unsup/47116_0.txt\n",
            "aclImdb/train/unsup/47115_0.txt\n",
            "aclImdb/train/unsup/47114_0.txt\n",
            "aclImdb/train/unsup/47113_0.txt\n",
            "aclImdb/train/unsup/47112_0.txt\n",
            "aclImdb/train/unsup/47111_0.txt\n",
            "aclImdb/train/unsup/47110_0.txt\n",
            "aclImdb/train/unsup/47109_0.txt\n",
            "aclImdb/train/unsup/47108_0.txt\n",
            "aclImdb/train/unsup/47107_0.txt\n",
            "aclImdb/train/unsup/47106_0.txt\n",
            "aclImdb/train/unsup/47105_0.txt\n",
            "aclImdb/train/unsup/47104_0.txt\n",
            "aclImdb/train/unsup/47359_0.txt\n",
            "aclImdb/train/unsup/47358_0.txt\n",
            "aclImdb/train/unsup/47357_0.txt\n",
            "aclImdb/train/unsup/47356_0.txt\n",
            "aclImdb/train/unsup/47355_0.txt\n",
            "aclImdb/train/unsup/47354_0.txt\n",
            "aclImdb/train/unsup/47353_0.txt\n",
            "aclImdb/train/unsup/47352_0.txt\n",
            "aclImdb/train/unsup/47351_0.txt\n",
            "aclImdb/train/unsup/47350_0.txt\n",
            "aclImdb/train/unsup/47349_0.txt\n",
            "aclImdb/train/unsup/47348_0.txt\n",
            "aclImdb/train/unsup/47347_0.txt\n",
            "aclImdb/train/unsup/47346_0.txt\n",
            "aclImdb/train/unsup/47345_0.txt\n",
            "aclImdb/train/unsup/47344_0.txt\n",
            "aclImdb/train/unsup/47343_0.txt\n",
            "aclImdb/train/unsup/47342_0.txt\n",
            "aclImdb/train/unsup/47341_0.txt\n",
            "aclImdb/train/unsup/47340_0.txt\n",
            "aclImdb/train/unsup/47339_0.txt\n",
            "aclImdb/train/unsup/47338_0.txt\n",
            "aclImdb/train/unsup/47337_0.txt\n",
            "aclImdb/train/unsup/47336_0.txt\n",
            "aclImdb/train/unsup/47335_0.txt\n",
            "aclImdb/train/unsup/47334_0.txt\n",
            "aclImdb/train/unsup/47333_0.txt\n",
            "aclImdb/train/unsup/47332_0.txt\n",
            "aclImdb/train/unsup/47331_0.txt\n",
            "aclImdb/train/unsup/47330_0.txt\n",
            "aclImdb/train/unsup/47329_0.txt\n",
            "aclImdb/train/unsup/47328_0.txt\n",
            "aclImdb/train/unsup/47327_0.txt\n",
            "aclImdb/train/unsup/47326_0.txt\n",
            "aclImdb/train/unsup/47325_0.txt\n",
            "aclImdb/train/unsup/47324_0.txt\n",
            "aclImdb/train/unsup/47323_0.txt\n",
            "aclImdb/train/unsup/47322_0.txt\n",
            "aclImdb/train/unsup/47321_0.txt\n",
            "aclImdb/train/unsup/47320_0.txt\n",
            "aclImdb/train/unsup/47319_0.txt\n",
            "aclImdb/train/unsup/47318_0.txt\n",
            "aclImdb/train/unsup/47317_0.txt\n",
            "aclImdb/train/unsup/47316_0.txt\n",
            "aclImdb/train/unsup/47315_0.txt\n",
            "aclImdb/train/unsup/47314_0.txt\n",
            "aclImdb/train/unsup/47313_0.txt\n",
            "aclImdb/train/unsup/47312_0.txt\n",
            "aclImdb/train/unsup/47311_0.txt\n",
            "aclImdb/train/unsup/47310_0.txt\n",
            "aclImdb/train/unsup/47309_0.txt\n",
            "aclImdb/train/unsup/47308_0.txt\n",
            "aclImdb/train/unsup/47307_0.txt\n",
            "aclImdb/train/unsup/47306_0.txt\n",
            "aclImdb/train/unsup/47305_0.txt\n",
            "aclImdb/train/unsup/47304_0.txt\n",
            "aclImdb/train/unsup/47303_0.txt\n",
            "aclImdb/train/unsup/47302_0.txt\n",
            "aclImdb/train/unsup/47301_0.txt\n",
            "aclImdb/train/unsup/47300_0.txt\n",
            "aclImdb/train/unsup/47299_0.txt\n",
            "aclImdb/train/unsup/47298_0.txt\n",
            "aclImdb/train/unsup/47297_0.txt\n",
            "aclImdb/train/unsup/47296_0.txt\n",
            "aclImdb/train/unsup/47295_0.txt\n",
            "aclImdb/train/unsup/47294_0.txt\n",
            "aclImdb/train/unsup/47293_0.txt\n",
            "aclImdb/train/unsup/47292_0.txt\n",
            "aclImdb/train/unsup/47291_0.txt\n",
            "aclImdb/train/unsup/47290_0.txt\n",
            "aclImdb/train/unsup/47289_0.txt\n",
            "aclImdb/train/unsup/47288_0.txt\n",
            "aclImdb/train/unsup/47287_0.txt\n",
            "aclImdb/train/unsup/47286_0.txt\n",
            "aclImdb/train/unsup/47285_0.txt\n",
            "aclImdb/train/unsup/47284_0.txt\n",
            "aclImdb/train/unsup/47283_0.txt\n",
            "aclImdb/train/unsup/47282_0.txt\n",
            "aclImdb/train/unsup/47281_0.txt\n",
            "aclImdb/train/unsup/47280_0.txt\n",
            "aclImdb/train/unsup/47279_0.txt\n",
            "aclImdb/train/unsup/47278_0.txt\n",
            "aclImdb/train/unsup/47277_0.txt\n",
            "aclImdb/train/unsup/47276_0.txt\n",
            "aclImdb/train/unsup/47275_0.txt\n",
            "aclImdb/train/unsup/47274_0.txt\n",
            "aclImdb/train/unsup/47273_0.txt\n",
            "aclImdb/train/unsup/47272_0.txt\n",
            "aclImdb/train/unsup/47271_0.txt\n",
            "aclImdb/train/unsup/47270_0.txt\n",
            "aclImdb/train/unsup/47269_0.txt\n",
            "aclImdb/train/unsup/47268_0.txt\n",
            "aclImdb/train/unsup/47267_0.txt\n",
            "aclImdb/train/unsup/47266_0.txt\n",
            "aclImdb/train/unsup/47265_0.txt\n",
            "aclImdb/train/unsup/47264_0.txt\n",
            "aclImdb/train/unsup/47263_0.txt\n",
            "aclImdb/train/unsup/47262_0.txt\n",
            "aclImdb/train/unsup/47261_0.txt\n",
            "aclImdb/train/unsup/47260_0.txt\n",
            "aclImdb/train/unsup/47259_0.txt\n",
            "aclImdb/train/unsup/47258_0.txt\n",
            "aclImdb/train/unsup/47257_0.txt\n",
            "aclImdb/train/unsup/47256_0.txt\n",
            "aclImdb/train/unsup/47255_0.txt\n",
            "aclImdb/train/unsup/47254_0.txt\n",
            "aclImdb/train/unsup/47253_0.txt\n",
            "aclImdb/train/unsup/47252_0.txt\n",
            "aclImdb/train/unsup/47251_0.txt\n",
            "aclImdb/train/unsup/47250_0.txt\n",
            "aclImdb/train/unsup/47249_0.txt\n",
            "aclImdb/train/unsup/47248_0.txt\n",
            "aclImdb/train/unsup/47247_0.txt\n",
            "aclImdb/train/unsup/47246_0.txt\n",
            "aclImdb/train/unsup/47245_0.txt\n",
            "aclImdb/train/unsup/47244_0.txt\n",
            "aclImdb/train/unsup/47243_0.txt\n",
            "aclImdb/train/unsup/47242_0.txt\n",
            "aclImdb/train/unsup/47241_0.txt\n",
            "aclImdb/train/unsup/47240_0.txt\n",
            "aclImdb/train/unsup/47239_0.txt\n",
            "aclImdb/train/unsup/47238_0.txt\n",
            "aclImdb/train/unsup/47237_0.txt\n",
            "aclImdb/train/unsup/47236_0.txt\n",
            "aclImdb/train/unsup/47235_0.txt\n",
            "aclImdb/train/unsup/47234_0.txt\n",
            "aclImdb/train/unsup/47233_0.txt\n",
            "aclImdb/train/unsup/47232_0.txt\n",
            "aclImdb/train/unsup/47487_0.txt\n",
            "aclImdb/train/unsup/47486_0.txt\n",
            "aclImdb/train/unsup/47485_0.txt\n",
            "aclImdb/train/unsup/47484_0.txt\n",
            "aclImdb/train/unsup/47483_0.txt\n",
            "aclImdb/train/unsup/47482_0.txt\n",
            "aclImdb/train/unsup/47481_0.txt\n",
            "aclImdb/train/unsup/47480_0.txt\n",
            "aclImdb/train/unsup/47479_0.txt\n",
            "aclImdb/train/unsup/47478_0.txt\n",
            "aclImdb/train/unsup/47477_0.txt\n",
            "aclImdb/train/unsup/47476_0.txt\n",
            "aclImdb/train/unsup/47475_0.txt\n",
            "aclImdb/train/unsup/47474_0.txt\n",
            "aclImdb/train/unsup/47473_0.txt\n",
            "aclImdb/train/unsup/47472_0.txt\n",
            "aclImdb/train/unsup/47471_0.txt\n",
            "aclImdb/train/unsup/47470_0.txt\n",
            "aclImdb/train/unsup/47469_0.txt\n",
            "aclImdb/train/unsup/47468_0.txt\n",
            "aclImdb/train/unsup/47467_0.txt\n",
            "aclImdb/train/unsup/47466_0.txt\n",
            "aclImdb/train/unsup/47465_0.txt\n",
            "aclImdb/train/unsup/47464_0.txt\n",
            "aclImdb/train/unsup/47463_0.txt\n",
            "aclImdb/train/unsup/47462_0.txt\n",
            "aclImdb/train/unsup/47461_0.txt\n",
            "aclImdb/train/unsup/47460_0.txt\n",
            "aclImdb/train/unsup/47459_0.txt\n",
            "aclImdb/train/unsup/47458_0.txt\n",
            "aclImdb/train/unsup/47457_0.txt\n",
            "aclImdb/train/unsup/47456_0.txt\n",
            "aclImdb/train/unsup/47455_0.txt\n",
            "aclImdb/train/unsup/47454_0.txt\n",
            "aclImdb/train/unsup/47453_0.txt\n",
            "aclImdb/train/unsup/47452_0.txt\n",
            "aclImdb/train/unsup/47451_0.txt\n",
            "aclImdb/train/unsup/47450_0.txt\n",
            "aclImdb/train/unsup/47449_0.txt\n",
            "aclImdb/train/unsup/47448_0.txt\n",
            "aclImdb/train/unsup/47447_0.txt\n",
            "aclImdb/train/unsup/47446_0.txt\n",
            "aclImdb/train/unsup/47445_0.txt\n",
            "aclImdb/train/unsup/47444_0.txt\n",
            "aclImdb/train/unsup/47443_0.txt\n",
            "aclImdb/train/unsup/47442_0.txt\n",
            "aclImdb/train/unsup/47441_0.txt\n",
            "aclImdb/train/unsup/47440_0.txt\n",
            "aclImdb/train/unsup/47439_0.txt\n",
            "aclImdb/train/unsup/47438_0.txt\n",
            "aclImdb/train/unsup/47437_0.txt\n",
            "aclImdb/train/unsup/47436_0.txt\n",
            "aclImdb/train/unsup/47435_0.txt\n",
            "aclImdb/train/unsup/47434_0.txt\n",
            "aclImdb/train/unsup/47433_0.txt\n",
            "aclImdb/train/unsup/47432_0.txt\n",
            "aclImdb/train/unsup/47431_0.txt\n",
            "aclImdb/train/unsup/47430_0.txt\n",
            "aclImdb/train/unsup/47429_0.txt\n",
            "aclImdb/train/unsup/47428_0.txt\n",
            "aclImdb/train/unsup/47427_0.txt\n",
            "aclImdb/train/unsup/47426_0.txt\n",
            "aclImdb/train/unsup/47425_0.txt\n",
            "aclImdb/train/unsup/47424_0.txt\n",
            "aclImdb/train/unsup/47423_0.txt\n",
            "aclImdb/train/unsup/47422_0.txt\n",
            "aclImdb/train/unsup/47421_0.txt\n",
            "aclImdb/train/unsup/47420_0.txt\n",
            "aclImdb/train/unsup/47419_0.txt\n",
            "aclImdb/train/unsup/47418_0.txt\n",
            "aclImdb/train/unsup/47417_0.txt\n",
            "aclImdb/train/unsup/47416_0.txt\n",
            "aclImdb/train/unsup/47415_0.txt\n",
            "aclImdb/train/unsup/47414_0.txt\n",
            "aclImdb/train/unsup/47413_0.txt\n",
            "aclImdb/train/unsup/47412_0.txt\n",
            "aclImdb/train/unsup/47411_0.txt\n",
            "aclImdb/train/unsup/47410_0.txt\n",
            "aclImdb/train/unsup/47409_0.txt\n",
            "aclImdb/train/unsup/47408_0.txt\n",
            "aclImdb/train/unsup/47407_0.txt\n",
            "aclImdb/train/unsup/47406_0.txt\n",
            "aclImdb/train/unsup/47405_0.txt\n",
            "aclImdb/train/unsup/47404_0.txt\n",
            "aclImdb/train/unsup/47403_0.txt\n",
            "aclImdb/train/unsup/47402_0.txt\n",
            "aclImdb/train/unsup/47401_0.txt\n",
            "aclImdb/train/unsup/47400_0.txt\n",
            "aclImdb/train/unsup/47399_0.txt\n",
            "aclImdb/train/unsup/47398_0.txt\n",
            "aclImdb/train/unsup/47397_0.txt\n",
            "aclImdb/train/unsup/47396_0.txt\n",
            "aclImdb/train/unsup/47395_0.txt\n",
            "aclImdb/train/unsup/47394_0.txt\n",
            "aclImdb/train/unsup/47393_0.txt\n",
            "aclImdb/train/unsup/47392_0.txt\n",
            "aclImdb/train/unsup/47391_0.txt\n",
            "aclImdb/train/unsup/47390_0.txt\n",
            "aclImdb/train/unsup/47389_0.txt\n",
            "aclImdb/train/unsup/47388_0.txt\n",
            "aclImdb/train/unsup/47387_0.txt\n",
            "aclImdb/train/unsup/47386_0.txt\n",
            "aclImdb/train/unsup/47385_0.txt\n",
            "aclImdb/train/unsup/47384_0.txt\n",
            "aclImdb/train/unsup/47383_0.txt\n",
            "aclImdb/train/unsup/47382_0.txt\n",
            "aclImdb/train/unsup/47381_0.txt\n",
            "aclImdb/train/unsup/47380_0.txt\n",
            "aclImdb/train/unsup/47379_0.txt\n",
            "aclImdb/train/unsup/47378_0.txt\n",
            "aclImdb/train/unsup/47377_0.txt\n",
            "aclImdb/train/unsup/47376_0.txt\n",
            "aclImdb/train/unsup/47375_0.txt\n",
            "aclImdb/train/unsup/47374_0.txt\n",
            "aclImdb/train/unsup/47373_0.txt\n",
            "aclImdb/train/unsup/47372_0.txt\n",
            "aclImdb/train/unsup/47371_0.txt\n",
            "aclImdb/train/unsup/47370_0.txt\n",
            "aclImdb/train/unsup/47369_0.txt\n",
            "aclImdb/train/unsup/47368_0.txt\n",
            "aclImdb/train/unsup/47367_0.txt\n",
            "aclImdb/train/unsup/47366_0.txt\n",
            "aclImdb/train/unsup/47365_0.txt\n",
            "aclImdb/train/unsup/47364_0.txt\n",
            "aclImdb/train/unsup/47363_0.txt\n",
            "aclImdb/train/unsup/47362_0.txt\n",
            "aclImdb/train/unsup/47361_0.txt\n",
            "aclImdb/train/unsup/47360_0.txt\n",
            "aclImdb/train/unsup/47615_0.txt\n",
            "aclImdb/train/unsup/47614_0.txt\n",
            "aclImdb/train/unsup/47613_0.txt\n",
            "aclImdb/train/unsup/47612_0.txt\n",
            "aclImdb/train/unsup/47611_0.txt\n",
            "aclImdb/train/unsup/47610_0.txt\n",
            "aclImdb/train/unsup/47609_0.txt\n",
            "aclImdb/train/unsup/47608_0.txt\n",
            "aclImdb/train/unsup/47607_0.txt\n",
            "aclImdb/train/unsup/47606_0.txt\n",
            "aclImdb/train/unsup/47605_0.txt\n",
            "aclImdb/train/unsup/47604_0.txt\n",
            "aclImdb/train/unsup/47603_0.txt\n",
            "aclImdb/train/unsup/47602_0.txt\n",
            "aclImdb/train/unsup/47601_0.txt\n",
            "aclImdb/train/unsup/47600_0.txt\n",
            "aclImdb/train/unsup/47599_0.txt\n",
            "aclImdb/train/unsup/47598_0.txt\n",
            "aclImdb/train/unsup/47597_0.txt\n",
            "aclImdb/train/unsup/47596_0.txt\n",
            "aclImdb/train/unsup/47595_0.txt\n",
            "aclImdb/train/unsup/47594_0.txt\n",
            "aclImdb/train/unsup/47593_0.txt\n",
            "aclImdb/train/unsup/47592_0.txt\n",
            "aclImdb/train/unsup/47591_0.txt\n",
            "aclImdb/train/unsup/47590_0.txt\n",
            "aclImdb/train/unsup/47589_0.txt\n",
            "aclImdb/train/unsup/47588_0.txt\n",
            "aclImdb/train/unsup/47587_0.txt\n",
            "aclImdb/train/unsup/47586_0.txt\n",
            "aclImdb/train/unsup/47585_0.txt\n",
            "aclImdb/train/unsup/47584_0.txt\n",
            "aclImdb/train/unsup/47583_0.txt\n",
            "aclImdb/train/unsup/47582_0.txt\n",
            "aclImdb/train/unsup/47581_0.txt\n",
            "aclImdb/train/unsup/47580_0.txt\n",
            "aclImdb/train/unsup/47579_0.txt\n",
            "aclImdb/train/unsup/47578_0.txt\n",
            "aclImdb/train/unsup/47577_0.txt\n",
            "aclImdb/train/unsup/47576_0.txt\n",
            "aclImdb/train/unsup/47575_0.txt\n",
            "aclImdb/train/unsup/47574_0.txt\n",
            "aclImdb/train/unsup/47573_0.txt\n",
            "aclImdb/train/unsup/47572_0.txt\n",
            "aclImdb/train/unsup/47571_0.txt\n",
            "aclImdb/train/unsup/47570_0.txt\n",
            "aclImdb/train/unsup/47569_0.txt\n",
            "aclImdb/train/unsup/47568_0.txt\n",
            "aclImdb/train/unsup/47567_0.txt\n",
            "aclImdb/train/unsup/47566_0.txt\n",
            "aclImdb/train/unsup/47565_0.txt\n",
            "aclImdb/train/unsup/47564_0.txt\n",
            "aclImdb/train/unsup/47563_0.txt\n",
            "aclImdb/train/unsup/47562_0.txt\n",
            "aclImdb/train/unsup/47561_0.txt\n",
            "aclImdb/train/unsup/47560_0.txt\n",
            "aclImdb/train/unsup/47559_0.txt\n",
            "aclImdb/train/unsup/47558_0.txt\n",
            "aclImdb/train/unsup/47557_0.txt\n",
            "aclImdb/train/unsup/47556_0.txt\n",
            "aclImdb/train/unsup/47555_0.txt\n",
            "aclImdb/train/unsup/47554_0.txt\n",
            "aclImdb/train/unsup/47553_0.txt\n",
            "aclImdb/train/unsup/47552_0.txt\n",
            "aclImdb/train/unsup/47551_0.txt\n",
            "aclImdb/train/unsup/47550_0.txt\n",
            "aclImdb/train/unsup/47549_0.txt\n",
            "aclImdb/train/unsup/47548_0.txt\n",
            "aclImdb/train/unsup/47547_0.txt\n",
            "aclImdb/train/unsup/47546_0.txt\n",
            "aclImdb/train/unsup/47545_0.txt\n",
            "aclImdb/train/unsup/47544_0.txt\n",
            "aclImdb/train/unsup/47543_0.txt\n",
            "aclImdb/train/unsup/47542_0.txt\n",
            "aclImdb/train/unsup/47541_0.txt\n",
            "aclImdb/train/unsup/47540_0.txt\n",
            "aclImdb/train/unsup/47539_0.txt\n",
            "aclImdb/train/unsup/47538_0.txt\n",
            "aclImdb/train/unsup/47537_0.txt\n",
            "aclImdb/train/unsup/47536_0.txt\n",
            "aclImdb/train/unsup/47535_0.txt\n",
            "aclImdb/train/unsup/47534_0.txt\n",
            "aclImdb/train/unsup/47533_0.txt\n",
            "aclImdb/train/unsup/47532_0.txt\n",
            "aclImdb/train/unsup/47531_0.txt\n",
            "aclImdb/train/unsup/47530_0.txt\n",
            "aclImdb/train/unsup/47529_0.txt\n",
            "aclImdb/train/unsup/47528_0.txt\n",
            "aclImdb/train/unsup/47527_0.txt\n",
            "aclImdb/train/unsup/47526_0.txt\n",
            "aclImdb/train/unsup/47525_0.txt\n",
            "aclImdb/train/unsup/47524_0.txt\n",
            "aclImdb/train/unsup/47523_0.txt\n",
            "aclImdb/train/unsup/47522_0.txt\n",
            "aclImdb/train/unsup/47521_0.txt\n",
            "aclImdb/train/unsup/47520_0.txt\n",
            "aclImdb/train/unsup/47519_0.txt\n",
            "aclImdb/train/unsup/47518_0.txt\n",
            "aclImdb/train/unsup/47517_0.txt\n",
            "aclImdb/train/unsup/47516_0.txt\n",
            "aclImdb/train/unsup/47515_0.txt\n",
            "aclImdb/train/unsup/47514_0.txt\n",
            "aclImdb/train/unsup/47513_0.txt\n",
            "aclImdb/train/unsup/47512_0.txt\n",
            "aclImdb/train/unsup/47511_0.txt\n",
            "aclImdb/train/unsup/47510_0.txt\n",
            "aclImdb/train/unsup/47509_0.txt\n",
            "aclImdb/train/unsup/47508_0.txt\n",
            "aclImdb/train/unsup/47507_0.txt\n",
            "aclImdb/train/unsup/47506_0.txt\n",
            "aclImdb/train/unsup/47505_0.txt\n",
            "aclImdb/train/unsup/47504_0.txt\n",
            "aclImdb/train/unsup/47503_0.txt\n",
            "aclImdb/train/unsup/47502_0.txt\n",
            "aclImdb/train/unsup/47501_0.txt\n",
            "aclImdb/train/unsup/47500_0.txt\n",
            "aclImdb/train/unsup/47499_0.txt\n",
            "aclImdb/train/unsup/47498_0.txt\n",
            "aclImdb/train/unsup/47497_0.txt\n",
            "aclImdb/train/unsup/47496_0.txt\n",
            "aclImdb/train/unsup/47495_0.txt\n",
            "aclImdb/train/unsup/47494_0.txt\n",
            "aclImdb/train/unsup/47493_0.txt\n",
            "aclImdb/train/unsup/47492_0.txt\n",
            "aclImdb/train/unsup/47491_0.txt\n",
            "aclImdb/train/unsup/47490_0.txt\n",
            "aclImdb/train/unsup/47489_0.txt\n",
            "aclImdb/train/unsup/47488_0.txt\n",
            "aclImdb/train/unsup/47743_0.txt\n",
            "aclImdb/train/unsup/47742_0.txt\n",
            "aclImdb/train/unsup/47741_0.txt\n",
            "aclImdb/train/unsup/47740_0.txt\n",
            "aclImdb/train/unsup/47739_0.txt\n",
            "aclImdb/train/unsup/47738_0.txt\n",
            "aclImdb/train/unsup/47737_0.txt\n",
            "aclImdb/train/unsup/47736_0.txt\n",
            "aclImdb/train/unsup/47735_0.txt\n",
            "aclImdb/train/unsup/47734_0.txt\n",
            "aclImdb/train/unsup/47733_0.txt\n",
            "aclImdb/train/unsup/47732_0.txt\n",
            "aclImdb/train/unsup/47731_0.txt\n",
            "aclImdb/train/unsup/47730_0.txt\n",
            "aclImdb/train/unsup/47729_0.txt\n",
            "aclImdb/train/unsup/47728_0.txt\n",
            "aclImdb/train/unsup/47727_0.txt\n",
            "aclImdb/train/unsup/47726_0.txt\n",
            "aclImdb/train/unsup/47725_0.txt\n",
            "aclImdb/train/unsup/47724_0.txt\n",
            "aclImdb/train/unsup/47723_0.txt\n",
            "aclImdb/train/unsup/47722_0.txt\n",
            "aclImdb/train/unsup/47721_0.txt\n",
            "aclImdb/train/unsup/47720_0.txt\n",
            "aclImdb/train/unsup/47719_0.txt\n",
            "aclImdb/train/unsup/47718_0.txt\n",
            "aclImdb/train/unsup/47717_0.txt\n",
            "aclImdb/train/unsup/47716_0.txt\n",
            "aclImdb/train/unsup/47715_0.txt\n",
            "aclImdb/train/unsup/47714_0.txt\n",
            "aclImdb/train/unsup/47713_0.txt\n",
            "aclImdb/train/unsup/47712_0.txt\n",
            "aclImdb/train/unsup/47711_0.txt\n",
            "aclImdb/train/unsup/47710_0.txt\n",
            "aclImdb/train/unsup/47709_0.txt\n",
            "aclImdb/train/unsup/47708_0.txt\n",
            "aclImdb/train/unsup/47707_0.txt\n",
            "aclImdb/train/unsup/47706_0.txt\n",
            "aclImdb/train/unsup/47705_0.txt\n",
            "aclImdb/train/unsup/47704_0.txt\n",
            "aclImdb/train/unsup/47703_0.txt\n",
            "aclImdb/train/unsup/47702_0.txt\n",
            "aclImdb/train/unsup/47701_0.txt\n",
            "aclImdb/train/unsup/47700_0.txt\n",
            "aclImdb/train/unsup/47699_0.txt\n",
            "aclImdb/train/unsup/47698_0.txt\n",
            "aclImdb/train/unsup/47697_0.txt\n",
            "aclImdb/train/unsup/47696_0.txt\n",
            "aclImdb/train/unsup/47695_0.txt\n",
            "aclImdb/train/unsup/47694_0.txt\n",
            "aclImdb/train/unsup/47693_0.txt\n",
            "aclImdb/train/unsup/47692_0.txt\n",
            "aclImdb/train/unsup/47691_0.txt\n",
            "aclImdb/train/unsup/47690_0.txt\n",
            "aclImdb/train/unsup/47689_0.txt\n",
            "aclImdb/train/unsup/47688_0.txt\n",
            "aclImdb/train/unsup/47687_0.txt\n",
            "aclImdb/train/unsup/47686_0.txt\n",
            "aclImdb/train/unsup/47685_0.txt\n",
            "aclImdb/train/unsup/47684_0.txt\n",
            "aclImdb/train/unsup/47683_0.txt\n",
            "aclImdb/train/unsup/47682_0.txt\n",
            "aclImdb/train/unsup/47681_0.txt\n",
            "aclImdb/train/unsup/47680_0.txt\n",
            "aclImdb/train/unsup/47679_0.txt\n",
            "aclImdb/train/unsup/47678_0.txt\n",
            "aclImdb/train/unsup/47677_0.txt\n",
            "aclImdb/train/unsup/47676_0.txt\n",
            "aclImdb/train/unsup/47675_0.txt\n",
            "aclImdb/train/unsup/47674_0.txt\n",
            "aclImdb/train/unsup/47673_0.txt\n",
            "aclImdb/train/unsup/47672_0.txt\n",
            "aclImdb/train/unsup/47671_0.txt\n",
            "aclImdb/train/unsup/47670_0.txt\n",
            "aclImdb/train/unsup/47669_0.txt\n",
            "aclImdb/train/unsup/47668_0.txt\n",
            "aclImdb/train/unsup/47667_0.txt\n",
            "aclImdb/train/unsup/47666_0.txt\n",
            "aclImdb/train/unsup/47665_0.txt\n",
            "aclImdb/train/unsup/47664_0.txt\n",
            "aclImdb/train/unsup/47663_0.txt\n",
            "aclImdb/train/unsup/47662_0.txt\n",
            "aclImdb/train/unsup/47661_0.txt\n",
            "aclImdb/train/unsup/47660_0.txt\n",
            "aclImdb/train/unsup/47659_0.txt\n",
            "aclImdb/train/unsup/47658_0.txt\n",
            "aclImdb/train/unsup/47657_0.txt\n",
            "aclImdb/train/unsup/47656_0.txt\n",
            "aclImdb/train/unsup/47655_0.txt\n",
            "aclImdb/train/unsup/47654_0.txt\n",
            "aclImdb/train/unsup/47653_0.txt\n",
            "aclImdb/train/unsup/47652_0.txt\n",
            "aclImdb/train/unsup/47651_0.txt\n",
            "aclImdb/train/unsup/47650_0.txt\n",
            "aclImdb/train/unsup/47649_0.txt\n",
            "aclImdb/train/unsup/47648_0.txt\n",
            "aclImdb/train/unsup/47647_0.txt\n",
            "aclImdb/train/unsup/47646_0.txt\n",
            "aclImdb/train/unsup/47645_0.txt\n",
            "aclImdb/train/unsup/47644_0.txt\n",
            "aclImdb/train/unsup/47643_0.txt\n",
            "aclImdb/train/unsup/47642_0.txt\n",
            "aclImdb/train/unsup/47641_0.txt\n",
            "aclImdb/train/unsup/47640_0.txt\n",
            "aclImdb/train/unsup/47639_0.txt\n",
            "aclImdb/train/unsup/47638_0.txt\n",
            "aclImdb/train/unsup/47637_0.txt\n",
            "aclImdb/train/unsup/47636_0.txt\n",
            "aclImdb/train/unsup/47635_0.txt\n",
            "aclImdb/train/unsup/47634_0.txt\n",
            "aclImdb/train/unsup/47633_0.txt\n",
            "aclImdb/train/unsup/47632_0.txt\n",
            "aclImdb/train/unsup/47631_0.txt\n",
            "aclImdb/train/unsup/47630_0.txt\n",
            "aclImdb/train/unsup/47629_0.txt\n",
            "aclImdb/train/unsup/47628_0.txt\n",
            "aclImdb/train/unsup/47627_0.txt\n",
            "aclImdb/train/unsup/47626_0.txt\n",
            "aclImdb/train/unsup/47625_0.txt\n",
            "aclImdb/train/unsup/47624_0.txt\n",
            "aclImdb/train/unsup/47623_0.txt\n",
            "aclImdb/train/unsup/47622_0.txt\n",
            "aclImdb/train/unsup/47621_0.txt\n",
            "aclImdb/train/unsup/47620_0.txt\n",
            "aclImdb/train/unsup/47619_0.txt\n",
            "aclImdb/train/unsup/47618_0.txt\n",
            "aclImdb/train/unsup/47617_0.txt\n",
            "aclImdb/train/unsup/47616_0.txt\n",
            "aclImdb/train/unsup/47871_0.txt\n",
            "aclImdb/train/unsup/47870_0.txt\n",
            "aclImdb/train/unsup/47869_0.txt\n",
            "aclImdb/train/unsup/47868_0.txt\n",
            "aclImdb/train/unsup/47867_0.txt\n",
            "aclImdb/train/unsup/47866_0.txt\n",
            "aclImdb/train/unsup/47865_0.txt\n",
            "aclImdb/train/unsup/47864_0.txt\n",
            "aclImdb/train/unsup/47863_0.txt\n",
            "aclImdb/train/unsup/47862_0.txt\n",
            "aclImdb/train/unsup/47861_0.txt\n",
            "aclImdb/train/unsup/47860_0.txt\n",
            "aclImdb/train/unsup/47859_0.txt\n",
            "aclImdb/train/unsup/47858_0.txt\n",
            "aclImdb/train/unsup/47857_0.txt\n",
            "aclImdb/train/unsup/47856_0.txt\n",
            "aclImdb/train/unsup/47855_0.txt\n",
            "aclImdb/train/unsup/47854_0.txt\n",
            "aclImdb/train/unsup/47853_0.txt\n",
            "aclImdb/train/unsup/47852_0.txt\n",
            "aclImdb/train/unsup/47851_0.txt\n",
            "aclImdb/train/unsup/47850_0.txt\n",
            "aclImdb/train/unsup/47849_0.txt\n",
            "aclImdb/train/unsup/47848_0.txt\n",
            "aclImdb/train/unsup/47847_0.txt\n",
            "aclImdb/train/unsup/47846_0.txt\n",
            "aclImdb/train/unsup/47845_0.txt\n",
            "aclImdb/train/unsup/47844_0.txt\n",
            "aclImdb/train/unsup/47843_0.txt\n",
            "aclImdb/train/unsup/47842_0.txt\n",
            "aclImdb/train/unsup/47841_0.txt\n",
            "aclImdb/train/unsup/47840_0.txt\n",
            "aclImdb/train/unsup/47839_0.txt\n",
            "aclImdb/train/unsup/47838_0.txt\n",
            "aclImdb/train/unsup/47837_0.txt\n",
            "aclImdb/train/unsup/47836_0.txt\n",
            "aclImdb/train/unsup/47835_0.txt\n",
            "aclImdb/train/unsup/47834_0.txt\n",
            "aclImdb/train/unsup/47833_0.txt\n",
            "aclImdb/train/unsup/47832_0.txt\n",
            "aclImdb/train/unsup/47831_0.txt\n",
            "aclImdb/train/unsup/47830_0.txt\n",
            "aclImdb/train/unsup/47829_0.txt\n",
            "aclImdb/train/unsup/47828_0.txt\n",
            "aclImdb/train/unsup/47827_0.txt\n",
            "aclImdb/train/unsup/47826_0.txt\n",
            "aclImdb/train/unsup/47825_0.txt\n",
            "aclImdb/train/unsup/47824_0.txt\n",
            "aclImdb/train/unsup/47823_0.txt\n",
            "aclImdb/train/unsup/47822_0.txt\n",
            "aclImdb/train/unsup/47821_0.txt\n",
            "aclImdb/train/unsup/47820_0.txt\n",
            "aclImdb/train/unsup/47819_0.txt\n",
            "aclImdb/train/unsup/47818_0.txt\n",
            "aclImdb/train/unsup/47817_0.txt\n",
            "aclImdb/train/unsup/47816_0.txt\n",
            "aclImdb/train/unsup/47815_0.txt\n",
            "aclImdb/train/unsup/47814_0.txt\n",
            "aclImdb/train/unsup/47813_0.txt\n",
            "aclImdb/train/unsup/47812_0.txt\n",
            "aclImdb/train/unsup/47811_0.txt\n",
            "aclImdb/train/unsup/47810_0.txt\n",
            "aclImdb/train/unsup/47809_0.txt\n",
            "aclImdb/train/unsup/47808_0.txt\n",
            "aclImdb/train/unsup/47807_0.txt\n",
            "aclImdb/train/unsup/47806_0.txt\n",
            "aclImdb/train/unsup/47805_0.txt\n",
            "aclImdb/train/unsup/47804_0.txt\n",
            "aclImdb/train/unsup/47803_0.txt\n",
            "aclImdb/train/unsup/47802_0.txt\n",
            "aclImdb/train/unsup/47801_0.txt\n",
            "aclImdb/train/unsup/47800_0.txt\n",
            "aclImdb/train/unsup/47799_0.txt\n",
            "aclImdb/train/unsup/47798_0.txt\n",
            "aclImdb/train/unsup/47797_0.txt\n",
            "aclImdb/train/unsup/47796_0.txt\n",
            "aclImdb/train/unsup/47795_0.txt\n",
            "aclImdb/train/unsup/47794_0.txt\n",
            "aclImdb/train/unsup/47793_0.txt\n",
            "aclImdb/train/unsup/47792_0.txt\n",
            "aclImdb/train/unsup/47791_0.txt\n",
            "aclImdb/train/unsup/47790_0.txt\n",
            "aclImdb/train/unsup/47789_0.txt\n",
            "aclImdb/train/unsup/47788_0.txt\n",
            "aclImdb/train/unsup/47787_0.txt\n",
            "aclImdb/train/unsup/47786_0.txt\n",
            "aclImdb/train/unsup/47785_0.txt\n",
            "aclImdb/train/unsup/47784_0.txt\n",
            "aclImdb/train/unsup/47783_0.txt\n",
            "aclImdb/train/unsup/47782_0.txt\n",
            "aclImdb/train/unsup/47781_0.txt\n",
            "aclImdb/train/unsup/47780_0.txt\n",
            "aclImdb/train/unsup/47779_0.txt\n",
            "aclImdb/train/unsup/47778_0.txt\n",
            "aclImdb/train/unsup/47777_0.txt\n",
            "aclImdb/train/unsup/47776_0.txt\n",
            "aclImdb/train/unsup/47775_0.txt\n",
            "aclImdb/train/unsup/47774_0.txt\n",
            "aclImdb/train/unsup/47773_0.txt\n",
            "aclImdb/train/unsup/47772_0.txt\n",
            "aclImdb/train/unsup/47771_0.txt\n",
            "aclImdb/train/unsup/47770_0.txt\n",
            "aclImdb/train/unsup/47769_0.txt\n",
            "aclImdb/train/unsup/47768_0.txt\n",
            "aclImdb/train/unsup/47767_0.txt\n",
            "aclImdb/train/unsup/47766_0.txt\n",
            "aclImdb/train/unsup/47765_0.txt\n",
            "aclImdb/train/unsup/47764_0.txt\n",
            "aclImdb/train/unsup/47763_0.txt\n",
            "aclImdb/train/unsup/47762_0.txt\n",
            "aclImdb/train/unsup/47761_0.txt\n",
            "aclImdb/train/unsup/47760_0.txt\n",
            "aclImdb/train/unsup/47759_0.txt\n",
            "aclImdb/train/unsup/47758_0.txt\n",
            "aclImdb/train/unsup/47757_0.txt\n",
            "aclImdb/train/unsup/47756_0.txt\n",
            "aclImdb/train/unsup/47755_0.txt\n",
            "aclImdb/train/unsup/47754_0.txt\n",
            "aclImdb/train/unsup/47753_0.txt\n",
            "aclImdb/train/unsup/47752_0.txt\n",
            "aclImdb/train/unsup/47751_0.txt\n",
            "aclImdb/train/unsup/47750_0.txt\n",
            "aclImdb/train/unsup/47749_0.txt\n",
            "aclImdb/train/unsup/47748_0.txt\n",
            "aclImdb/train/unsup/47747_0.txt\n",
            "aclImdb/train/unsup/47746_0.txt\n",
            "aclImdb/train/unsup/47745_0.txt\n",
            "aclImdb/train/unsup/47744_0.txt\n",
            "aclImdb/train/unsup/47999_0.txt\n",
            "aclImdb/train/unsup/47998_0.txt\n",
            "aclImdb/train/unsup/47997_0.txt\n",
            "aclImdb/train/unsup/47996_0.txt\n",
            "aclImdb/train/unsup/47995_0.txt\n",
            "aclImdb/train/unsup/47994_0.txt\n",
            "aclImdb/train/unsup/47993_0.txt\n",
            "aclImdb/train/unsup/47992_0.txt\n",
            "aclImdb/train/unsup/47991_0.txt\n",
            "aclImdb/train/unsup/47990_0.txt\n",
            "aclImdb/train/unsup/47989_0.txt\n",
            "aclImdb/train/unsup/47988_0.txt\n",
            "aclImdb/train/unsup/47987_0.txt\n",
            "aclImdb/train/unsup/47986_0.txt\n",
            "aclImdb/train/unsup/47985_0.txt\n",
            "aclImdb/train/unsup/47984_0.txt\n",
            "aclImdb/train/unsup/47983_0.txt\n",
            "aclImdb/train/unsup/47982_0.txt\n",
            "aclImdb/train/unsup/47981_0.txt\n",
            "aclImdb/train/unsup/47980_0.txt\n",
            "aclImdb/train/unsup/47979_0.txt\n",
            "aclImdb/train/unsup/47978_0.txt\n",
            "aclImdb/train/unsup/47977_0.txt\n",
            "aclImdb/train/unsup/47976_0.txt\n",
            "aclImdb/train/unsup/47975_0.txt\n",
            "aclImdb/train/unsup/47974_0.txt\n",
            "aclImdb/train/unsup/47973_0.txt\n",
            "aclImdb/train/unsup/47972_0.txt\n",
            "aclImdb/train/unsup/47971_0.txt\n",
            "aclImdb/train/unsup/47970_0.txt\n",
            "aclImdb/train/unsup/47969_0.txt\n",
            "aclImdb/train/unsup/47968_0.txt\n",
            "aclImdb/train/unsup/47967_0.txt\n",
            "aclImdb/train/unsup/47966_0.txt\n",
            "aclImdb/train/unsup/47965_0.txt\n",
            "aclImdb/train/unsup/47964_0.txt\n",
            "aclImdb/train/unsup/47963_0.txt\n",
            "aclImdb/train/unsup/47962_0.txt\n",
            "aclImdb/train/unsup/47961_0.txt\n",
            "aclImdb/train/unsup/47960_0.txt\n",
            "aclImdb/train/unsup/47959_0.txt\n",
            "aclImdb/train/unsup/47958_0.txt\n",
            "aclImdb/train/unsup/47957_0.txt\n",
            "aclImdb/train/unsup/47956_0.txt\n",
            "aclImdb/train/unsup/47955_0.txt\n",
            "aclImdb/train/unsup/47954_0.txt\n",
            "aclImdb/train/unsup/47953_0.txt\n",
            "aclImdb/train/unsup/47952_0.txt\n",
            "aclImdb/train/unsup/47951_0.txt\n",
            "aclImdb/train/unsup/47950_0.txt\n",
            "aclImdb/train/unsup/47949_0.txt\n",
            "aclImdb/train/unsup/47948_0.txt\n",
            "aclImdb/train/unsup/47947_0.txt\n",
            "aclImdb/train/unsup/47946_0.txt\n",
            "aclImdb/train/unsup/47945_0.txt\n",
            "aclImdb/train/unsup/47944_0.txt\n",
            "aclImdb/train/unsup/47943_0.txt\n",
            "aclImdb/train/unsup/47942_0.txt\n",
            "aclImdb/train/unsup/47941_0.txt\n",
            "aclImdb/train/unsup/47940_0.txt\n",
            "aclImdb/train/unsup/47939_0.txt\n",
            "aclImdb/train/unsup/47938_0.txt\n",
            "aclImdb/train/unsup/47937_0.txt\n",
            "aclImdb/train/unsup/47936_0.txt\n",
            "aclImdb/train/unsup/47935_0.txt\n",
            "aclImdb/train/unsup/47934_0.txt\n",
            "aclImdb/train/unsup/47933_0.txt\n",
            "aclImdb/train/unsup/47932_0.txt\n",
            "aclImdb/train/unsup/47931_0.txt\n",
            "aclImdb/train/unsup/47930_0.txt\n",
            "aclImdb/train/unsup/47929_0.txt\n",
            "aclImdb/train/unsup/47928_0.txt\n",
            "aclImdb/train/unsup/47927_0.txt\n",
            "aclImdb/train/unsup/47926_0.txt\n",
            "aclImdb/train/unsup/47925_0.txt\n",
            "aclImdb/train/unsup/47924_0.txt\n",
            "aclImdb/train/unsup/47923_0.txt\n",
            "aclImdb/train/unsup/47922_0.txt\n",
            "aclImdb/train/unsup/47921_0.txt\n",
            "aclImdb/train/unsup/47920_0.txt\n",
            "aclImdb/train/unsup/47919_0.txt\n",
            "aclImdb/train/unsup/47918_0.txt\n",
            "aclImdb/train/unsup/47917_0.txt\n",
            "aclImdb/train/unsup/47916_0.txt\n",
            "aclImdb/train/unsup/47915_0.txt\n",
            "aclImdb/train/unsup/47914_0.txt\n",
            "aclImdb/train/unsup/47913_0.txt\n",
            "aclImdb/train/unsup/47912_0.txt\n",
            "aclImdb/train/unsup/47911_0.txt\n",
            "aclImdb/train/unsup/47910_0.txt\n",
            "aclImdb/train/unsup/47909_0.txt\n",
            "aclImdb/train/unsup/47908_0.txt\n",
            "aclImdb/train/unsup/47907_0.txt\n",
            "aclImdb/train/unsup/47906_0.txt\n",
            "aclImdb/train/unsup/47905_0.txt\n",
            "aclImdb/train/unsup/47904_0.txt\n",
            "aclImdb/train/unsup/47903_0.txt\n",
            "aclImdb/train/unsup/47902_0.txt\n",
            "aclImdb/train/unsup/47901_0.txt\n",
            "aclImdb/train/unsup/47900_0.txt\n",
            "aclImdb/train/unsup/47899_0.txt\n",
            "aclImdb/train/unsup/47898_0.txt\n",
            "aclImdb/train/unsup/47897_0.txt\n",
            "aclImdb/train/unsup/47896_0.txt\n",
            "aclImdb/train/unsup/47895_0.txt\n",
            "aclImdb/train/unsup/47894_0.txt\n",
            "aclImdb/train/unsup/47893_0.txt\n",
            "aclImdb/train/unsup/47892_0.txt\n",
            "aclImdb/train/unsup/47891_0.txt\n",
            "aclImdb/train/unsup/47890_0.txt\n",
            "aclImdb/train/unsup/47889_0.txt\n",
            "aclImdb/train/unsup/47888_0.txt\n",
            "aclImdb/train/unsup/47887_0.txt\n",
            "aclImdb/train/unsup/47886_0.txt\n",
            "aclImdb/train/unsup/47885_0.txt\n",
            "aclImdb/train/unsup/47884_0.txt\n",
            "aclImdb/train/unsup/47883_0.txt\n",
            "aclImdb/train/unsup/47882_0.txt\n",
            "aclImdb/train/unsup/47881_0.txt\n",
            "aclImdb/train/unsup/47880_0.txt\n",
            "aclImdb/train/unsup/47879_0.txt\n",
            "aclImdb/train/unsup/47878_0.txt\n",
            "aclImdb/train/unsup/47877_0.txt\n",
            "aclImdb/train/unsup/47876_0.txt\n",
            "aclImdb/train/unsup/47875_0.txt\n",
            "aclImdb/train/unsup/47874_0.txt\n",
            "aclImdb/train/unsup/47873_0.txt\n",
            "aclImdb/train/unsup/47872_0.txt\n",
            "aclImdb/train/unsup/48127_0.txt\n",
            "aclImdb/train/unsup/48126_0.txt\n",
            "aclImdb/train/unsup/48125_0.txt\n",
            "aclImdb/train/unsup/48124_0.txt\n",
            "aclImdb/train/unsup/48123_0.txt\n",
            "aclImdb/train/unsup/48122_0.txt\n",
            "aclImdb/train/unsup/48121_0.txt\n",
            "aclImdb/train/unsup/48120_0.txt\n",
            "aclImdb/train/unsup/48119_0.txt\n",
            "aclImdb/train/unsup/48118_0.txt\n",
            "aclImdb/train/unsup/48117_0.txt\n",
            "aclImdb/train/unsup/48116_0.txt\n",
            "aclImdb/train/unsup/48115_0.txt\n",
            "aclImdb/train/unsup/48114_0.txt\n",
            "aclImdb/train/unsup/48113_0.txt\n",
            "aclImdb/train/unsup/48112_0.txt\n",
            "aclImdb/train/unsup/48111_0.txt\n",
            "aclImdb/train/unsup/48110_0.txt\n",
            "aclImdb/train/unsup/48109_0.txt\n",
            "aclImdb/train/unsup/48108_0.txt\n",
            "aclImdb/train/unsup/48107_0.txt\n",
            "aclImdb/train/unsup/48106_0.txt\n",
            "aclImdb/train/unsup/48105_0.txt\n",
            "aclImdb/train/unsup/48104_0.txt\n",
            "aclImdb/train/unsup/48103_0.txt\n",
            "aclImdb/train/unsup/48102_0.txt\n",
            "aclImdb/train/unsup/48101_0.txt\n",
            "aclImdb/train/unsup/48100_0.txt\n",
            "aclImdb/train/unsup/48099_0.txt\n",
            "aclImdb/train/unsup/48098_0.txt\n",
            "aclImdb/train/unsup/48097_0.txt\n",
            "aclImdb/train/unsup/48096_0.txt\n",
            "aclImdb/train/unsup/48095_0.txt\n",
            "aclImdb/train/unsup/48094_0.txt\n",
            "aclImdb/train/unsup/48093_0.txt\n",
            "aclImdb/train/unsup/48092_0.txt\n",
            "aclImdb/train/unsup/48091_0.txt\n",
            "aclImdb/train/unsup/48090_0.txt\n",
            "aclImdb/train/unsup/48089_0.txt\n",
            "aclImdb/train/unsup/48088_0.txt\n",
            "aclImdb/train/unsup/48087_0.txt\n",
            "aclImdb/train/unsup/48086_0.txt\n",
            "aclImdb/train/unsup/48085_0.txt\n",
            "aclImdb/train/unsup/48084_0.txt\n",
            "aclImdb/train/unsup/48083_0.txt\n",
            "aclImdb/train/unsup/48082_0.txt\n",
            "aclImdb/train/unsup/48081_0.txt\n",
            "aclImdb/train/unsup/48080_0.txt\n",
            "aclImdb/train/unsup/48079_0.txt\n",
            "aclImdb/train/unsup/48078_0.txt\n",
            "aclImdb/train/unsup/48077_0.txt\n",
            "aclImdb/train/unsup/48076_0.txt\n",
            "aclImdb/train/unsup/48075_0.txt\n",
            "aclImdb/train/unsup/48074_0.txt\n",
            "aclImdb/train/unsup/48073_0.txt\n",
            "aclImdb/train/unsup/48072_0.txt\n",
            "aclImdb/train/unsup/48071_0.txt\n",
            "aclImdb/train/unsup/48070_0.txt\n",
            "aclImdb/train/unsup/48069_0.txt\n",
            "aclImdb/train/unsup/48068_0.txt\n",
            "aclImdb/train/unsup/48067_0.txt\n",
            "aclImdb/train/unsup/48066_0.txt\n",
            "aclImdb/train/unsup/48065_0.txt\n",
            "aclImdb/train/unsup/48064_0.txt\n",
            "aclImdb/train/unsup/48063_0.txt\n",
            "aclImdb/train/unsup/48062_0.txt\n",
            "aclImdb/train/unsup/48061_0.txt\n",
            "aclImdb/train/unsup/48060_0.txt\n",
            "aclImdb/train/unsup/48059_0.txt\n",
            "aclImdb/train/unsup/48058_0.txt\n",
            "aclImdb/train/unsup/48057_0.txt\n",
            "aclImdb/train/unsup/48056_0.txt\n",
            "aclImdb/train/unsup/48055_0.txt\n",
            "aclImdb/train/unsup/48054_0.txt\n",
            "aclImdb/train/unsup/48053_0.txt\n",
            "aclImdb/train/unsup/48052_0.txt\n",
            "aclImdb/train/unsup/48051_0.txt\n",
            "aclImdb/train/unsup/48050_0.txt\n",
            "aclImdb/train/unsup/48049_0.txt\n",
            "aclImdb/train/unsup/48048_0.txt\n",
            "aclImdb/train/unsup/48047_0.txt\n",
            "aclImdb/train/unsup/48046_0.txt\n",
            "aclImdb/train/unsup/48045_0.txt\n",
            "aclImdb/train/unsup/48044_0.txt\n",
            "aclImdb/train/unsup/48043_0.txt\n",
            "aclImdb/train/unsup/48042_0.txt\n",
            "aclImdb/train/unsup/48041_0.txt\n",
            "aclImdb/train/unsup/48040_0.txt\n",
            "aclImdb/train/unsup/48039_0.txt\n",
            "aclImdb/train/unsup/48038_0.txt\n",
            "aclImdb/train/unsup/48037_0.txt\n",
            "aclImdb/train/unsup/48036_0.txt\n",
            "aclImdb/train/unsup/48035_0.txt\n",
            "aclImdb/train/unsup/48034_0.txt\n",
            "aclImdb/train/unsup/48033_0.txt\n",
            "aclImdb/train/unsup/48032_0.txt\n",
            "aclImdb/train/unsup/48031_0.txt\n",
            "aclImdb/train/unsup/48030_0.txt\n",
            "aclImdb/train/unsup/48029_0.txt\n",
            "aclImdb/train/unsup/48028_0.txt\n",
            "aclImdb/train/unsup/48027_0.txt\n",
            "aclImdb/train/unsup/48026_0.txt\n",
            "aclImdb/train/unsup/48025_0.txt\n",
            "aclImdb/train/unsup/48024_0.txt\n",
            "aclImdb/train/unsup/48023_0.txt\n",
            "aclImdb/train/unsup/48022_0.txt\n",
            "aclImdb/train/unsup/48021_0.txt\n",
            "aclImdb/train/unsup/48020_0.txt\n",
            "aclImdb/train/unsup/48019_0.txt\n",
            "aclImdb/train/unsup/48018_0.txt\n",
            "aclImdb/train/unsup/48017_0.txt\n",
            "aclImdb/train/unsup/48016_0.txt\n",
            "aclImdb/train/unsup/48015_0.txt\n",
            "aclImdb/train/unsup/48014_0.txt\n",
            "aclImdb/train/unsup/48013_0.txt\n",
            "aclImdb/train/unsup/48012_0.txt\n",
            "aclImdb/train/unsup/48011_0.txt\n",
            "aclImdb/train/unsup/48010_0.txt\n",
            "aclImdb/train/unsup/48009_0.txt\n",
            "aclImdb/train/unsup/48008_0.txt\n",
            "aclImdb/train/unsup/48007_0.txt\n",
            "aclImdb/train/unsup/48006_0.txt\n",
            "aclImdb/train/unsup/48005_0.txt\n",
            "aclImdb/train/unsup/48004_0.txt\n",
            "aclImdb/train/unsup/48003_0.txt\n",
            "aclImdb/train/unsup/48002_0.txt\n",
            "aclImdb/train/unsup/48001_0.txt\n",
            "aclImdb/train/unsup/48000_0.txt\n",
            "aclImdb/train/unsup/48255_0.txt\n",
            "aclImdb/train/unsup/48254_0.txt\n",
            "aclImdb/train/unsup/48253_0.txt\n",
            "aclImdb/train/unsup/48252_0.txt\n",
            "aclImdb/train/unsup/48251_0.txt\n",
            "aclImdb/train/unsup/48250_0.txt\n",
            "aclImdb/train/unsup/48249_0.txt\n",
            "aclImdb/train/unsup/48248_0.txt\n",
            "aclImdb/train/unsup/48247_0.txt\n",
            "aclImdb/train/unsup/48246_0.txt\n",
            "aclImdb/train/unsup/48245_0.txt\n",
            "aclImdb/train/unsup/48244_0.txt\n",
            "aclImdb/train/unsup/48243_0.txt\n",
            "aclImdb/train/unsup/48242_0.txt\n",
            "aclImdb/train/unsup/48241_0.txt\n",
            "aclImdb/train/unsup/48240_0.txt\n",
            "aclImdb/train/unsup/48239_0.txt\n",
            "aclImdb/train/unsup/48238_0.txt\n",
            "aclImdb/train/unsup/48237_0.txt\n",
            "aclImdb/train/unsup/48236_0.txt\n",
            "aclImdb/train/unsup/48235_0.txt\n",
            "aclImdb/train/unsup/48234_0.txt\n",
            "aclImdb/train/unsup/48233_0.txt\n",
            "aclImdb/train/unsup/48232_0.txt\n",
            "aclImdb/train/unsup/48231_0.txt\n",
            "aclImdb/train/unsup/48230_0.txt\n",
            "aclImdb/train/unsup/48229_0.txt\n",
            "aclImdb/train/unsup/48228_0.txt\n",
            "aclImdb/train/unsup/48227_0.txt\n",
            "aclImdb/train/unsup/48226_0.txt\n",
            "aclImdb/train/unsup/48225_0.txt\n",
            "aclImdb/train/unsup/48224_0.txt\n",
            "aclImdb/train/unsup/48223_0.txt\n",
            "aclImdb/train/unsup/48222_0.txt\n",
            "aclImdb/train/unsup/48221_0.txt\n",
            "aclImdb/train/unsup/48220_0.txt\n",
            "aclImdb/train/unsup/48219_0.txt\n",
            "aclImdb/train/unsup/48218_0.txt\n",
            "aclImdb/train/unsup/48217_0.txt\n",
            "aclImdb/train/unsup/48216_0.txt\n",
            "aclImdb/train/unsup/48215_0.txt\n",
            "aclImdb/train/unsup/48214_0.txt\n",
            "aclImdb/train/unsup/48213_0.txt\n",
            "aclImdb/train/unsup/48212_0.txt\n",
            "aclImdb/train/unsup/48211_0.txt\n",
            "aclImdb/train/unsup/48210_0.txt\n",
            "aclImdb/train/unsup/48209_0.txt\n",
            "aclImdb/train/unsup/48208_0.txt\n",
            "aclImdb/train/unsup/48207_0.txt\n",
            "aclImdb/train/unsup/48206_0.txt\n",
            "aclImdb/train/unsup/48205_0.txt\n",
            "aclImdb/train/unsup/48204_0.txt\n",
            "aclImdb/train/unsup/48203_0.txt\n",
            "aclImdb/train/unsup/48202_0.txt\n",
            "aclImdb/train/unsup/48201_0.txt\n",
            "aclImdb/train/unsup/48200_0.txt\n",
            "aclImdb/train/unsup/48199_0.txt\n",
            "aclImdb/train/unsup/48198_0.txt\n",
            "aclImdb/train/unsup/48197_0.txt\n",
            "aclImdb/train/unsup/48196_0.txt\n",
            "aclImdb/train/unsup/48195_0.txt\n",
            "aclImdb/train/unsup/48194_0.txt\n",
            "aclImdb/train/unsup/48193_0.txt\n",
            "aclImdb/train/unsup/48192_0.txt\n",
            "aclImdb/train/unsup/48191_0.txt\n",
            "aclImdb/train/unsup/48190_0.txt\n",
            "aclImdb/train/unsup/48189_0.txt\n",
            "aclImdb/train/unsup/48188_0.txt\n",
            "aclImdb/train/unsup/48187_0.txt\n",
            "aclImdb/train/unsup/48186_0.txt\n",
            "aclImdb/train/unsup/48185_0.txt\n",
            "aclImdb/train/unsup/48184_0.txt\n",
            "aclImdb/train/unsup/48183_0.txt\n",
            "aclImdb/train/unsup/48182_0.txt\n",
            "aclImdb/train/unsup/48181_0.txt\n",
            "aclImdb/train/unsup/48180_0.txt\n",
            "aclImdb/train/unsup/48179_0.txt\n",
            "aclImdb/train/unsup/48178_0.txt\n",
            "aclImdb/train/unsup/48177_0.txt\n",
            "aclImdb/train/unsup/48176_0.txt\n",
            "aclImdb/train/unsup/48175_0.txt\n",
            "aclImdb/train/unsup/48174_0.txt\n",
            "aclImdb/train/unsup/48173_0.txt\n",
            "aclImdb/train/unsup/48172_0.txt\n",
            "aclImdb/train/unsup/48171_0.txt\n",
            "aclImdb/train/unsup/48170_0.txt\n",
            "aclImdb/train/unsup/48169_0.txt\n",
            "aclImdb/train/unsup/48168_0.txt\n",
            "aclImdb/train/unsup/48167_0.txt\n",
            "aclImdb/train/unsup/48166_0.txt\n",
            "aclImdb/train/unsup/48165_0.txt\n",
            "aclImdb/train/unsup/48164_0.txt\n",
            "aclImdb/train/unsup/48163_0.txt\n",
            "aclImdb/train/unsup/48162_0.txt\n",
            "aclImdb/train/unsup/48161_0.txt\n",
            "aclImdb/train/unsup/48160_0.txt\n",
            "aclImdb/train/unsup/48159_0.txt\n",
            "aclImdb/train/unsup/48158_0.txt\n",
            "aclImdb/train/unsup/48157_0.txt\n",
            "aclImdb/train/unsup/48156_0.txt\n",
            "aclImdb/train/unsup/48155_0.txt\n",
            "aclImdb/train/unsup/48154_0.txt\n",
            "aclImdb/train/unsup/48153_0.txt\n",
            "aclImdb/train/unsup/48152_0.txt\n",
            "aclImdb/train/unsup/48151_0.txt\n",
            "aclImdb/train/unsup/48150_0.txt\n",
            "aclImdb/train/unsup/48149_0.txt\n",
            "aclImdb/train/unsup/48148_0.txt\n",
            "aclImdb/train/unsup/48147_0.txt\n",
            "aclImdb/train/unsup/48146_0.txt\n",
            "aclImdb/train/unsup/48145_0.txt\n",
            "aclImdb/train/unsup/48144_0.txt\n",
            "aclImdb/train/unsup/48143_0.txt\n",
            "aclImdb/train/unsup/48142_0.txt\n",
            "aclImdb/train/unsup/48141_0.txt\n",
            "aclImdb/train/unsup/48140_0.txt\n",
            "aclImdb/train/unsup/48139_0.txt\n",
            "aclImdb/train/unsup/48138_0.txt\n",
            "aclImdb/train/unsup/48137_0.txt\n",
            "aclImdb/train/unsup/48136_0.txt\n",
            "aclImdb/train/unsup/48135_0.txt\n",
            "aclImdb/train/unsup/48134_0.txt\n",
            "aclImdb/train/unsup/48133_0.txt\n",
            "aclImdb/train/unsup/48132_0.txt\n",
            "aclImdb/train/unsup/48131_0.txt\n",
            "aclImdb/train/unsup/48130_0.txt\n",
            "aclImdb/train/unsup/48129_0.txt\n",
            "aclImdb/train/unsup/48128_0.txt\n",
            "aclImdb/train/unsup/48383_0.txt\n",
            "aclImdb/train/unsup/48382_0.txt\n",
            "aclImdb/train/unsup/48381_0.txt\n",
            "aclImdb/train/unsup/48380_0.txt\n",
            "aclImdb/train/unsup/48379_0.txt\n",
            "aclImdb/train/unsup/48378_0.txt\n",
            "aclImdb/train/unsup/48377_0.txt\n",
            "aclImdb/train/unsup/48376_0.txt\n",
            "aclImdb/train/unsup/48375_0.txt\n",
            "aclImdb/train/unsup/48374_0.txt\n",
            "aclImdb/train/unsup/48373_0.txt\n",
            "aclImdb/train/unsup/48372_0.txt\n",
            "aclImdb/train/unsup/48371_0.txt\n",
            "aclImdb/train/unsup/48370_0.txt\n",
            "aclImdb/train/unsup/48369_0.txt\n",
            "aclImdb/train/unsup/48368_0.txt\n",
            "aclImdb/train/unsup/48367_0.txt\n",
            "aclImdb/train/unsup/48366_0.txt\n",
            "aclImdb/train/unsup/48365_0.txt\n",
            "aclImdb/train/unsup/48364_0.txt\n",
            "aclImdb/train/unsup/48363_0.txt\n",
            "aclImdb/train/unsup/48362_0.txt\n",
            "aclImdb/train/unsup/48361_0.txt\n",
            "aclImdb/train/unsup/48360_0.txt\n",
            "aclImdb/train/unsup/48359_0.txt\n",
            "aclImdb/train/unsup/48358_0.txt\n",
            "aclImdb/train/unsup/48357_0.txt\n",
            "aclImdb/train/unsup/48356_0.txt\n",
            "aclImdb/train/unsup/48355_0.txt\n",
            "aclImdb/train/unsup/48354_0.txt\n",
            "aclImdb/train/unsup/48353_0.txt\n",
            "aclImdb/train/unsup/48352_0.txt\n",
            "aclImdb/train/unsup/48351_0.txt\n",
            "aclImdb/train/unsup/48350_0.txt\n",
            "aclImdb/train/unsup/48349_0.txt\n",
            "aclImdb/train/unsup/48348_0.txt\n",
            "aclImdb/train/unsup/48347_0.txt\n",
            "aclImdb/train/unsup/48346_0.txt\n",
            "aclImdb/train/unsup/48345_0.txt\n",
            "aclImdb/train/unsup/48344_0.txt\n",
            "aclImdb/train/unsup/48343_0.txt\n",
            "aclImdb/train/unsup/48342_0.txt\n",
            "aclImdb/train/unsup/48341_0.txt\n",
            "aclImdb/train/unsup/48340_0.txt\n",
            "aclImdb/train/unsup/48339_0.txt\n",
            "aclImdb/train/unsup/48338_0.txt\n",
            "aclImdb/train/unsup/48337_0.txt\n",
            "aclImdb/train/unsup/48336_0.txt\n",
            "aclImdb/train/unsup/48335_0.txt\n",
            "aclImdb/train/unsup/48334_0.txt\n",
            "aclImdb/train/unsup/48333_0.txt\n",
            "aclImdb/train/unsup/48332_0.txt\n",
            "aclImdb/train/unsup/48331_0.txt\n",
            "aclImdb/train/unsup/48330_0.txt\n",
            "aclImdb/train/unsup/48329_0.txt\n",
            "aclImdb/train/unsup/48328_0.txt\n",
            "aclImdb/train/unsup/48327_0.txt\n",
            "aclImdb/train/unsup/48326_0.txt\n",
            "aclImdb/train/unsup/48325_0.txt\n",
            "aclImdb/train/unsup/48324_0.txt\n",
            "aclImdb/train/unsup/48323_0.txt\n",
            "aclImdb/train/unsup/48322_0.txt\n",
            "aclImdb/train/unsup/48321_0.txt\n",
            "aclImdb/train/unsup/48320_0.txt\n",
            "aclImdb/train/unsup/48319_0.txt\n",
            "aclImdb/train/unsup/48318_0.txt\n",
            "aclImdb/train/unsup/48317_0.txt\n",
            "aclImdb/train/unsup/48316_0.txt\n",
            "aclImdb/train/unsup/48315_0.txt\n",
            "aclImdb/train/unsup/48314_0.txt\n",
            "aclImdb/train/unsup/48313_0.txt\n",
            "aclImdb/train/unsup/48312_0.txt\n",
            "aclImdb/train/unsup/48311_0.txt\n",
            "aclImdb/train/unsup/48310_0.txt\n",
            "aclImdb/train/unsup/48309_0.txt\n",
            "aclImdb/train/unsup/48308_0.txt\n",
            "aclImdb/train/unsup/48307_0.txt\n",
            "aclImdb/train/unsup/48306_0.txt\n",
            "aclImdb/train/unsup/48305_0.txt\n",
            "aclImdb/train/unsup/48304_0.txt\n",
            "aclImdb/train/unsup/48303_0.txt\n",
            "aclImdb/train/unsup/48302_0.txt\n",
            "aclImdb/train/unsup/48301_0.txt\n",
            "aclImdb/train/unsup/48300_0.txt\n",
            "aclImdb/train/unsup/48299_0.txt\n",
            "aclImdb/train/unsup/48298_0.txt\n",
            "aclImdb/train/unsup/48297_0.txt\n",
            "aclImdb/train/unsup/48296_0.txt\n",
            "aclImdb/train/unsup/48295_0.txt\n",
            "aclImdb/train/unsup/48294_0.txt\n",
            "aclImdb/train/unsup/48293_0.txt\n",
            "aclImdb/train/unsup/48292_0.txt\n",
            "aclImdb/train/unsup/48291_0.txt\n",
            "aclImdb/train/unsup/48290_0.txt\n",
            "aclImdb/train/unsup/48289_0.txt\n",
            "aclImdb/train/unsup/48288_0.txt\n",
            "aclImdb/train/unsup/48287_0.txt\n",
            "aclImdb/train/unsup/48286_0.txt\n",
            "aclImdb/train/unsup/48285_0.txt\n",
            "aclImdb/train/unsup/48284_0.txt\n",
            "aclImdb/train/unsup/48283_0.txt\n",
            "aclImdb/train/unsup/48282_0.txt\n",
            "aclImdb/train/unsup/48281_0.txt\n",
            "aclImdb/train/unsup/48280_0.txt\n",
            "aclImdb/train/unsup/48279_0.txt\n",
            "aclImdb/train/unsup/48278_0.txt\n",
            "aclImdb/train/unsup/48277_0.txt\n",
            "aclImdb/train/unsup/48276_0.txt\n",
            "aclImdb/train/unsup/48275_0.txt\n",
            "aclImdb/train/unsup/48274_0.txt\n",
            "aclImdb/train/unsup/48273_0.txt\n",
            "aclImdb/train/unsup/48272_0.txt\n",
            "aclImdb/train/unsup/48271_0.txt\n",
            "aclImdb/train/unsup/48270_0.txt\n",
            "aclImdb/train/unsup/48269_0.txt\n",
            "aclImdb/train/unsup/48268_0.txt\n",
            "aclImdb/train/unsup/48267_0.txt\n",
            "aclImdb/train/unsup/48266_0.txt\n",
            "aclImdb/train/unsup/48265_0.txt\n",
            "aclImdb/train/unsup/48264_0.txt\n",
            "aclImdb/train/unsup/48263_0.txt\n",
            "aclImdb/train/unsup/48262_0.txt\n",
            "aclImdb/train/unsup/48261_0.txt\n",
            "aclImdb/train/unsup/48260_0.txt\n",
            "aclImdb/train/unsup/48259_0.txt\n",
            "aclImdb/train/unsup/48258_0.txt\n",
            "aclImdb/train/unsup/48257_0.txt\n",
            "aclImdb/train/unsup/48256_0.txt\n",
            "aclImdb/train/unsup/48511_0.txt\n",
            "aclImdb/train/unsup/48510_0.txt\n",
            "aclImdb/train/unsup/48509_0.txt\n",
            "aclImdb/train/unsup/48508_0.txt\n",
            "aclImdb/train/unsup/48507_0.txt\n",
            "aclImdb/train/unsup/48506_0.txt\n",
            "aclImdb/train/unsup/48505_0.txt\n",
            "aclImdb/train/unsup/48504_0.txt\n",
            "aclImdb/train/unsup/48503_0.txt\n",
            "aclImdb/train/unsup/48502_0.txt\n",
            "aclImdb/train/unsup/48501_0.txt\n",
            "aclImdb/train/unsup/48500_0.txt\n",
            "aclImdb/train/unsup/48499_0.txt\n",
            "aclImdb/train/unsup/48498_0.txt\n",
            "aclImdb/train/unsup/48497_0.txt\n",
            "aclImdb/train/unsup/48496_0.txt\n",
            "aclImdb/train/unsup/48495_0.txt\n",
            "aclImdb/train/unsup/48494_0.txt\n",
            "aclImdb/train/unsup/48493_0.txt\n",
            "aclImdb/train/unsup/48492_0.txt\n",
            "aclImdb/train/unsup/48491_0.txt\n",
            "aclImdb/train/unsup/48490_0.txt\n",
            "aclImdb/train/unsup/48489_0.txt\n",
            "aclImdb/train/unsup/48488_0.txt\n",
            "aclImdb/train/unsup/48487_0.txt\n",
            "aclImdb/train/unsup/48486_0.txt\n",
            "aclImdb/train/unsup/48485_0.txt\n",
            "aclImdb/train/unsup/48484_0.txt\n",
            "aclImdb/train/unsup/48483_0.txt\n",
            "aclImdb/train/unsup/48482_0.txt\n",
            "aclImdb/train/unsup/48481_0.txt\n",
            "aclImdb/train/unsup/48480_0.txt\n",
            "aclImdb/train/unsup/48479_0.txt\n",
            "aclImdb/train/unsup/48478_0.txt\n",
            "aclImdb/train/unsup/48477_0.txt\n",
            "aclImdb/train/unsup/48476_0.txt\n",
            "aclImdb/train/unsup/48475_0.txt\n",
            "aclImdb/train/unsup/48474_0.txt\n",
            "aclImdb/train/unsup/48473_0.txt\n",
            "aclImdb/train/unsup/48472_0.txt\n",
            "aclImdb/train/unsup/48471_0.txt\n",
            "aclImdb/train/unsup/48470_0.txt\n",
            "aclImdb/train/unsup/48469_0.txt\n",
            "aclImdb/train/unsup/48468_0.txt\n",
            "aclImdb/train/unsup/48467_0.txt\n",
            "aclImdb/train/unsup/48466_0.txt\n",
            "aclImdb/train/unsup/48465_0.txt\n",
            "aclImdb/train/unsup/48464_0.txt\n",
            "aclImdb/train/unsup/48463_0.txt\n",
            "aclImdb/train/unsup/48462_0.txt\n",
            "aclImdb/train/unsup/48461_0.txt\n",
            "aclImdb/train/unsup/48460_0.txt\n",
            "aclImdb/train/unsup/48459_0.txt\n",
            "aclImdb/train/unsup/48458_0.txt\n",
            "aclImdb/train/unsup/48457_0.txt\n",
            "aclImdb/train/unsup/48456_0.txt\n",
            "aclImdb/train/unsup/48455_0.txt\n",
            "aclImdb/train/unsup/48454_0.txt\n",
            "aclImdb/train/unsup/48453_0.txt\n",
            "aclImdb/train/unsup/48452_0.txt\n",
            "aclImdb/train/unsup/48451_0.txt\n",
            "aclImdb/train/unsup/48450_0.txt\n",
            "aclImdb/train/unsup/48449_0.txt\n",
            "aclImdb/train/unsup/48448_0.txt\n",
            "aclImdb/train/unsup/48447_0.txt\n",
            "aclImdb/train/unsup/48446_0.txt\n",
            "aclImdb/train/unsup/48445_0.txt\n",
            "aclImdb/train/unsup/48444_0.txt\n",
            "aclImdb/train/unsup/48443_0.txt\n",
            "aclImdb/train/unsup/48442_0.txt\n",
            "aclImdb/train/unsup/48441_0.txt\n",
            "aclImdb/train/unsup/48440_0.txt\n",
            "aclImdb/train/unsup/48439_0.txt\n",
            "aclImdb/train/unsup/48438_0.txt\n",
            "aclImdb/train/unsup/48437_0.txt\n",
            "aclImdb/train/unsup/48436_0.txt\n",
            "aclImdb/train/unsup/48435_0.txt\n",
            "aclImdb/train/unsup/48434_0.txt\n",
            "aclImdb/train/unsup/48433_0.txt\n",
            "aclImdb/train/unsup/48432_0.txt\n",
            "aclImdb/train/unsup/48431_0.txt\n",
            "aclImdb/train/unsup/48430_0.txt\n",
            "aclImdb/train/unsup/48429_0.txt\n",
            "aclImdb/train/unsup/48428_0.txt\n",
            "aclImdb/train/unsup/48427_0.txt\n",
            "aclImdb/train/unsup/48426_0.txt\n",
            "aclImdb/train/unsup/48425_0.txt\n",
            "aclImdb/train/unsup/48424_0.txt\n",
            "aclImdb/train/unsup/48423_0.txt\n",
            "aclImdb/train/unsup/48422_0.txt\n",
            "aclImdb/train/unsup/48421_0.txt\n",
            "aclImdb/train/unsup/48420_0.txt\n",
            "aclImdb/train/unsup/48419_0.txt\n",
            "aclImdb/train/unsup/48418_0.txt\n",
            "aclImdb/train/unsup/48417_0.txt\n",
            "aclImdb/train/unsup/48416_0.txt\n",
            "aclImdb/train/unsup/48415_0.txt\n",
            "aclImdb/train/unsup/48414_0.txt\n",
            "aclImdb/train/unsup/48413_0.txt\n",
            "aclImdb/train/unsup/48412_0.txt\n",
            "aclImdb/train/unsup/48411_0.txt\n",
            "aclImdb/train/unsup/48410_0.txt\n",
            "aclImdb/train/unsup/48409_0.txt\n",
            "aclImdb/train/unsup/48408_0.txt\n",
            "aclImdb/train/unsup/48407_0.txt\n",
            "aclImdb/train/unsup/48406_0.txt\n",
            "aclImdb/train/unsup/48405_0.txt\n",
            "aclImdb/train/unsup/48404_0.txt\n",
            "aclImdb/train/unsup/48403_0.txt\n",
            "aclImdb/train/unsup/48402_0.txt\n",
            "aclImdb/train/unsup/48401_0.txt\n",
            "aclImdb/train/unsup/48400_0.txt\n",
            "aclImdb/train/unsup/48399_0.txt\n",
            "aclImdb/train/unsup/48398_0.txt\n",
            "aclImdb/train/unsup/48397_0.txt\n",
            "aclImdb/train/unsup/48396_0.txt\n",
            "aclImdb/train/unsup/48395_0.txt\n",
            "aclImdb/train/unsup/48394_0.txt\n",
            "aclImdb/train/unsup/48393_0.txt\n",
            "aclImdb/train/unsup/48392_0.txt\n",
            "aclImdb/train/unsup/48391_0.txt\n",
            "aclImdb/train/unsup/48390_0.txt\n",
            "aclImdb/train/unsup/48389_0.txt\n",
            "aclImdb/train/unsup/48388_0.txt\n",
            "aclImdb/train/unsup/48387_0.txt\n",
            "aclImdb/train/unsup/48386_0.txt\n",
            "aclImdb/train/unsup/48385_0.txt\n",
            "aclImdb/train/unsup/48384_0.txt\n",
            "aclImdb/train/unsup/48639_0.txt\n",
            "aclImdb/train/unsup/48638_0.txt\n",
            "aclImdb/train/unsup/48637_0.txt\n",
            "aclImdb/train/unsup/48636_0.txt\n",
            "aclImdb/train/unsup/48635_0.txt\n",
            "aclImdb/train/unsup/48634_0.txt\n",
            "aclImdb/train/unsup/48633_0.txt\n",
            "aclImdb/train/unsup/48632_0.txt\n",
            "aclImdb/train/unsup/48631_0.txt\n",
            "aclImdb/train/unsup/48630_0.txt\n",
            "aclImdb/train/unsup/48629_0.txt\n",
            "aclImdb/train/unsup/48628_0.txt\n",
            "aclImdb/train/unsup/48627_0.txt\n",
            "aclImdb/train/unsup/48626_0.txt\n",
            "aclImdb/train/unsup/48625_0.txt\n",
            "aclImdb/train/unsup/48624_0.txt\n",
            "aclImdb/train/unsup/48623_0.txt\n",
            "aclImdb/train/unsup/48622_0.txt\n",
            "aclImdb/train/unsup/48621_0.txt\n",
            "aclImdb/train/unsup/48620_0.txt\n",
            "aclImdb/train/unsup/48619_0.txt\n",
            "aclImdb/train/unsup/48618_0.txt\n",
            "aclImdb/train/unsup/48617_0.txt\n",
            "aclImdb/train/unsup/48616_0.txt\n",
            "aclImdb/train/unsup/48615_0.txt\n",
            "aclImdb/train/unsup/48614_0.txt\n",
            "aclImdb/train/unsup/48613_0.txt\n",
            "aclImdb/train/unsup/48612_0.txt\n",
            "aclImdb/train/unsup/48611_0.txt\n",
            "aclImdb/train/unsup/48610_0.txt\n",
            "aclImdb/train/unsup/48609_0.txt\n",
            "aclImdb/train/unsup/48608_0.txt\n",
            "aclImdb/train/unsup/48607_0.txt\n",
            "aclImdb/train/unsup/48606_0.txt\n",
            "aclImdb/train/unsup/48605_0.txt\n",
            "aclImdb/train/unsup/48604_0.txt\n",
            "aclImdb/train/unsup/48603_0.txt\n",
            "aclImdb/train/unsup/48602_0.txt\n",
            "aclImdb/train/unsup/48601_0.txt\n",
            "aclImdb/train/unsup/48600_0.txt\n",
            "aclImdb/train/unsup/48599_0.txt\n",
            "aclImdb/train/unsup/48598_0.txt\n",
            "aclImdb/train/unsup/48597_0.txt\n",
            "aclImdb/train/unsup/48596_0.txt\n",
            "aclImdb/train/unsup/48595_0.txt\n",
            "aclImdb/train/unsup/48594_0.txt\n",
            "aclImdb/train/unsup/48593_0.txt\n",
            "aclImdb/train/unsup/48592_0.txt\n",
            "aclImdb/train/unsup/48591_0.txt\n",
            "aclImdb/train/unsup/48590_0.txt\n",
            "aclImdb/train/unsup/48589_0.txt\n",
            "aclImdb/train/unsup/48588_0.txt\n",
            "aclImdb/train/unsup/48587_0.txt\n",
            "aclImdb/train/unsup/48586_0.txt\n",
            "aclImdb/train/unsup/48585_0.txt\n",
            "aclImdb/train/unsup/48584_0.txt\n",
            "aclImdb/train/unsup/48583_0.txt\n",
            "aclImdb/train/unsup/48582_0.txt\n",
            "aclImdb/train/unsup/48581_0.txt\n",
            "aclImdb/train/unsup/48580_0.txt\n",
            "aclImdb/train/unsup/48579_0.txt\n",
            "aclImdb/train/unsup/48578_0.txt\n",
            "aclImdb/train/unsup/48577_0.txt\n",
            "aclImdb/train/unsup/48576_0.txt\n",
            "aclImdb/train/unsup/48575_0.txt\n",
            "aclImdb/train/unsup/48574_0.txt\n",
            "aclImdb/train/unsup/48573_0.txt\n",
            "aclImdb/train/unsup/48572_0.txt\n",
            "aclImdb/train/unsup/48571_0.txt\n",
            "aclImdb/train/unsup/48570_0.txt\n",
            "aclImdb/train/unsup/48569_0.txt\n",
            "aclImdb/train/unsup/48568_0.txt\n",
            "aclImdb/train/unsup/48567_0.txt\n",
            "aclImdb/train/unsup/48566_0.txt\n",
            "aclImdb/train/unsup/48565_0.txt\n",
            "aclImdb/train/unsup/48564_0.txt\n",
            "aclImdb/train/unsup/48563_0.txt\n",
            "aclImdb/train/unsup/48562_0.txt\n",
            "aclImdb/train/unsup/48561_0.txt\n",
            "aclImdb/train/unsup/48560_0.txt\n",
            "aclImdb/train/unsup/48559_0.txt\n",
            "aclImdb/train/unsup/48558_0.txt\n",
            "aclImdb/train/unsup/48557_0.txt\n",
            "aclImdb/train/unsup/48556_0.txt\n",
            "aclImdb/train/unsup/48555_0.txt\n",
            "aclImdb/train/unsup/48554_0.txt\n",
            "aclImdb/train/unsup/48553_0.txt\n",
            "aclImdb/train/unsup/48552_0.txt\n",
            "aclImdb/train/unsup/48551_0.txt\n",
            "aclImdb/train/unsup/48550_0.txt\n",
            "aclImdb/train/unsup/48549_0.txt\n",
            "aclImdb/train/unsup/48548_0.txt\n",
            "aclImdb/train/unsup/48547_0.txt\n",
            "aclImdb/train/unsup/48546_0.txt\n",
            "aclImdb/train/unsup/48545_0.txt\n",
            "aclImdb/train/unsup/48544_0.txt\n",
            "aclImdb/train/unsup/48543_0.txt\n",
            "aclImdb/train/unsup/48542_0.txt\n",
            "aclImdb/train/unsup/48541_0.txt\n",
            "aclImdb/train/unsup/48540_0.txt\n",
            "aclImdb/train/unsup/48539_0.txt\n",
            "aclImdb/train/unsup/48538_0.txt\n",
            "aclImdb/train/unsup/48537_0.txt\n",
            "aclImdb/train/unsup/48536_0.txt\n",
            "aclImdb/train/unsup/48535_0.txt\n",
            "aclImdb/train/unsup/48534_0.txt\n",
            "aclImdb/train/unsup/48533_0.txt\n",
            "aclImdb/train/unsup/48532_0.txt\n",
            "aclImdb/train/unsup/48531_0.txt\n",
            "aclImdb/train/unsup/48530_0.txt\n",
            "aclImdb/train/unsup/48529_0.txt\n",
            "aclImdb/train/unsup/48528_0.txt\n",
            "aclImdb/train/unsup/48527_0.txt\n",
            "aclImdb/train/unsup/48526_0.txt\n",
            "aclImdb/train/unsup/48525_0.txt\n",
            "aclImdb/train/unsup/48524_0.txt\n",
            "aclImdb/train/unsup/48523_0.txt\n",
            "aclImdb/train/unsup/48522_0.txt\n",
            "aclImdb/train/unsup/48521_0.txt\n",
            "aclImdb/train/unsup/48520_0.txt\n",
            "aclImdb/train/unsup/48519_0.txt\n",
            "aclImdb/train/unsup/48518_0.txt\n",
            "aclImdb/train/unsup/48517_0.txt\n",
            "aclImdb/train/unsup/48516_0.txt\n",
            "aclImdb/train/unsup/48515_0.txt\n",
            "aclImdb/train/unsup/48514_0.txt\n",
            "aclImdb/train/unsup/48513_0.txt\n",
            "aclImdb/train/unsup/48512_0.txt\n",
            "aclImdb/train/unsup/48767_0.txt\n",
            "aclImdb/train/unsup/48766_0.txt\n",
            "aclImdb/train/unsup/48765_0.txt\n",
            "aclImdb/train/unsup/48764_0.txt\n",
            "aclImdb/train/unsup/48763_0.txt\n",
            "aclImdb/train/unsup/48762_0.txt\n",
            "aclImdb/train/unsup/48761_0.txt\n",
            "aclImdb/train/unsup/48760_0.txt\n",
            "aclImdb/train/unsup/48759_0.txt\n",
            "aclImdb/train/unsup/48758_0.txt\n",
            "aclImdb/train/unsup/48757_0.txt\n",
            "aclImdb/train/unsup/48756_0.txt\n",
            "aclImdb/train/unsup/48755_0.txt\n",
            "aclImdb/train/unsup/48754_0.txt\n",
            "aclImdb/train/unsup/48753_0.txt\n",
            "aclImdb/train/unsup/48752_0.txt\n",
            "aclImdb/train/unsup/48751_0.txt\n",
            "aclImdb/train/unsup/48750_0.txt\n",
            "aclImdb/train/unsup/48749_0.txt\n",
            "aclImdb/train/unsup/48748_0.txt\n",
            "aclImdb/train/unsup/48747_0.txt\n",
            "aclImdb/train/unsup/48746_0.txt\n",
            "aclImdb/train/unsup/48745_0.txt\n",
            "aclImdb/train/unsup/48744_0.txt\n",
            "aclImdb/train/unsup/48743_0.txt\n",
            "aclImdb/train/unsup/48742_0.txt\n",
            "aclImdb/train/unsup/48741_0.txt\n",
            "aclImdb/train/unsup/48740_0.txt\n",
            "aclImdb/train/unsup/48739_0.txt\n",
            "aclImdb/train/unsup/48738_0.txt\n",
            "aclImdb/train/unsup/48737_0.txt\n",
            "aclImdb/train/unsup/48736_0.txt\n",
            "aclImdb/train/unsup/48735_0.txt\n",
            "aclImdb/train/unsup/48734_0.txt\n",
            "aclImdb/train/unsup/48733_0.txt\n",
            "aclImdb/train/unsup/48732_0.txt\n",
            "aclImdb/train/unsup/48731_0.txt\n",
            "aclImdb/train/unsup/48730_0.txt\n",
            "aclImdb/train/unsup/48729_0.txt\n",
            "aclImdb/train/unsup/48728_0.txt\n",
            "aclImdb/train/unsup/48727_0.txt\n",
            "aclImdb/train/unsup/48726_0.txt\n",
            "aclImdb/train/unsup/48725_0.txt\n",
            "aclImdb/train/unsup/48724_0.txt\n",
            "aclImdb/train/unsup/48723_0.txt\n",
            "aclImdb/train/unsup/48722_0.txt\n",
            "aclImdb/train/unsup/48721_0.txt\n",
            "aclImdb/train/unsup/48720_0.txt\n",
            "aclImdb/train/unsup/48719_0.txt\n",
            "aclImdb/train/unsup/48718_0.txt\n",
            "aclImdb/train/unsup/48717_0.txt\n",
            "aclImdb/train/unsup/48716_0.txt\n",
            "aclImdb/train/unsup/48715_0.txt\n",
            "aclImdb/train/unsup/48714_0.txt\n",
            "aclImdb/train/unsup/48713_0.txt\n",
            "aclImdb/train/unsup/48712_0.txt\n",
            "aclImdb/train/unsup/48711_0.txt\n",
            "aclImdb/train/unsup/48710_0.txt\n",
            "aclImdb/train/unsup/48709_0.txt\n",
            "aclImdb/train/unsup/48708_0.txt\n",
            "aclImdb/train/unsup/48707_0.txt\n",
            "aclImdb/train/unsup/48706_0.txt\n",
            "aclImdb/train/unsup/48705_0.txt\n",
            "aclImdb/train/unsup/48704_0.txt\n",
            "aclImdb/train/unsup/48703_0.txt\n",
            "aclImdb/train/unsup/48702_0.txt\n",
            "aclImdb/train/unsup/48701_0.txt\n",
            "aclImdb/train/unsup/48700_0.txt\n",
            "aclImdb/train/unsup/48699_0.txt\n",
            "aclImdb/train/unsup/48698_0.txt\n",
            "aclImdb/train/unsup/48697_0.txt\n",
            "aclImdb/train/unsup/48696_0.txt\n",
            "aclImdb/train/unsup/48695_0.txt\n",
            "aclImdb/train/unsup/48694_0.txt\n",
            "aclImdb/train/unsup/48693_0.txt\n",
            "aclImdb/train/unsup/48692_0.txt\n",
            "aclImdb/train/unsup/48691_0.txt\n",
            "aclImdb/train/unsup/48690_0.txt\n",
            "aclImdb/train/unsup/48689_0.txt\n",
            "aclImdb/train/unsup/48688_0.txt\n",
            "aclImdb/train/unsup/48687_0.txt\n",
            "aclImdb/train/unsup/48686_0.txt\n",
            "aclImdb/train/unsup/48685_0.txt\n",
            "aclImdb/train/unsup/48684_0.txt\n",
            "aclImdb/train/unsup/48683_0.txt\n",
            "aclImdb/train/unsup/48682_0.txt\n",
            "aclImdb/train/unsup/48681_0.txt\n",
            "aclImdb/train/unsup/48680_0.txt\n",
            "aclImdb/train/unsup/48679_0.txt\n",
            "aclImdb/train/unsup/48678_0.txt\n",
            "aclImdb/train/unsup/48677_0.txt\n",
            "aclImdb/train/unsup/48676_0.txt\n",
            "aclImdb/train/unsup/48675_0.txt\n",
            "aclImdb/train/unsup/48674_0.txt\n",
            "aclImdb/train/unsup/48673_0.txt\n",
            "aclImdb/train/unsup/48672_0.txt\n",
            "aclImdb/train/unsup/48671_0.txt\n",
            "aclImdb/train/unsup/48670_0.txt\n",
            "aclImdb/train/unsup/48669_0.txt\n",
            "aclImdb/train/unsup/48668_0.txt\n",
            "aclImdb/train/unsup/48667_0.txt\n",
            "aclImdb/train/unsup/48666_0.txt\n",
            "aclImdb/train/unsup/48665_0.txt\n",
            "aclImdb/train/unsup/48664_0.txt\n",
            "aclImdb/train/unsup/48663_0.txt\n",
            "aclImdb/train/unsup/48662_0.txt\n",
            "aclImdb/train/unsup/48661_0.txt\n",
            "aclImdb/train/unsup/48660_0.txt\n",
            "aclImdb/train/unsup/48659_0.txt\n",
            "aclImdb/train/unsup/48658_0.txt\n",
            "aclImdb/train/unsup/48657_0.txt\n",
            "aclImdb/train/unsup/48656_0.txt\n",
            "aclImdb/train/unsup/48655_0.txt\n",
            "aclImdb/train/unsup/48654_0.txt\n",
            "aclImdb/train/unsup/48653_0.txt\n",
            "aclImdb/train/unsup/48652_0.txt\n",
            "aclImdb/train/unsup/48651_0.txt\n",
            "aclImdb/train/unsup/48650_0.txt\n",
            "aclImdb/train/unsup/48649_0.txt\n",
            "aclImdb/train/unsup/48648_0.txt\n",
            "aclImdb/train/unsup/48647_0.txt\n",
            "aclImdb/train/unsup/48646_0.txt\n",
            "aclImdb/train/unsup/48645_0.txt\n",
            "aclImdb/train/unsup/48644_0.txt\n",
            "aclImdb/train/unsup/48643_0.txt\n",
            "aclImdb/train/unsup/48642_0.txt\n",
            "aclImdb/train/unsup/48641_0.txt\n",
            "aclImdb/train/unsup/48640_0.txt\n",
            "aclImdb/train/unsup/48895_0.txt\n",
            "aclImdb/train/unsup/48894_0.txt\n",
            "aclImdb/train/unsup/48893_0.txt\n",
            "aclImdb/train/unsup/48892_0.txt\n",
            "aclImdb/train/unsup/48891_0.txt\n",
            "aclImdb/train/unsup/48890_0.txt\n",
            "aclImdb/train/unsup/48889_0.txt\n",
            "aclImdb/train/unsup/48888_0.txt\n",
            "aclImdb/train/unsup/48887_0.txt\n",
            "aclImdb/train/unsup/48886_0.txt\n",
            "aclImdb/train/unsup/48885_0.txt\n",
            "aclImdb/train/unsup/48884_0.txt\n",
            "aclImdb/train/unsup/48883_0.txt\n",
            "aclImdb/train/unsup/48882_0.txt\n",
            "aclImdb/train/unsup/48881_0.txt\n",
            "aclImdb/train/unsup/48880_0.txt\n",
            "aclImdb/train/unsup/48879_0.txt\n",
            "aclImdb/train/unsup/48878_0.txt\n",
            "aclImdb/train/unsup/48877_0.txt\n",
            "aclImdb/train/unsup/48876_0.txt\n",
            "aclImdb/train/unsup/48875_0.txt\n",
            "aclImdb/train/unsup/48874_0.txt\n",
            "aclImdb/train/unsup/48873_0.txt\n",
            "aclImdb/train/unsup/48872_0.txt\n",
            "aclImdb/train/unsup/48871_0.txt\n",
            "aclImdb/train/unsup/48870_0.txt\n",
            "aclImdb/train/unsup/48869_0.txt\n",
            "aclImdb/train/unsup/48868_0.txt\n",
            "aclImdb/train/unsup/48867_0.txt\n",
            "aclImdb/train/unsup/48866_0.txt\n",
            "aclImdb/train/unsup/48865_0.txt\n",
            "aclImdb/train/unsup/48864_0.txt\n",
            "aclImdb/train/unsup/48863_0.txt\n",
            "aclImdb/train/unsup/48862_0.txt\n",
            "aclImdb/train/unsup/48861_0.txt\n",
            "aclImdb/train/unsup/48860_0.txt\n",
            "aclImdb/train/unsup/48859_0.txt\n",
            "aclImdb/train/unsup/48858_0.txt\n",
            "aclImdb/train/unsup/48857_0.txt\n",
            "aclImdb/train/unsup/48856_0.txt\n",
            "aclImdb/train/unsup/48855_0.txt\n",
            "aclImdb/train/unsup/48854_0.txt\n",
            "aclImdb/train/unsup/48853_0.txt\n",
            "aclImdb/train/unsup/48852_0.txt\n",
            "aclImdb/train/unsup/48851_0.txt\n",
            "aclImdb/train/unsup/48850_0.txt\n",
            "aclImdb/train/unsup/48849_0.txt\n",
            "aclImdb/train/unsup/48848_0.txt\n",
            "aclImdb/train/unsup/48847_0.txt\n",
            "aclImdb/train/unsup/48846_0.txt\n",
            "aclImdb/train/unsup/48845_0.txt\n",
            "aclImdb/train/unsup/48844_0.txt\n",
            "aclImdb/train/unsup/48843_0.txt\n",
            "aclImdb/train/unsup/48842_0.txt\n",
            "aclImdb/train/unsup/48841_0.txt\n",
            "aclImdb/train/unsup/48840_0.txt\n",
            "aclImdb/train/unsup/48839_0.txt\n",
            "aclImdb/train/unsup/48838_0.txt\n",
            "aclImdb/train/unsup/48837_0.txt\n",
            "aclImdb/train/unsup/48836_0.txt\n",
            "aclImdb/train/unsup/48835_0.txt\n",
            "aclImdb/train/unsup/48834_0.txt\n",
            "aclImdb/train/unsup/48833_0.txt\n",
            "aclImdb/train/unsup/48832_0.txt\n",
            "aclImdb/train/unsup/48831_0.txt\n",
            "aclImdb/train/unsup/48830_0.txt\n",
            "aclImdb/train/unsup/48829_0.txt\n",
            "aclImdb/train/unsup/48828_0.txt\n",
            "aclImdb/train/unsup/48827_0.txt\n",
            "aclImdb/train/unsup/48826_0.txt\n",
            "aclImdb/train/unsup/48825_0.txt\n",
            "aclImdb/train/unsup/48824_0.txt\n",
            "aclImdb/train/unsup/48823_0.txt\n",
            "aclImdb/train/unsup/48822_0.txt\n",
            "aclImdb/train/unsup/48821_0.txt\n",
            "aclImdb/train/unsup/48820_0.txt\n",
            "aclImdb/train/unsup/48819_0.txt\n",
            "aclImdb/train/unsup/48818_0.txt\n",
            "aclImdb/train/unsup/48817_0.txt\n",
            "aclImdb/train/unsup/48816_0.txt\n",
            "aclImdb/train/unsup/48815_0.txt\n",
            "aclImdb/train/unsup/48814_0.txt\n",
            "aclImdb/train/unsup/48813_0.txt\n",
            "aclImdb/train/unsup/48812_0.txt\n",
            "aclImdb/train/unsup/48811_0.txt\n",
            "aclImdb/train/unsup/48810_0.txt\n",
            "aclImdb/train/unsup/48809_0.txt\n",
            "aclImdb/train/unsup/48808_0.txt\n",
            "aclImdb/train/unsup/48807_0.txt\n",
            "aclImdb/train/unsup/48806_0.txt\n",
            "aclImdb/train/unsup/48805_0.txt\n",
            "aclImdb/train/unsup/48804_0.txt\n",
            "aclImdb/train/unsup/48803_0.txt\n",
            "aclImdb/train/unsup/48802_0.txt\n",
            "aclImdb/train/unsup/48801_0.txt\n",
            "aclImdb/train/unsup/48800_0.txt\n",
            "aclImdb/train/unsup/48799_0.txt\n",
            "aclImdb/train/unsup/48798_0.txt\n",
            "aclImdb/train/unsup/48797_0.txt\n",
            "aclImdb/train/unsup/48796_0.txt\n",
            "aclImdb/train/unsup/48795_0.txt\n",
            "aclImdb/train/unsup/48794_0.txt\n",
            "aclImdb/train/unsup/48793_0.txt\n",
            "aclImdb/train/unsup/48792_0.txt\n",
            "aclImdb/train/unsup/48791_0.txt\n",
            "aclImdb/train/unsup/48790_0.txt\n",
            "aclImdb/train/unsup/48789_0.txt\n",
            "aclImdb/train/unsup/48788_0.txt\n",
            "aclImdb/train/unsup/48787_0.txt\n",
            "aclImdb/train/unsup/48786_0.txt\n",
            "aclImdb/train/unsup/48785_0.txt\n",
            "aclImdb/train/unsup/48784_0.txt\n",
            "aclImdb/train/unsup/48783_0.txt\n",
            "aclImdb/train/unsup/48782_0.txt\n",
            "aclImdb/train/unsup/48781_0.txt\n",
            "aclImdb/train/unsup/48780_0.txt\n",
            "aclImdb/train/unsup/48779_0.txt\n",
            "aclImdb/train/unsup/48778_0.txt\n",
            "aclImdb/train/unsup/48777_0.txt\n",
            "aclImdb/train/unsup/48776_0.txt\n",
            "aclImdb/train/unsup/48775_0.txt\n",
            "aclImdb/train/unsup/48774_0.txt\n",
            "aclImdb/train/unsup/48773_0.txt\n",
            "aclImdb/train/unsup/48772_0.txt\n",
            "aclImdb/train/unsup/48771_0.txt\n",
            "aclImdb/train/unsup/48770_0.txt\n",
            "aclImdb/train/unsup/48769_0.txt\n",
            "aclImdb/train/unsup/48768_0.txt\n",
            "aclImdb/train/unsup/49023_0.txt\n",
            "aclImdb/train/unsup/49022_0.txt\n",
            "aclImdb/train/unsup/49021_0.txt\n",
            "aclImdb/train/unsup/49020_0.txt\n",
            "aclImdb/train/unsup/49019_0.txt\n",
            "aclImdb/train/unsup/49018_0.txt\n",
            "aclImdb/train/unsup/49017_0.txt\n",
            "aclImdb/train/unsup/49016_0.txt\n",
            "aclImdb/train/unsup/49015_0.txt\n",
            "aclImdb/train/unsup/49014_0.txt\n",
            "aclImdb/train/unsup/49013_0.txt\n",
            "aclImdb/train/unsup/49012_0.txt\n",
            "aclImdb/train/unsup/49011_0.txt\n",
            "aclImdb/train/unsup/49010_0.txt\n",
            "aclImdb/train/unsup/49009_0.txt\n",
            "aclImdb/train/unsup/49008_0.txt\n",
            "aclImdb/train/unsup/49007_0.txt\n",
            "aclImdb/train/unsup/49006_0.txt\n",
            "aclImdb/train/unsup/49005_0.txt\n",
            "aclImdb/train/unsup/49004_0.txt\n",
            "aclImdb/train/unsup/49003_0.txt\n",
            "aclImdb/train/unsup/49002_0.txt\n",
            "aclImdb/train/unsup/49001_0.txt\n",
            "aclImdb/train/unsup/49000_0.txt\n",
            "aclImdb/train/unsup/48999_0.txt\n",
            "aclImdb/train/unsup/48998_0.txt\n",
            "aclImdb/train/unsup/48997_0.txt\n",
            "aclImdb/train/unsup/48996_0.txt\n",
            "aclImdb/train/unsup/48995_0.txt\n",
            "aclImdb/train/unsup/48994_0.txt\n",
            "aclImdb/train/unsup/48993_0.txt\n",
            "aclImdb/train/unsup/48992_0.txt\n",
            "aclImdb/train/unsup/48991_0.txt\n",
            "aclImdb/train/unsup/48990_0.txt\n",
            "aclImdb/train/unsup/48989_0.txt\n",
            "aclImdb/train/unsup/48988_0.txt\n",
            "aclImdb/train/unsup/48987_0.txt\n",
            "aclImdb/train/unsup/48986_0.txt\n",
            "aclImdb/train/unsup/48985_0.txt\n",
            "aclImdb/train/unsup/48984_0.txt\n",
            "aclImdb/train/unsup/48983_0.txt\n",
            "aclImdb/train/unsup/48982_0.txt\n",
            "aclImdb/train/unsup/48981_0.txt\n",
            "aclImdb/train/unsup/48980_0.txt\n",
            "aclImdb/train/unsup/48979_0.txt\n",
            "aclImdb/train/unsup/48978_0.txt\n",
            "aclImdb/train/unsup/48977_0.txt\n",
            "aclImdb/train/unsup/48976_0.txt\n",
            "aclImdb/train/unsup/48975_0.txt\n",
            "aclImdb/train/unsup/48974_0.txt\n",
            "aclImdb/train/unsup/48973_0.txt\n",
            "aclImdb/train/unsup/48972_0.txt\n",
            "aclImdb/train/unsup/48971_0.txt\n",
            "aclImdb/train/unsup/48970_0.txt\n",
            "aclImdb/train/unsup/48969_0.txt\n",
            "aclImdb/train/unsup/48968_0.txt\n",
            "aclImdb/train/unsup/48967_0.txt\n",
            "aclImdb/train/unsup/48966_0.txt\n",
            "aclImdb/train/unsup/48965_0.txt\n",
            "aclImdb/train/unsup/48964_0.txt\n",
            "aclImdb/train/unsup/48963_0.txt\n",
            "aclImdb/train/unsup/48962_0.txt\n",
            "aclImdb/train/unsup/48961_0.txt\n",
            "aclImdb/train/unsup/48960_0.txt\n",
            "aclImdb/train/unsup/48959_0.txt\n",
            "aclImdb/train/unsup/48958_0.txt\n",
            "aclImdb/train/unsup/48957_0.txt\n",
            "aclImdb/train/unsup/48956_0.txt\n",
            "aclImdb/train/unsup/48955_0.txt\n",
            "aclImdb/train/unsup/48954_0.txt\n",
            "aclImdb/train/unsup/48953_0.txt\n",
            "aclImdb/train/unsup/48952_0.txt\n",
            "aclImdb/train/unsup/48951_0.txt\n",
            "aclImdb/train/unsup/48950_0.txt\n",
            "aclImdb/train/unsup/48949_0.txt\n",
            "aclImdb/train/unsup/48948_0.txt\n",
            "aclImdb/train/unsup/48947_0.txt\n",
            "aclImdb/train/unsup/48946_0.txt\n",
            "aclImdb/train/unsup/48945_0.txt\n",
            "aclImdb/train/unsup/48944_0.txt\n",
            "aclImdb/train/unsup/48943_0.txt\n",
            "aclImdb/train/unsup/48942_0.txt\n",
            "aclImdb/train/unsup/48941_0.txt\n",
            "aclImdb/train/unsup/48940_0.txt\n",
            "aclImdb/train/unsup/48939_0.txt\n",
            "aclImdb/train/unsup/48938_0.txt\n",
            "aclImdb/train/unsup/48937_0.txt\n",
            "aclImdb/train/unsup/48936_0.txt\n",
            "aclImdb/train/unsup/48935_0.txt\n",
            "aclImdb/train/unsup/48934_0.txt\n",
            "aclImdb/train/unsup/48933_0.txt\n",
            "aclImdb/train/unsup/48932_0.txt\n",
            "aclImdb/train/unsup/48931_0.txt\n",
            "aclImdb/train/unsup/48930_0.txt\n",
            "aclImdb/train/unsup/48929_0.txt\n",
            "aclImdb/train/unsup/48928_0.txt\n",
            "aclImdb/train/unsup/48927_0.txt\n",
            "aclImdb/train/unsup/48926_0.txt\n",
            "aclImdb/train/unsup/48925_0.txt\n",
            "aclImdb/train/unsup/48924_0.txt\n",
            "aclImdb/train/unsup/48923_0.txt\n",
            "aclImdb/train/unsup/48922_0.txt\n",
            "aclImdb/train/unsup/48921_0.txt\n",
            "aclImdb/train/unsup/48920_0.txt\n",
            "aclImdb/train/unsup/48919_0.txt\n",
            "aclImdb/train/unsup/48918_0.txt\n",
            "aclImdb/train/unsup/48917_0.txt\n",
            "aclImdb/train/unsup/48916_0.txt\n",
            "aclImdb/train/unsup/48915_0.txt\n",
            "aclImdb/train/unsup/48914_0.txt\n",
            "aclImdb/train/unsup/48913_0.txt\n",
            "aclImdb/train/unsup/48912_0.txt\n",
            "aclImdb/train/unsup/48911_0.txt\n",
            "aclImdb/train/unsup/48910_0.txt\n",
            "aclImdb/train/unsup/48909_0.txt\n",
            "aclImdb/train/unsup/48908_0.txt\n",
            "aclImdb/train/unsup/48907_0.txt\n",
            "aclImdb/train/unsup/48906_0.txt\n",
            "aclImdb/train/unsup/48905_0.txt\n",
            "aclImdb/train/unsup/48904_0.txt\n",
            "aclImdb/train/unsup/48903_0.txt\n",
            "aclImdb/train/unsup/48902_0.txt\n",
            "aclImdb/train/unsup/48901_0.txt\n",
            "aclImdb/train/unsup/48900_0.txt\n",
            "aclImdb/train/unsup/48899_0.txt\n",
            "aclImdb/train/unsup/48898_0.txt\n",
            "aclImdb/train/unsup/48897_0.txt\n",
            "aclImdb/train/unsup/48896_0.txt\n",
            "aclImdb/train/unsup/49151_0.txt\n",
            "aclImdb/train/unsup/49150_0.txt\n",
            "aclImdb/train/unsup/49149_0.txt\n",
            "aclImdb/train/unsup/49148_0.txt\n",
            "aclImdb/train/unsup/49147_0.txt\n",
            "aclImdb/train/unsup/49146_0.txt\n",
            "aclImdb/train/unsup/49145_0.txt\n",
            "aclImdb/train/unsup/49144_0.txt\n",
            "aclImdb/train/unsup/49143_0.txt\n",
            "aclImdb/train/unsup/49142_0.txt\n",
            "aclImdb/train/unsup/49141_0.txt\n",
            "aclImdb/train/unsup/49140_0.txt\n",
            "aclImdb/train/unsup/49139_0.txt\n",
            "aclImdb/train/unsup/49138_0.txt\n",
            "aclImdb/train/unsup/49137_0.txt\n",
            "aclImdb/train/unsup/49136_0.txt\n",
            "aclImdb/train/unsup/49135_0.txt\n",
            "aclImdb/train/unsup/49134_0.txt\n",
            "aclImdb/train/unsup/49133_0.txt\n",
            "aclImdb/train/unsup/49132_0.txt\n",
            "aclImdb/train/unsup/49131_0.txt\n",
            "aclImdb/train/unsup/49130_0.txt\n",
            "aclImdb/train/unsup/49129_0.txt\n",
            "aclImdb/train/unsup/49128_0.txt\n",
            "aclImdb/train/unsup/49127_0.txt\n",
            "aclImdb/train/unsup/49126_0.txt\n",
            "aclImdb/train/unsup/49125_0.txt\n",
            "aclImdb/train/unsup/49124_0.txt\n",
            "aclImdb/train/unsup/49123_0.txt\n",
            "aclImdb/train/unsup/49122_0.txt\n",
            "aclImdb/train/unsup/49121_0.txt\n",
            "aclImdb/train/unsup/49120_0.txt\n",
            "aclImdb/train/unsup/49119_0.txt\n",
            "aclImdb/train/unsup/49118_0.txt\n",
            "aclImdb/train/unsup/49117_0.txt\n",
            "aclImdb/train/unsup/49116_0.txt\n",
            "aclImdb/train/unsup/49115_0.txt\n",
            "aclImdb/train/unsup/49114_0.txt\n",
            "aclImdb/train/unsup/49113_0.txt\n",
            "aclImdb/train/unsup/49112_0.txt\n",
            "aclImdb/train/unsup/49111_0.txt\n",
            "aclImdb/train/unsup/49110_0.txt\n",
            "aclImdb/train/unsup/49109_0.txt\n",
            "aclImdb/train/unsup/49108_0.txt\n",
            "aclImdb/train/unsup/49107_0.txt\n",
            "aclImdb/train/unsup/49106_0.txt\n",
            "aclImdb/train/unsup/49105_0.txt\n",
            "aclImdb/train/unsup/49104_0.txt\n",
            "aclImdb/train/unsup/49103_0.txt\n",
            "aclImdb/train/unsup/49102_0.txt\n",
            "aclImdb/train/unsup/49101_0.txt\n",
            "aclImdb/train/unsup/49100_0.txt\n",
            "aclImdb/train/unsup/49099_0.txt\n",
            "aclImdb/train/unsup/49098_0.txt\n",
            "aclImdb/train/unsup/49097_0.txt\n",
            "aclImdb/train/unsup/49096_0.txt\n",
            "aclImdb/train/unsup/49095_0.txt\n",
            "aclImdb/train/unsup/49094_0.txt\n",
            "aclImdb/train/unsup/49093_0.txt\n",
            "aclImdb/train/unsup/49092_0.txt\n",
            "aclImdb/train/unsup/49091_0.txt\n",
            "aclImdb/train/unsup/49090_0.txt\n",
            "aclImdb/train/unsup/49089_0.txt\n",
            "aclImdb/train/unsup/49088_0.txt\n",
            "aclImdb/train/unsup/49087_0.txt\n",
            "aclImdb/train/unsup/49086_0.txt\n",
            "aclImdb/train/unsup/49085_0.txt\n",
            "aclImdb/train/unsup/49084_0.txt\n",
            "aclImdb/train/unsup/49083_0.txt\n",
            "aclImdb/train/unsup/49082_0.txt\n",
            "aclImdb/train/unsup/49081_0.txt\n",
            "aclImdb/train/unsup/49080_0.txt\n",
            "aclImdb/train/unsup/49079_0.txt\n",
            "aclImdb/train/unsup/49078_0.txt\n",
            "aclImdb/train/unsup/49077_0.txt\n",
            "aclImdb/train/unsup/49076_0.txt\n",
            "aclImdb/train/unsup/49075_0.txt\n",
            "aclImdb/train/unsup/49074_0.txt\n",
            "aclImdb/train/unsup/49073_0.txt\n",
            "aclImdb/train/unsup/49072_0.txt\n",
            "aclImdb/train/unsup/49071_0.txt\n",
            "aclImdb/train/unsup/49070_0.txt\n",
            "aclImdb/train/unsup/49069_0.txt\n",
            "aclImdb/train/unsup/49068_0.txt\n",
            "aclImdb/train/unsup/49067_0.txt\n",
            "aclImdb/train/unsup/49066_0.txt\n",
            "aclImdb/train/unsup/49065_0.txt\n",
            "aclImdb/train/unsup/49064_0.txt\n",
            "aclImdb/train/unsup/49063_0.txt\n",
            "aclImdb/train/unsup/49062_0.txt\n",
            "aclImdb/train/unsup/49061_0.txt\n",
            "aclImdb/train/unsup/49060_0.txt\n",
            "aclImdb/train/unsup/49059_0.txt\n",
            "aclImdb/train/unsup/49058_0.txt\n",
            "aclImdb/train/unsup/49057_0.txt\n",
            "aclImdb/train/unsup/49056_0.txt\n",
            "aclImdb/train/unsup/49055_0.txt\n",
            "aclImdb/train/unsup/49054_0.txt\n",
            "aclImdb/train/unsup/49053_0.txt\n",
            "aclImdb/train/unsup/49052_0.txt\n",
            "aclImdb/train/unsup/49051_0.txt\n",
            "aclImdb/train/unsup/49050_0.txt\n",
            "aclImdb/train/unsup/49049_0.txt\n",
            "aclImdb/train/unsup/49048_0.txt\n",
            "aclImdb/train/unsup/49047_0.txt\n",
            "aclImdb/train/unsup/49046_0.txt\n",
            "aclImdb/train/unsup/49045_0.txt\n",
            "aclImdb/train/unsup/49044_0.txt\n",
            "aclImdb/train/unsup/49043_0.txt\n",
            "aclImdb/train/unsup/49042_0.txt\n",
            "aclImdb/train/unsup/49041_0.txt\n",
            "aclImdb/train/unsup/49040_0.txt\n",
            "aclImdb/train/unsup/49039_0.txt\n",
            "aclImdb/train/unsup/49038_0.txt\n",
            "aclImdb/train/unsup/49037_0.txt\n",
            "aclImdb/train/unsup/49036_0.txt\n",
            "aclImdb/train/unsup/49035_0.txt\n",
            "aclImdb/train/unsup/49034_0.txt\n",
            "aclImdb/train/unsup/49033_0.txt\n",
            "aclImdb/train/unsup/49032_0.txt\n",
            "aclImdb/train/unsup/49031_0.txt\n",
            "aclImdb/train/unsup/49030_0.txt\n",
            "aclImdb/train/unsup/49029_0.txt\n",
            "aclImdb/train/unsup/49028_0.txt\n",
            "aclImdb/train/unsup/49027_0.txt\n",
            "aclImdb/train/unsup/49026_0.txt\n",
            "aclImdb/train/unsup/49025_0.txt\n",
            "aclImdb/train/unsup/49024_0.txt\n",
            "aclImdb/train/unsup/49279_0.txt\n",
            "aclImdb/train/unsup/49278_0.txt\n",
            "aclImdb/train/unsup/49277_0.txt\n",
            "aclImdb/train/unsup/49276_0.txt\n",
            "aclImdb/train/unsup/49275_0.txt\n",
            "aclImdb/train/unsup/49274_0.txt\n",
            "aclImdb/train/unsup/49273_0.txt\n",
            "aclImdb/train/unsup/49272_0.txt\n",
            "aclImdb/train/unsup/49271_0.txt\n",
            "aclImdb/train/unsup/49270_0.txt\n",
            "aclImdb/train/unsup/49269_0.txt\n",
            "aclImdb/train/unsup/49268_0.txt\n",
            "aclImdb/train/unsup/49267_0.txt\n",
            "aclImdb/train/unsup/49266_0.txt\n",
            "aclImdb/train/unsup/49265_0.txt\n",
            "aclImdb/train/unsup/49264_0.txt\n",
            "aclImdb/train/unsup/49263_0.txt\n",
            "aclImdb/train/unsup/49262_0.txt\n",
            "aclImdb/train/unsup/49261_0.txt\n",
            "aclImdb/train/unsup/49260_0.txt\n",
            "aclImdb/train/unsup/49259_0.txt\n",
            "aclImdb/train/unsup/49258_0.txt\n",
            "aclImdb/train/unsup/49257_0.txt\n",
            "aclImdb/train/unsup/49256_0.txt\n",
            "aclImdb/train/unsup/49255_0.txt\n",
            "aclImdb/train/unsup/49254_0.txt\n",
            "aclImdb/train/unsup/49253_0.txt\n",
            "aclImdb/train/unsup/49252_0.txt\n",
            "aclImdb/train/unsup/49251_0.txt\n",
            "aclImdb/train/unsup/49250_0.txt\n",
            "aclImdb/train/unsup/49249_0.txt\n",
            "aclImdb/train/unsup/49248_0.txt\n",
            "aclImdb/train/unsup/49247_0.txt\n",
            "aclImdb/train/unsup/49246_0.txt\n",
            "aclImdb/train/unsup/49245_0.txt\n",
            "aclImdb/train/unsup/49244_0.txt\n",
            "aclImdb/train/unsup/49243_0.txt\n",
            "aclImdb/train/unsup/49242_0.txt\n",
            "aclImdb/train/unsup/49241_0.txt\n",
            "aclImdb/train/unsup/49240_0.txt\n",
            "aclImdb/train/unsup/49239_0.txt\n",
            "aclImdb/train/unsup/49238_0.txt\n",
            "aclImdb/train/unsup/49237_0.txt\n",
            "aclImdb/train/unsup/49236_0.txt\n",
            "aclImdb/train/unsup/49235_0.txt\n",
            "aclImdb/train/unsup/49234_0.txt\n",
            "aclImdb/train/unsup/49233_0.txt\n",
            "aclImdb/train/unsup/49232_0.txt\n",
            "aclImdb/train/unsup/49231_0.txt\n",
            "aclImdb/train/unsup/49230_0.txt\n",
            "aclImdb/train/unsup/49229_0.txt\n",
            "aclImdb/train/unsup/49228_0.txt\n",
            "aclImdb/train/unsup/49227_0.txt\n",
            "aclImdb/train/unsup/49226_0.txt\n",
            "aclImdb/train/unsup/49225_0.txt\n",
            "aclImdb/train/unsup/49224_0.txt\n",
            "aclImdb/train/unsup/49223_0.txt\n",
            "aclImdb/train/unsup/49222_0.txt\n",
            "aclImdb/train/unsup/49221_0.txt\n",
            "aclImdb/train/unsup/49220_0.txt\n",
            "aclImdb/train/unsup/49219_0.txt\n",
            "aclImdb/train/unsup/49218_0.txt\n",
            "aclImdb/train/unsup/49217_0.txt\n",
            "aclImdb/train/unsup/49216_0.txt\n",
            "aclImdb/train/unsup/49215_0.txt\n",
            "aclImdb/train/unsup/49214_0.txt\n",
            "aclImdb/train/unsup/49213_0.txt\n",
            "aclImdb/train/unsup/49212_0.txt\n",
            "aclImdb/train/unsup/49211_0.txt\n",
            "aclImdb/train/unsup/49210_0.txt\n",
            "aclImdb/train/unsup/49209_0.txt\n",
            "aclImdb/train/unsup/49208_0.txt\n",
            "aclImdb/train/unsup/49207_0.txt\n",
            "aclImdb/train/unsup/49206_0.txt\n",
            "aclImdb/train/unsup/49205_0.txt\n",
            "aclImdb/train/unsup/49204_0.txt\n",
            "aclImdb/train/unsup/49203_0.txt\n",
            "aclImdb/train/unsup/49202_0.txt\n",
            "aclImdb/train/unsup/49201_0.txt\n",
            "aclImdb/train/unsup/49200_0.txt\n",
            "aclImdb/train/unsup/49199_0.txt\n",
            "aclImdb/train/unsup/49198_0.txt\n",
            "aclImdb/train/unsup/49197_0.txt\n",
            "aclImdb/train/unsup/49196_0.txt\n",
            "aclImdb/train/unsup/49195_0.txt\n",
            "aclImdb/train/unsup/49194_0.txt\n",
            "aclImdb/train/unsup/49193_0.txt\n",
            "aclImdb/train/unsup/49192_0.txt\n",
            "aclImdb/train/unsup/49191_0.txt\n",
            "aclImdb/train/unsup/49190_0.txt\n",
            "aclImdb/train/unsup/49189_0.txt\n",
            "aclImdb/train/unsup/49188_0.txt\n",
            "aclImdb/train/unsup/49187_0.txt\n",
            "aclImdb/train/unsup/49186_0.txt\n",
            "aclImdb/train/unsup/49185_0.txt\n",
            "aclImdb/train/unsup/49184_0.txt\n",
            "aclImdb/train/unsup/49183_0.txt\n",
            "aclImdb/train/unsup/49182_0.txt\n",
            "aclImdb/train/unsup/49181_0.txt\n",
            "aclImdb/train/unsup/49180_0.txt\n",
            "aclImdb/train/unsup/49179_0.txt\n",
            "aclImdb/train/unsup/49178_0.txt\n",
            "aclImdb/train/unsup/49177_0.txt\n",
            "aclImdb/train/unsup/49176_0.txt\n",
            "aclImdb/train/unsup/49175_0.txt\n",
            "aclImdb/train/unsup/49174_0.txt\n",
            "aclImdb/train/unsup/49173_0.txt\n",
            "aclImdb/train/unsup/49172_0.txt\n",
            "aclImdb/train/unsup/49171_0.txt\n",
            "aclImdb/train/unsup/49170_0.txt\n",
            "aclImdb/train/unsup/49169_0.txt\n",
            "aclImdb/train/unsup/49168_0.txt\n",
            "aclImdb/train/unsup/49167_0.txt\n",
            "aclImdb/train/unsup/49166_0.txt\n",
            "aclImdb/train/unsup/49165_0.txt\n",
            "aclImdb/train/unsup/49164_0.txt\n",
            "aclImdb/train/unsup/49163_0.txt\n",
            "aclImdb/train/unsup/49162_0.txt\n",
            "aclImdb/train/unsup/49161_0.txt\n",
            "aclImdb/train/unsup/49160_0.txt\n",
            "aclImdb/train/unsup/49159_0.txt\n",
            "aclImdb/train/unsup/49158_0.txt\n",
            "aclImdb/train/unsup/49157_0.txt\n",
            "aclImdb/train/unsup/49156_0.txt\n",
            "aclImdb/train/unsup/49155_0.txt\n",
            "aclImdb/train/unsup/49154_0.txt\n",
            "aclImdb/train/unsup/49153_0.txt\n",
            "aclImdb/train/unsup/49152_0.txt\n",
            "aclImdb/train/unsup/49407_0.txt\n",
            "aclImdb/train/unsup/49406_0.txt\n",
            "aclImdb/train/unsup/49405_0.txt\n",
            "aclImdb/train/unsup/49404_0.txt\n",
            "aclImdb/train/unsup/49403_0.txt\n",
            "aclImdb/train/unsup/49402_0.txt\n",
            "aclImdb/train/unsup/49401_0.txt\n",
            "aclImdb/train/unsup/49400_0.txt\n",
            "aclImdb/train/unsup/49399_0.txt\n",
            "aclImdb/train/unsup/49398_0.txt\n",
            "aclImdb/train/unsup/49397_0.txt\n",
            "aclImdb/train/unsup/49396_0.txt\n",
            "aclImdb/train/unsup/49395_0.txt\n",
            "aclImdb/train/unsup/49394_0.txt\n",
            "aclImdb/train/unsup/49393_0.txt\n",
            "aclImdb/train/unsup/49392_0.txt\n",
            "aclImdb/train/unsup/49391_0.txt\n",
            "aclImdb/train/unsup/49390_0.txt\n",
            "aclImdb/train/unsup/49389_0.txt\n",
            "aclImdb/train/unsup/49388_0.txt\n",
            "aclImdb/train/unsup/49387_0.txt\n",
            "aclImdb/train/unsup/49386_0.txt\n",
            "aclImdb/train/unsup/49385_0.txt\n",
            "aclImdb/train/unsup/49384_0.txt\n",
            "aclImdb/train/unsup/49383_0.txt\n",
            "aclImdb/train/unsup/49382_0.txt\n",
            "aclImdb/train/unsup/49381_0.txt\n",
            "aclImdb/train/unsup/49380_0.txt\n",
            "aclImdb/train/unsup/49379_0.txt\n",
            "aclImdb/train/unsup/49378_0.txt\n",
            "aclImdb/train/unsup/49377_0.txt\n",
            "aclImdb/train/unsup/49376_0.txt\n",
            "aclImdb/train/unsup/49375_0.txt\n",
            "aclImdb/train/unsup/49374_0.txt\n",
            "aclImdb/train/unsup/49373_0.txt\n",
            "aclImdb/train/unsup/49372_0.txt\n",
            "aclImdb/train/unsup/49371_0.txt\n",
            "aclImdb/train/unsup/49370_0.txt\n",
            "aclImdb/train/unsup/49369_0.txt\n",
            "aclImdb/train/unsup/49368_0.txt\n",
            "aclImdb/train/unsup/49367_0.txt\n",
            "aclImdb/train/unsup/49366_0.txt\n",
            "aclImdb/train/unsup/49365_0.txt\n",
            "aclImdb/train/unsup/49364_0.txt\n",
            "aclImdb/train/unsup/49363_0.txt\n",
            "aclImdb/train/unsup/49362_0.txt\n",
            "aclImdb/train/unsup/49361_0.txt\n",
            "aclImdb/train/unsup/49360_0.txt\n",
            "aclImdb/train/unsup/49359_0.txt\n",
            "aclImdb/train/unsup/49358_0.txt\n",
            "aclImdb/train/unsup/49357_0.txt\n",
            "aclImdb/train/unsup/49356_0.txt\n",
            "aclImdb/train/unsup/49355_0.txt\n",
            "aclImdb/train/unsup/49354_0.txt\n",
            "aclImdb/train/unsup/49353_0.txt\n",
            "aclImdb/train/unsup/49352_0.txt\n",
            "aclImdb/train/unsup/49351_0.txt\n",
            "aclImdb/train/unsup/49350_0.txt\n",
            "aclImdb/train/unsup/49349_0.txt\n",
            "aclImdb/train/unsup/49348_0.txt\n",
            "aclImdb/train/unsup/49347_0.txt\n",
            "aclImdb/train/unsup/49346_0.txt\n",
            "aclImdb/train/unsup/49345_0.txt\n",
            "aclImdb/train/unsup/49344_0.txt\n",
            "aclImdb/train/unsup/49343_0.txt\n",
            "aclImdb/train/unsup/49342_0.txt\n",
            "aclImdb/train/unsup/49341_0.txt\n",
            "aclImdb/train/unsup/49340_0.txt\n",
            "aclImdb/train/unsup/49339_0.txt\n",
            "aclImdb/train/unsup/49338_0.txt\n",
            "aclImdb/train/unsup/49337_0.txt\n",
            "aclImdb/train/unsup/49336_0.txt\n",
            "aclImdb/train/unsup/49335_0.txt\n",
            "aclImdb/train/unsup/49334_0.txt\n",
            "aclImdb/train/unsup/49333_0.txt\n",
            "aclImdb/train/unsup/49332_0.txt\n",
            "aclImdb/train/unsup/49331_0.txt\n",
            "aclImdb/train/unsup/49330_0.txt\n",
            "aclImdb/train/unsup/49329_0.txt\n",
            "aclImdb/train/unsup/49328_0.txt\n",
            "aclImdb/train/unsup/49327_0.txt\n",
            "aclImdb/train/unsup/49326_0.txt\n",
            "aclImdb/train/unsup/49325_0.txt\n",
            "aclImdb/train/unsup/49324_0.txt\n",
            "aclImdb/train/unsup/49323_0.txt\n",
            "aclImdb/train/unsup/49322_0.txt\n",
            "aclImdb/train/unsup/49321_0.txt\n",
            "aclImdb/train/unsup/49320_0.txt\n",
            "aclImdb/train/unsup/49319_0.txt\n",
            "aclImdb/train/unsup/49318_0.txt\n",
            "aclImdb/train/unsup/49317_0.txt\n",
            "aclImdb/train/unsup/49316_0.txt\n",
            "aclImdb/train/unsup/49315_0.txt\n",
            "aclImdb/train/unsup/49314_0.txt\n",
            "aclImdb/train/unsup/49313_0.txt\n",
            "aclImdb/train/unsup/49312_0.txt\n",
            "aclImdb/train/unsup/49311_0.txt\n",
            "aclImdb/train/unsup/49310_0.txt\n",
            "aclImdb/train/unsup/49309_0.txt\n",
            "aclImdb/train/unsup/49308_0.txt\n",
            "aclImdb/train/unsup/49307_0.txt\n",
            "aclImdb/train/unsup/49306_0.txt\n",
            "aclImdb/train/unsup/49305_0.txt\n",
            "aclImdb/train/unsup/49304_0.txt\n",
            "aclImdb/train/unsup/49303_0.txt\n",
            "aclImdb/train/unsup/49302_0.txt\n",
            "aclImdb/train/unsup/49301_0.txt\n",
            "aclImdb/train/unsup/49300_0.txt\n",
            "aclImdb/train/unsup/49299_0.txt\n",
            "aclImdb/train/unsup/49298_0.txt\n",
            "aclImdb/train/unsup/49297_0.txt\n",
            "aclImdb/train/unsup/49296_0.txt\n",
            "aclImdb/train/unsup/49295_0.txt\n",
            "aclImdb/train/unsup/49294_0.txt\n",
            "aclImdb/train/unsup/49293_0.txt\n",
            "aclImdb/train/unsup/49292_0.txt\n",
            "aclImdb/train/unsup/49291_0.txt\n",
            "aclImdb/train/unsup/49290_0.txt\n",
            "aclImdb/train/unsup/49289_0.txt\n",
            "aclImdb/train/unsup/49288_0.txt\n",
            "aclImdb/train/unsup/49287_0.txt\n",
            "aclImdb/train/unsup/49286_0.txt\n",
            "aclImdb/train/unsup/49285_0.txt\n",
            "aclImdb/train/unsup/49284_0.txt\n",
            "aclImdb/train/unsup/49283_0.txt\n",
            "aclImdb/train/unsup/49282_0.txt\n",
            "aclImdb/train/unsup/49281_0.txt\n",
            "aclImdb/train/unsup/49280_0.txt\n",
            "aclImdb/train/unsup/49535_0.txt\n",
            "aclImdb/train/unsup/49534_0.txt\n",
            "aclImdb/train/unsup/49533_0.txt\n",
            "aclImdb/train/unsup/49532_0.txt\n",
            "aclImdb/train/unsup/49531_0.txt\n",
            "aclImdb/train/unsup/49530_0.txt\n",
            "aclImdb/train/unsup/49529_0.txt\n",
            "aclImdb/train/unsup/49528_0.txt\n",
            "aclImdb/train/unsup/49527_0.txt\n",
            "aclImdb/train/unsup/49526_0.txt\n",
            "aclImdb/train/unsup/49525_0.txt\n",
            "aclImdb/train/unsup/49524_0.txt\n",
            "aclImdb/train/unsup/49523_0.txt\n",
            "aclImdb/train/unsup/49522_0.txt\n",
            "aclImdb/train/unsup/49521_0.txt\n",
            "aclImdb/train/unsup/49520_0.txt\n",
            "aclImdb/train/unsup/49519_0.txt\n",
            "aclImdb/train/unsup/49518_0.txt\n",
            "aclImdb/train/unsup/49517_0.txt\n",
            "aclImdb/train/unsup/49516_0.txt\n",
            "aclImdb/train/unsup/49515_0.txt\n",
            "aclImdb/train/unsup/49514_0.txt\n",
            "aclImdb/train/unsup/49513_0.txt\n",
            "aclImdb/train/unsup/49512_0.txt\n",
            "aclImdb/train/unsup/49511_0.txt\n",
            "aclImdb/train/unsup/49510_0.txt\n",
            "aclImdb/train/unsup/49509_0.txt\n",
            "aclImdb/train/unsup/49508_0.txt\n",
            "aclImdb/train/unsup/49507_0.txt\n",
            "aclImdb/train/unsup/49506_0.txt\n",
            "aclImdb/train/unsup/49505_0.txt\n",
            "aclImdb/train/unsup/49504_0.txt\n",
            "aclImdb/train/unsup/49503_0.txt\n",
            "aclImdb/train/unsup/49502_0.txt\n",
            "aclImdb/train/unsup/49501_0.txt\n",
            "aclImdb/train/unsup/49500_0.txt\n",
            "aclImdb/train/unsup/49499_0.txt\n",
            "aclImdb/train/unsup/49498_0.txt\n",
            "aclImdb/train/unsup/49497_0.txt\n",
            "aclImdb/train/unsup/49496_0.txt\n",
            "aclImdb/train/unsup/49495_0.txt\n",
            "aclImdb/train/unsup/49494_0.txt\n",
            "aclImdb/train/unsup/49493_0.txt\n",
            "aclImdb/train/unsup/49492_0.txt\n",
            "aclImdb/train/unsup/49491_0.txt\n",
            "aclImdb/train/unsup/49490_0.txt\n",
            "aclImdb/train/unsup/49489_0.txt\n",
            "aclImdb/train/unsup/49488_0.txt\n",
            "aclImdb/train/unsup/49487_0.txt\n",
            "aclImdb/train/unsup/49486_0.txt\n",
            "aclImdb/train/unsup/49485_0.txt\n",
            "aclImdb/train/unsup/49484_0.txt\n",
            "aclImdb/train/unsup/49483_0.txt\n",
            "aclImdb/train/unsup/49482_0.txt\n",
            "aclImdb/train/unsup/49481_0.txt\n",
            "aclImdb/train/unsup/49480_0.txt\n",
            "aclImdb/train/unsup/49479_0.txt\n",
            "aclImdb/train/unsup/49478_0.txt\n",
            "aclImdb/train/unsup/49477_0.txt\n",
            "aclImdb/train/unsup/49476_0.txt\n",
            "aclImdb/train/unsup/49475_0.txt\n",
            "aclImdb/train/unsup/49474_0.txt\n",
            "aclImdb/train/unsup/49473_0.txt\n",
            "aclImdb/train/unsup/49472_0.txt\n",
            "aclImdb/train/unsup/49471_0.txt\n",
            "aclImdb/train/unsup/49470_0.txt\n",
            "aclImdb/train/unsup/49469_0.txt\n",
            "aclImdb/train/unsup/49468_0.txt\n",
            "aclImdb/train/unsup/49467_0.txt\n",
            "aclImdb/train/unsup/49466_0.txt\n",
            "aclImdb/train/unsup/49465_0.txt\n",
            "aclImdb/train/unsup/49464_0.txt\n",
            "aclImdb/train/unsup/49463_0.txt\n",
            "aclImdb/train/unsup/49462_0.txt\n",
            "aclImdb/train/unsup/49461_0.txt\n",
            "aclImdb/train/unsup/49460_0.txt\n",
            "aclImdb/train/unsup/49459_0.txt\n",
            "aclImdb/train/unsup/49458_0.txt\n",
            "aclImdb/train/unsup/49457_0.txt\n",
            "aclImdb/train/unsup/49456_0.txt\n",
            "aclImdb/train/unsup/49455_0.txt\n",
            "aclImdb/train/unsup/49454_0.txt\n",
            "aclImdb/train/unsup/49453_0.txt\n",
            "aclImdb/train/unsup/49452_0.txt\n",
            "aclImdb/train/unsup/49451_0.txt\n",
            "aclImdb/train/unsup/49450_0.txt\n",
            "aclImdb/train/unsup/49449_0.txt\n",
            "aclImdb/train/unsup/49448_0.txt\n",
            "aclImdb/train/unsup/49447_0.txt\n",
            "aclImdb/train/unsup/49446_0.txt\n",
            "aclImdb/train/unsup/49445_0.txt\n",
            "aclImdb/train/unsup/49444_0.txt\n",
            "aclImdb/train/unsup/49443_0.txt\n",
            "aclImdb/train/unsup/49442_0.txt\n",
            "aclImdb/train/unsup/49441_0.txt\n",
            "aclImdb/train/unsup/49440_0.txt\n",
            "aclImdb/train/unsup/49439_0.txt\n",
            "aclImdb/train/unsup/49438_0.txt\n",
            "aclImdb/train/unsup/49437_0.txt\n",
            "aclImdb/train/unsup/49436_0.txt\n",
            "aclImdb/train/unsup/49435_0.txt\n",
            "aclImdb/train/unsup/49434_0.txt\n",
            "aclImdb/train/unsup/49433_0.txt\n",
            "aclImdb/train/unsup/49432_0.txt\n",
            "aclImdb/train/unsup/49431_0.txt\n",
            "aclImdb/train/unsup/49430_0.txt\n",
            "aclImdb/train/unsup/49429_0.txt\n",
            "aclImdb/train/unsup/49428_0.txt\n",
            "aclImdb/train/unsup/49427_0.txt\n",
            "aclImdb/train/unsup/49426_0.txt\n",
            "aclImdb/train/unsup/49425_0.txt\n",
            "aclImdb/train/unsup/49424_0.txt\n",
            "aclImdb/train/unsup/49423_0.txt\n",
            "aclImdb/train/unsup/49422_0.txt\n",
            "aclImdb/train/unsup/49421_0.txt\n",
            "aclImdb/train/unsup/49420_0.txt\n",
            "aclImdb/train/unsup/49419_0.txt\n",
            "aclImdb/train/unsup/49418_0.txt\n",
            "aclImdb/train/unsup/49417_0.txt\n",
            "aclImdb/train/unsup/49416_0.txt\n",
            "aclImdb/train/unsup/49415_0.txt\n",
            "aclImdb/train/unsup/49414_0.txt\n",
            "aclImdb/train/unsup/49413_0.txt\n",
            "aclImdb/train/unsup/49412_0.txt\n",
            "aclImdb/train/unsup/49411_0.txt\n",
            "aclImdb/train/unsup/49410_0.txt\n",
            "aclImdb/train/unsup/49409_0.txt\n",
            "aclImdb/train/unsup/49408_0.txt\n",
            "aclImdb/train/unsup/49663_0.txt\n",
            "aclImdb/train/unsup/49662_0.txt\n",
            "aclImdb/train/unsup/49661_0.txt\n",
            "aclImdb/train/unsup/49660_0.txt\n",
            "aclImdb/train/unsup/49659_0.txt\n",
            "aclImdb/train/unsup/49658_0.txt\n",
            "aclImdb/train/unsup/49657_0.txt\n",
            "aclImdb/train/unsup/49656_0.txt\n",
            "aclImdb/train/unsup/49655_0.txt\n",
            "aclImdb/train/unsup/49654_0.txt\n",
            "aclImdb/train/unsup/49653_0.txt\n",
            "aclImdb/train/unsup/49652_0.txt\n",
            "aclImdb/train/unsup/49651_0.txt\n",
            "aclImdb/train/unsup/49650_0.txt\n",
            "aclImdb/train/unsup/49649_0.txt\n",
            "aclImdb/train/unsup/49648_0.txt\n",
            "aclImdb/train/unsup/49647_0.txt\n",
            "aclImdb/train/unsup/49646_0.txt\n",
            "aclImdb/train/unsup/49645_0.txt\n",
            "aclImdb/train/unsup/49644_0.txt\n",
            "aclImdb/train/unsup/49643_0.txt\n",
            "aclImdb/train/unsup/49642_0.txt\n",
            "aclImdb/train/unsup/49641_0.txt\n",
            "aclImdb/train/unsup/49640_0.txt\n",
            "aclImdb/train/unsup/49639_0.txt\n",
            "aclImdb/train/unsup/49638_0.txt\n",
            "aclImdb/train/unsup/49637_0.txt\n",
            "aclImdb/train/unsup/49636_0.txt\n",
            "aclImdb/train/unsup/49635_0.txt\n",
            "aclImdb/train/unsup/49634_0.txt\n",
            "aclImdb/train/unsup/49633_0.txt\n",
            "aclImdb/train/unsup/49632_0.txt\n",
            "aclImdb/train/unsup/49631_0.txt\n",
            "aclImdb/train/unsup/49630_0.txt\n",
            "aclImdb/train/unsup/49629_0.txt\n",
            "aclImdb/train/unsup/49628_0.txt\n",
            "aclImdb/train/unsup/49627_0.txt\n",
            "aclImdb/train/unsup/49626_0.txt\n",
            "aclImdb/train/unsup/49625_0.txt\n",
            "aclImdb/train/unsup/49624_0.txt\n",
            "aclImdb/train/unsup/49623_0.txt\n",
            "aclImdb/train/unsup/49622_0.txt\n",
            "aclImdb/train/unsup/49621_0.txt\n",
            "aclImdb/train/unsup/49620_0.txt\n",
            "aclImdb/train/unsup/49619_0.txt\n",
            "aclImdb/train/unsup/49618_0.txt\n",
            "aclImdb/train/unsup/49617_0.txt\n",
            "aclImdb/train/unsup/49616_0.txt\n",
            "aclImdb/train/unsup/49615_0.txt\n",
            "aclImdb/train/unsup/49614_0.txt\n",
            "aclImdb/train/unsup/49613_0.txt\n",
            "aclImdb/train/unsup/49612_0.txt\n",
            "aclImdb/train/unsup/49611_0.txt\n",
            "aclImdb/train/unsup/49610_0.txt\n",
            "aclImdb/train/unsup/49609_0.txt\n",
            "aclImdb/train/unsup/49608_0.txt\n",
            "aclImdb/train/unsup/49607_0.txt\n",
            "aclImdb/train/unsup/49606_0.txt\n",
            "aclImdb/train/unsup/49605_0.txt\n",
            "aclImdb/train/unsup/49604_0.txt\n",
            "aclImdb/train/unsup/49603_0.txt\n",
            "aclImdb/train/unsup/49602_0.txt\n",
            "aclImdb/train/unsup/49601_0.txt\n",
            "aclImdb/train/unsup/49600_0.txt\n",
            "aclImdb/train/unsup/49599_0.txt\n",
            "aclImdb/train/unsup/49598_0.txt\n",
            "aclImdb/train/unsup/49597_0.txt\n",
            "aclImdb/train/unsup/49596_0.txt\n",
            "aclImdb/train/unsup/49595_0.txt\n",
            "aclImdb/train/unsup/49594_0.txt\n",
            "aclImdb/train/unsup/49593_0.txt\n",
            "aclImdb/train/unsup/49592_0.txt\n",
            "aclImdb/train/unsup/49591_0.txt\n",
            "aclImdb/train/unsup/49590_0.txt\n",
            "aclImdb/train/unsup/49589_0.txt\n",
            "aclImdb/train/unsup/49588_0.txt\n",
            "aclImdb/train/unsup/49587_0.txt\n",
            "aclImdb/train/unsup/49586_0.txt\n",
            "aclImdb/train/unsup/49585_0.txt\n",
            "aclImdb/train/unsup/49584_0.txt\n",
            "aclImdb/train/unsup/49583_0.txt\n",
            "aclImdb/train/unsup/49582_0.txt\n",
            "aclImdb/train/unsup/49581_0.txt\n",
            "aclImdb/train/unsup/49580_0.txt\n",
            "aclImdb/train/unsup/49579_0.txt\n",
            "aclImdb/train/unsup/49578_0.txt\n",
            "aclImdb/train/unsup/49577_0.txt\n",
            "aclImdb/train/unsup/49576_0.txt\n",
            "aclImdb/train/unsup/49575_0.txt\n",
            "aclImdb/train/unsup/49574_0.txt\n",
            "aclImdb/train/unsup/49573_0.txt\n",
            "aclImdb/train/unsup/49572_0.txt\n",
            "aclImdb/train/unsup/49571_0.txt\n",
            "aclImdb/train/unsup/49570_0.txt\n",
            "aclImdb/train/unsup/49569_0.txt\n",
            "aclImdb/train/unsup/49568_0.txt\n",
            "aclImdb/train/unsup/49567_0.txt\n",
            "aclImdb/train/unsup/49566_0.txt\n",
            "aclImdb/train/unsup/49565_0.txt\n",
            "aclImdb/train/unsup/49564_0.txt\n",
            "aclImdb/train/unsup/49563_0.txt\n",
            "aclImdb/train/unsup/49562_0.txt\n",
            "aclImdb/train/unsup/49561_0.txt\n",
            "aclImdb/train/unsup/49560_0.txt\n",
            "aclImdb/train/unsup/49559_0.txt\n",
            "aclImdb/train/unsup/49558_0.txt\n",
            "aclImdb/train/unsup/49557_0.txt\n",
            "aclImdb/train/unsup/49556_0.txt\n",
            "aclImdb/train/unsup/49555_0.txt\n",
            "aclImdb/train/unsup/49554_0.txt\n",
            "aclImdb/train/unsup/49553_0.txt\n",
            "aclImdb/train/unsup/49552_0.txt\n",
            "aclImdb/train/unsup/49551_0.txt\n",
            "aclImdb/train/unsup/49550_0.txt\n",
            "aclImdb/train/unsup/49549_0.txt\n",
            "aclImdb/train/unsup/49548_0.txt\n",
            "aclImdb/train/unsup/49547_0.txt\n",
            "aclImdb/train/unsup/49546_0.txt\n",
            "aclImdb/train/unsup/49545_0.txt\n",
            "aclImdb/train/unsup/49544_0.txt\n",
            "aclImdb/train/unsup/49543_0.txt\n",
            "aclImdb/train/unsup/49542_0.txt\n",
            "aclImdb/train/unsup/49541_0.txt\n",
            "aclImdb/train/unsup/49540_0.txt\n",
            "aclImdb/train/unsup/49539_0.txt\n",
            "aclImdb/train/unsup/49538_0.txt\n",
            "aclImdb/train/unsup/49537_0.txt\n",
            "aclImdb/train/unsup/49536_0.txt\n",
            "aclImdb/train/unsup/49791_0.txt\n",
            "aclImdb/train/unsup/49790_0.txt\n",
            "aclImdb/train/unsup/49789_0.txt\n",
            "aclImdb/train/unsup/49788_0.txt\n",
            "aclImdb/train/unsup/49787_0.txt\n",
            "aclImdb/train/unsup/49786_0.txt\n",
            "aclImdb/train/unsup/49785_0.txt\n",
            "aclImdb/train/unsup/49784_0.txt\n",
            "aclImdb/train/unsup/49783_0.txt\n",
            "aclImdb/train/unsup/49782_0.txt\n",
            "aclImdb/train/unsup/49781_0.txt\n",
            "aclImdb/train/unsup/49780_0.txt\n",
            "aclImdb/train/unsup/49779_0.txt\n",
            "aclImdb/train/unsup/49778_0.txt\n",
            "aclImdb/train/unsup/49777_0.txt\n",
            "aclImdb/train/unsup/49776_0.txt\n",
            "aclImdb/train/unsup/49775_0.txt\n",
            "aclImdb/train/unsup/49774_0.txt\n",
            "aclImdb/train/unsup/49773_0.txt\n",
            "aclImdb/train/unsup/49772_0.txt\n",
            "aclImdb/train/unsup/49771_0.txt\n",
            "aclImdb/train/unsup/49770_0.txt\n",
            "aclImdb/train/unsup/49769_0.txt\n",
            "aclImdb/train/unsup/49768_0.txt\n",
            "aclImdb/train/unsup/49767_0.txt\n",
            "aclImdb/train/unsup/49766_0.txt\n",
            "aclImdb/train/unsup/49765_0.txt\n",
            "aclImdb/train/unsup/49764_0.txt\n",
            "aclImdb/train/unsup/49763_0.txt\n",
            "aclImdb/train/unsup/49762_0.txt\n",
            "aclImdb/train/unsup/49761_0.txt\n",
            "aclImdb/train/unsup/49760_0.txt\n",
            "aclImdb/train/unsup/49759_0.txt\n",
            "aclImdb/train/unsup/49758_0.txt\n",
            "aclImdb/train/unsup/49757_0.txt\n",
            "aclImdb/train/unsup/49756_0.txt\n",
            "aclImdb/train/unsup/49755_0.txt\n",
            "aclImdb/train/unsup/49754_0.txt\n",
            "aclImdb/train/unsup/49753_0.txt\n",
            "aclImdb/train/unsup/49752_0.txt\n",
            "aclImdb/train/unsup/49751_0.txt\n",
            "aclImdb/train/unsup/49750_0.txt\n",
            "aclImdb/train/unsup/49749_0.txt\n",
            "aclImdb/train/unsup/49748_0.txt\n",
            "aclImdb/train/unsup/49747_0.txt\n",
            "aclImdb/train/unsup/49746_0.txt\n",
            "aclImdb/train/unsup/49745_0.txt\n",
            "aclImdb/train/unsup/49744_0.txt\n",
            "aclImdb/train/unsup/49743_0.txt\n",
            "aclImdb/train/unsup/49742_0.txt\n",
            "aclImdb/train/unsup/49741_0.txt\n",
            "aclImdb/train/unsup/49740_0.txt\n",
            "aclImdb/train/unsup/49739_0.txt\n",
            "aclImdb/train/unsup/49738_0.txt\n",
            "aclImdb/train/unsup/49737_0.txt\n",
            "aclImdb/train/unsup/49736_0.txt\n",
            "aclImdb/train/unsup/49735_0.txt\n",
            "aclImdb/train/unsup/49734_0.txt\n",
            "aclImdb/train/unsup/49733_0.txt\n",
            "aclImdb/train/unsup/49732_0.txt\n",
            "aclImdb/train/unsup/49731_0.txt\n",
            "aclImdb/train/unsup/49730_0.txt\n",
            "aclImdb/train/unsup/49729_0.txt\n",
            "aclImdb/train/unsup/49728_0.txt\n",
            "aclImdb/train/unsup/49727_0.txt\n",
            "aclImdb/train/unsup/49726_0.txt\n",
            "aclImdb/train/unsup/49725_0.txt\n",
            "aclImdb/train/unsup/49724_0.txt\n",
            "aclImdb/train/unsup/49723_0.txt\n",
            "aclImdb/train/unsup/49722_0.txt\n",
            "aclImdb/train/unsup/49721_0.txt\n",
            "aclImdb/train/unsup/49720_0.txt\n",
            "aclImdb/train/unsup/49719_0.txt\n",
            "aclImdb/train/unsup/49718_0.txt\n",
            "aclImdb/train/unsup/49717_0.txt\n",
            "aclImdb/train/unsup/49716_0.txt\n",
            "aclImdb/train/unsup/49715_0.txt\n",
            "aclImdb/train/unsup/49714_0.txt\n",
            "aclImdb/train/unsup/49713_0.txt\n",
            "aclImdb/train/unsup/49712_0.txt\n",
            "aclImdb/train/unsup/49711_0.txt\n",
            "aclImdb/train/unsup/49710_0.txt\n",
            "aclImdb/train/unsup/49709_0.txt\n",
            "aclImdb/train/unsup/49708_0.txt\n",
            "aclImdb/train/unsup/49707_0.txt\n",
            "aclImdb/train/unsup/49706_0.txt\n",
            "aclImdb/train/unsup/49705_0.txt\n",
            "aclImdb/train/unsup/49704_0.txt\n",
            "aclImdb/train/unsup/49703_0.txt\n",
            "aclImdb/train/unsup/49702_0.txt\n",
            "aclImdb/train/unsup/49701_0.txt\n",
            "aclImdb/train/unsup/49700_0.txt\n",
            "aclImdb/train/unsup/49699_0.txt\n",
            "aclImdb/train/unsup/49698_0.txt\n",
            "aclImdb/train/unsup/49697_0.txt\n",
            "aclImdb/train/unsup/49696_0.txt\n",
            "aclImdb/train/unsup/49695_0.txt\n",
            "aclImdb/train/unsup/49694_0.txt\n",
            "aclImdb/train/unsup/49693_0.txt\n",
            "aclImdb/train/unsup/49692_0.txt\n",
            "aclImdb/train/unsup/49691_0.txt\n",
            "aclImdb/train/unsup/49690_0.txt\n",
            "aclImdb/train/unsup/49689_0.txt\n",
            "aclImdb/train/unsup/49688_0.txt\n",
            "aclImdb/train/unsup/49687_0.txt\n",
            "aclImdb/train/unsup/49686_0.txt\n",
            "aclImdb/train/unsup/49685_0.txt\n",
            "aclImdb/train/unsup/49684_0.txt\n",
            "aclImdb/train/unsup/49683_0.txt\n",
            "aclImdb/train/unsup/49682_0.txt\n",
            "aclImdb/train/unsup/49681_0.txt\n",
            "aclImdb/train/unsup/49680_0.txt\n",
            "aclImdb/train/unsup/49679_0.txt\n",
            "aclImdb/train/unsup/49678_0.txt\n",
            "aclImdb/train/unsup/49677_0.txt\n",
            "aclImdb/train/unsup/49676_0.txt\n",
            "aclImdb/train/unsup/49675_0.txt\n",
            "aclImdb/train/unsup/49674_0.txt\n",
            "aclImdb/train/unsup/49673_0.txt\n",
            "aclImdb/train/unsup/49672_0.txt\n",
            "aclImdb/train/unsup/49671_0.txt\n",
            "aclImdb/train/unsup/49670_0.txt\n",
            "aclImdb/train/unsup/49669_0.txt\n",
            "aclImdb/train/unsup/49668_0.txt\n",
            "aclImdb/train/unsup/49667_0.txt\n",
            "aclImdb/train/unsup/49666_0.txt\n",
            "aclImdb/train/unsup/49665_0.txt\n",
            "aclImdb/train/unsup/49664_0.txt\n",
            "aclImdb/train/unsup/49919_0.txt\n",
            "aclImdb/train/unsup/49918_0.txt\n",
            "aclImdb/train/unsup/49917_0.txt\n",
            "aclImdb/train/unsup/49916_0.txt\n",
            "aclImdb/train/unsup/49915_0.txt\n",
            "aclImdb/train/unsup/49914_0.txt\n",
            "aclImdb/train/unsup/49913_0.txt\n",
            "aclImdb/train/unsup/49912_0.txt\n",
            "aclImdb/train/unsup/49911_0.txt\n",
            "aclImdb/train/unsup/49910_0.txt\n",
            "aclImdb/train/unsup/49909_0.txt\n",
            "aclImdb/train/unsup/49908_0.txt\n",
            "aclImdb/train/unsup/49907_0.txt\n",
            "aclImdb/train/unsup/49906_0.txt\n",
            "aclImdb/train/unsup/49905_0.txt\n",
            "aclImdb/train/unsup/49904_0.txt\n",
            "aclImdb/train/unsup/49903_0.txt\n",
            "aclImdb/train/unsup/49902_0.txt\n",
            "aclImdb/train/unsup/49901_0.txt\n",
            "aclImdb/train/unsup/49900_0.txt\n",
            "aclImdb/train/unsup/49899_0.txt\n",
            "aclImdb/train/unsup/49898_0.txt\n",
            "aclImdb/train/unsup/49897_0.txt\n",
            "aclImdb/train/unsup/49896_0.txt\n",
            "aclImdb/train/unsup/49895_0.txt\n",
            "aclImdb/train/unsup/49894_0.txt\n",
            "aclImdb/train/unsup/49893_0.txt\n",
            "aclImdb/train/unsup/49892_0.txt\n",
            "aclImdb/train/unsup/49891_0.txt\n",
            "aclImdb/train/unsup/49890_0.txt\n",
            "aclImdb/train/unsup/49889_0.txt\n",
            "aclImdb/train/unsup/49888_0.txt\n",
            "aclImdb/train/unsup/49887_0.txt\n",
            "aclImdb/train/unsup/49886_0.txt\n",
            "aclImdb/train/unsup/49885_0.txt\n",
            "aclImdb/train/unsup/49884_0.txt\n",
            "aclImdb/train/unsup/49883_0.txt\n",
            "aclImdb/train/unsup/49882_0.txt\n",
            "aclImdb/train/unsup/49881_0.txt\n",
            "aclImdb/train/unsup/49880_0.txt\n",
            "aclImdb/train/unsup/49879_0.txt\n",
            "aclImdb/train/unsup/49878_0.txt\n",
            "aclImdb/train/unsup/49877_0.txt\n",
            "aclImdb/train/unsup/49876_0.txt\n",
            "aclImdb/train/unsup/49875_0.txt\n",
            "aclImdb/train/unsup/49874_0.txt\n",
            "aclImdb/train/unsup/49873_0.txt\n",
            "aclImdb/train/unsup/49872_0.txt\n",
            "aclImdb/train/unsup/49871_0.txt\n",
            "aclImdb/train/unsup/49870_0.txt\n",
            "aclImdb/train/unsup/49869_0.txt\n",
            "aclImdb/train/unsup/49868_0.txt\n",
            "aclImdb/train/unsup/49867_0.txt\n",
            "aclImdb/train/unsup/49866_0.txt\n",
            "aclImdb/train/unsup/49865_0.txt\n",
            "aclImdb/train/unsup/49864_0.txt\n",
            "aclImdb/train/unsup/49863_0.txt\n",
            "aclImdb/train/unsup/49862_0.txt\n",
            "aclImdb/train/unsup/49861_0.txt\n",
            "aclImdb/train/unsup/49860_0.txt\n",
            "aclImdb/train/unsup/49859_0.txt\n",
            "aclImdb/train/unsup/49858_0.txt\n",
            "aclImdb/train/unsup/49857_0.txt\n",
            "aclImdb/train/unsup/49856_0.txt\n",
            "aclImdb/train/unsup/49855_0.txt\n",
            "aclImdb/train/unsup/49854_0.txt\n",
            "aclImdb/train/unsup/49853_0.txt\n",
            "aclImdb/train/unsup/49852_0.txt\n",
            "aclImdb/train/unsup/49851_0.txt\n",
            "aclImdb/train/unsup/49850_0.txt\n",
            "aclImdb/train/unsup/49849_0.txt\n",
            "aclImdb/train/unsup/49848_0.txt\n",
            "aclImdb/train/unsup/49847_0.txt\n",
            "aclImdb/train/unsup/49846_0.txt\n",
            "aclImdb/train/unsup/49845_0.txt\n",
            "aclImdb/train/unsup/49844_0.txt\n",
            "aclImdb/train/unsup/49843_0.txt\n",
            "aclImdb/train/unsup/49842_0.txt\n",
            "aclImdb/train/unsup/49841_0.txt\n",
            "aclImdb/train/unsup/49840_0.txt\n",
            "aclImdb/train/unsup/49839_0.txt\n",
            "aclImdb/train/unsup/49838_0.txt\n",
            "aclImdb/train/unsup/49837_0.txt\n",
            "aclImdb/train/unsup/49836_0.txt\n",
            "aclImdb/train/unsup/49835_0.txt\n",
            "aclImdb/train/unsup/49834_0.txt\n",
            "aclImdb/train/unsup/49833_0.txt\n",
            "aclImdb/train/unsup/49832_0.txt\n",
            "aclImdb/train/unsup/49831_0.txt\n",
            "aclImdb/train/unsup/49830_0.txt\n",
            "aclImdb/train/unsup/49829_0.txt\n",
            "aclImdb/train/unsup/49828_0.txt\n",
            "aclImdb/train/unsup/49827_0.txt\n",
            "aclImdb/train/unsup/49826_0.txt\n",
            "aclImdb/train/unsup/49825_0.txt\n",
            "aclImdb/train/unsup/49824_0.txt\n",
            "aclImdb/train/unsup/49823_0.txt\n",
            "aclImdb/train/unsup/49822_0.txt\n",
            "aclImdb/train/unsup/49821_0.txt\n",
            "aclImdb/train/unsup/49820_0.txt\n",
            "aclImdb/train/unsup/49819_0.txt\n",
            "aclImdb/train/unsup/49818_0.txt\n",
            "aclImdb/train/unsup/49817_0.txt\n",
            "aclImdb/train/unsup/49816_0.txt\n",
            "aclImdb/train/unsup/49815_0.txt\n",
            "aclImdb/train/unsup/49814_0.txt\n",
            "aclImdb/train/unsup/49813_0.txt\n",
            "aclImdb/train/unsup/49812_0.txt\n",
            "aclImdb/train/unsup/49811_0.txt\n",
            "aclImdb/train/unsup/49810_0.txt\n",
            "aclImdb/train/unsup/49809_0.txt\n",
            "aclImdb/train/unsup/49808_0.txt\n",
            "aclImdb/train/unsup/49807_0.txt\n",
            "aclImdb/train/unsup/49806_0.txt\n",
            "aclImdb/train/unsup/49805_0.txt\n",
            "aclImdb/train/unsup/49804_0.txt\n",
            "aclImdb/train/unsup/49803_0.txt\n",
            "aclImdb/train/unsup/49802_0.txt\n",
            "aclImdb/train/unsup/49801_0.txt\n",
            "aclImdb/train/unsup/49800_0.txt\n",
            "aclImdb/train/unsup/49799_0.txt\n",
            "aclImdb/train/unsup/49798_0.txt\n",
            "aclImdb/train/unsup/49797_0.txt\n",
            "aclImdb/train/unsup/49796_0.txt\n",
            "aclImdb/train/unsup/49795_0.txt\n",
            "aclImdb/train/unsup/49794_0.txt\n",
            "aclImdb/train/unsup/49793_0.txt\n",
            "aclImdb/train/unsup/49792_0.txt\n",
            "aclImdb/train/unsup/49999_0.txt\n",
            "aclImdb/train/unsup/49998_0.txt\n",
            "aclImdb/train/unsup/49997_0.txt\n",
            "aclImdb/train/unsup/49996_0.txt\n",
            "aclImdb/train/unsup/49995_0.txt\n",
            "aclImdb/train/unsup/49994_0.txt\n",
            "aclImdb/train/unsup/49993_0.txt\n",
            "aclImdb/train/unsup/49992_0.txt\n",
            "aclImdb/train/unsup/49991_0.txt\n",
            "aclImdb/train/unsup/49990_0.txt\n",
            "aclImdb/train/unsup/49989_0.txt\n",
            "aclImdb/train/unsup/49988_0.txt\n",
            "aclImdb/train/unsup/49987_0.txt\n",
            "aclImdb/train/unsup/49986_0.txt\n",
            "aclImdb/train/unsup/49985_0.txt\n",
            "aclImdb/train/unsup/49984_0.txt\n",
            "aclImdb/train/unsup/49983_0.txt\n",
            "aclImdb/train/unsup/49982_0.txt\n",
            "aclImdb/train/unsup/49981_0.txt\n",
            "aclImdb/train/unsup/49980_0.txt\n",
            "aclImdb/train/unsup/49979_0.txt\n",
            "aclImdb/train/unsup/49978_0.txt\n",
            "aclImdb/train/unsup/49977_0.txt\n",
            "aclImdb/train/unsup/49976_0.txt\n",
            "aclImdb/train/unsup/49975_0.txt\n",
            "aclImdb/train/unsup/49974_0.txt\n",
            "aclImdb/train/unsup/49973_0.txt\n",
            "aclImdb/train/unsup/49972_0.txt\n",
            "aclImdb/train/unsup/49971_0.txt\n",
            "aclImdb/train/unsup/49970_0.txt\n",
            "aclImdb/train/unsup/49969_0.txt\n",
            "aclImdb/train/unsup/49968_0.txt\n",
            "aclImdb/train/unsup/49967_0.txt\n",
            "aclImdb/train/unsup/49966_0.txt\n",
            "aclImdb/train/unsup/49965_0.txt\n",
            "aclImdb/train/unsup/49964_0.txt\n",
            "aclImdb/train/unsup/49963_0.txt\n",
            "aclImdb/train/unsup/49962_0.txt\n",
            "aclImdb/train/unsup/49961_0.txt\n",
            "aclImdb/train/unsup/49960_0.txt\n",
            "aclImdb/train/unsup/49959_0.txt\n",
            "aclImdb/train/unsup/49958_0.txt\n",
            "aclImdb/train/unsup/49957_0.txt\n",
            "aclImdb/train/unsup/49956_0.txt\n",
            "aclImdb/train/unsup/49955_0.txt\n",
            "aclImdb/train/unsup/49954_0.txt\n",
            "aclImdb/train/unsup/49953_0.txt\n",
            "aclImdb/train/unsup/49952_0.txt\n",
            "aclImdb/train/unsup/49951_0.txt\n",
            "aclImdb/train/unsup/49950_0.txt\n",
            "aclImdb/train/unsup/49949_0.txt\n",
            "aclImdb/train/unsup/49948_0.txt\n",
            "aclImdb/train/unsup/49947_0.txt\n",
            "aclImdb/train/unsup/49946_0.txt\n",
            "aclImdb/train/unsup/49945_0.txt\n",
            "aclImdb/train/unsup/49944_0.txt\n",
            "aclImdb/train/unsup/49943_0.txt\n",
            "aclImdb/train/unsup/49942_0.txt\n",
            "aclImdb/train/unsup/49941_0.txt\n",
            "aclImdb/train/unsup/49940_0.txt\n",
            "aclImdb/train/unsup/49939_0.txt\n",
            "aclImdb/train/unsup/49938_0.txt\n",
            "aclImdb/train/unsup/49937_0.txt\n",
            "aclImdb/train/unsup/49936_0.txt\n",
            "aclImdb/train/unsup/49935_0.txt\n",
            "aclImdb/train/unsup/49934_0.txt\n",
            "aclImdb/train/unsup/49933_0.txt\n",
            "aclImdb/train/unsup/49932_0.txt\n",
            "aclImdb/train/unsup/49931_0.txt\n",
            "aclImdb/train/unsup/49930_0.txt\n",
            "aclImdb/train/unsup/49929_0.txt\n",
            "aclImdb/train/unsup/49928_0.txt\n",
            "aclImdb/train/unsup/49927_0.txt\n",
            "aclImdb/train/unsup/49926_0.txt\n",
            "aclImdb/train/unsup/49925_0.txt\n",
            "aclImdb/train/unsup/49924_0.txt\n",
            "aclImdb/train/unsup/49923_0.txt\n",
            "aclImdb/train/unsup/49922_0.txt\n",
            "aclImdb/train/unsup/49921_0.txt\n",
            "aclImdb/train/unsup/49920_0.txt\n"
          ]
        }
      ],
      "source": [
        "!tar -xvf aclImdb_v1.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Baf9TzzsXXu8",
        "outputId": "bdeaa9a1-fd97-474f-e780-0796102a4caa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cleaning up dataset...\n",
            " train/pos: 12500 files\n",
            " train/neg: 12500 files\n",
            " test/pos: 12500 files\n",
            " test/neg: 12500 files\n",
            " train/unsup: 50000 files\n",
            "Success, alldata-id.txt is available for next steps.\n"
          ]
        }
      ],
      "source": [
        "from smart_open import smart_open\n",
        "\n",
        "# Collect & normalize test/train data\n",
        "print(\"Cleaning up dataset...\")\n",
        "folders = ['train/pos', 'train/neg', 'test/pos', 'test/neg', 'train/unsup']\n",
        "for fol in folders:\n",
        "    temp = u''\n",
        "    newline = \"\\n\".encode(\"utf-8\")\n",
        "    output = fol.replace('/', '-') + '.txt'\n",
        "    # Is there a better pattern to use?\n",
        "    txt_files = glob.glob(os.path.join(dirname, fol, '*.txt'))\n",
        "    print(\" %s: %i files\" % (fol, len(txt_files)))\n",
        "    with smart_open(os.path.join(dirname, output), \"wb\") as n:\n",
        "        for i, txt in enumerate(txt_files):\n",
        "            with smart_open(txt, \"rb\") as t:\n",
        "                one_text = t.read().decode(\"utf-8\")\n",
        "                for c in control_chars:\n",
        "                    one_text = one_text.replace(c, ' ')\n",
        "                one_text = normalize_text(one_text)\n",
        "                all_lines.append(one_text)\n",
        "                n.write(one_text.encode(\"utf-8\"))\n",
        "                n.write(newline)\n",
        "\n",
        "# Save to disk for instant re-use on any future runs\n",
        "with smart_open('alldata-id.txt', 'wb') as f:\n",
        "    for idx, line in enumerate(all_lines):\n",
        "        num_line = u\"_*{0} {1}\\n\".format(idx, line)\n",
        "        f.write(num_line.encode(\"utf-8\"))\n",
        "\n",
        "assert os.path.isfile(\"alldata-id.txt\"), \"alldata-id.txt unavailable\"\n",
        "print(\"Success, alldata-id.txt is available for next steps.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQiuXXyvXadl"
      },
      "source": [
        "The text data is small enough to be read into memory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KSlxyPbOXawK",
        "outputId": "0fa7666b-f69f-416d-bf8f-b093161b3e70"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100000 docs: 25000 train-sentiment, 25000 test-sentiment\n",
            "CPU times: user 3.11 s, sys: 879 ms, total: 3.99 s\n",
            "Wall time: 4 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "import gensim\n",
        "from gensim.models.doc2vec import TaggedDocument\n",
        "from collections import namedtuple\n",
        "\n",
        "# this data object class suffices as a `TaggedDocument` (with `words` and `tags`)\n",
        "# plus adds other state helpful for our later evaluation/reporting\n",
        "SentimentDocument = namedtuple('SentimentDocument', 'words tags split sentiment')\n",
        "\n",
        "alldocs = []\n",
        "with smart_open('alldata-id.txt', 'rb', encoding='utf-8') as alldata:\n",
        "    for line_no, line in enumerate(alldata):\n",
        "        tokens = gensim.utils.to_unicode(line).split()\n",
        "        words = tokens[1:]\n",
        "        tags = [line_no] # 'tags = [tokens[0]]' would also work at extra memory cost\n",
        "        split = ['train', 'test', 'extra', 'extra'][line_no//25000]  # 25k train, 25k test, 25k extra\n",
        "        sentiment = [1.0, 0.0, 1.0, 0.0, None, None, None, None][line_no//12500] # [12.5K pos, 12.5K neg]*2 then unknown\n",
        "        alldocs.append(SentimentDocument(words, tags, split, sentiment))\n",
        "\n",
        "train_docs = [doc for doc in alldocs if doc.split == 'train']\n",
        "test_docs = [doc for doc in alldocs if doc.split == 'test']\n",
        "\n",
        "print('%d docs: %d train-sentiment, %d test-sentiment' % (len(alldocs), len(train_docs), len(test_docs)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCXxAcB3Xiwq"
      },
      "source": [
        "Because the native document-order has similar-sentiment documents in large clumps – which is suboptimal for training – we work with once-shuffled copy of the training set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9IV61szQXjC7"
      },
      "outputs": [],
      "source": [
        "from random import shuffle\n",
        "doc_list = alldocs[:]\n",
        "shuffle(doc_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9b2wS3-XmMK"
      },
      "source": [
        "### Model setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mymvs_4gXsdN"
      },
      "source": [
        "We approximate the experiment of Le & Mikolov [\"Distributed Representations of Sentences and Documents\"](http://cs.stanford.edu/~quocle/paragraph_vector.pdf) with guidance from Mikolov's [example go.sh](https://groups.google.com/d/msg/word2vec-toolkit/Q49FIrNOQRo/J6KG8mUj45sJ):\n",
        "\n",
        "`./word2vec -train ../alldata-id.txt -output vectors.txt -cbow 0 -size 100 -window 10 -negative 5 -hs 0 -sample 1e-4 -threads 40 -binary 0 -iter 20 -min-count 1 -sentence-vectors 1`\n",
        "\n",
        "We vary the following parameter choices:\n",
        "* 100-dimensional vectors, as the 400-d vectors of the paper take a lot of memory and, in our tests of this task, don't seem to offer much benefit\n",
        "* Similarly, frequent word subsampling seems to decrease sentiment-prediction accuracy, so it's left out\n",
        "* `cbow=0` means skip-gram which is equivalent to the paper's 'PV-DBOW' mode, matched in gensim with `dm=0`\n",
        "* Added to that DBOW model are two DM models, one which averages context vectors (`dm_mean`) and one which concatenates them (`dm_concat`, resulting in a much larger, slower, more data-hungry model)\n",
        "* A `min_count=2` saves quite a bit of model memory, discarding only words that appear in a single doc (and are thus no more expressive than the unique-to-each doc vectors themselves)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fzE4DY1XXqo_",
        "outputId": "c544ccd1-0266-4544-f351-74241c54c43e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Doc2Vec(dbow,d100,n5,mc2,t2) vocabulary scanned & state initialized\n",
            "Doc2Vec(\"alpha=0.05\",dm/m,d100,n5,w10,mc2,t2) vocabulary scanned & state initialized\n",
            "Doc2Vec(dm/c,d100,n5,w5,mc2,t2) vocabulary scanned & state initialized\n",
            "CPU times: user 2min 4s, sys: 2.5 s, total: 2min 7s\n",
            "Wall time: 2min 5s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "from gensim.models import Doc2Vec\n",
        "import gensim.models.doc2vec\n",
        "from collections import OrderedDict\n",
        "import multiprocessing\n",
        "\n",
        "cores = multiprocessing.cpu_count()\n",
        "assert gensim.models.doc2vec.FAST_VERSION > -1, \"This will be painfully slow otherwise\"\n",
        "\n",
        "simple_models = [\n",
        "    # PV-DBOW plain\n",
        "    Doc2Vec(dm=0, vector_size=100, negative=5, hs=0, min_count=2, sample=0,\n",
        "            epochs=20, workers=cores),\n",
        "    # PV-DM w/ default averaging; a higher starting alpha may improve CBOW/PV-DM modes\n",
        "    Doc2Vec(dm=1, vector_size=100, window=10, negative=5, hs=0, min_count=2, sample=0,\n",
        "            epochs=20, workers=cores, alpha=0.05, comment='alpha=0.05'),\n",
        "    # PV-DM w/ concatenation - big, slow, experimental mode\n",
        "    # window=5 (both sides) approximates paper's apparent 10-word total window size\n",
        "    Doc2Vec(dm=1, dm_concat=1, vector_size=100, window=5, negative=5, hs=0, min_count=2, sample=0,\n",
        "            epochs=20, workers=cores),\n",
        "]\n",
        "\n",
        "for model in simple_models:\n",
        "    model.build_vocab(alldocs)\n",
        "    print(\"%s vocabulary scanned & state initialized\" % model)\n",
        "\n",
        "models_by_name = OrderedDict((str(model), model) for model in simple_models)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i56PqocWXyEx"
      },
      "source": [
        "Le and Mikolov notes that combining a paragraph vector from Distributed Bag of Words (DBOW) and Distributed Memory (DM) improves performance. We will follow, pairing the models together for evaluation. Here, we concatenate the paragraph vectors obtained from each model with the help of a thin wrapper class included in a gensim test module. (Note that this a separate, later concatenation of output-vectors than the kind of input-window-concatenation enabled by the `dm_concat=1` mode above.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXiqJgVG6FtW",
        "outputId": "7e130093-9abc-460d-9658-f7a329923959"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting testfixtures\n",
            "  Downloading testfixtures-7.0.3-py3-none-any.whl (98 kB)\n",
            "\u001b[K     |████████████████████████████████| 98 kB 4.4 MB/s \n",
            "\u001b[?25hInstalling collected packages: testfixtures\n",
            "Successfully installed testfixtures-7.0.3\n"
          ]
        }
      ],
      "source": [
        "!pip install testfixtures"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1X58ot7pXyV6"
      },
      "outputs": [],
      "source": [
        "# make sure: !pip install testfixtures\n",
        "\n",
        "from gensim.test.test_doc2vec import ConcatenatedDoc2Vec\n",
        "models_by_name['dbow+dmm'] = ConcatenatedDoc2Vec([simple_models[0], simple_models[1]])\n",
        "models_by_name['dbow+dmc'] = ConcatenatedDoc2Vec([simple_models[0], simple_models[2]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pw5TCPPBX35H"
      },
      "source": [
        "### Model training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZteLDZWmgUCo"
      },
      "source": [
        "Let's define some helper methods for evaluating the performance of our Doc2vec using paragraph vectors. We will classify document sentiments using a logistic regression model based on our paragraph embeddings. We will compare the error rates based on word embeddings from our various Doc2vec models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1re8PKD9gWcB"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import statsmodels.api as sm\n",
        "from random import sample\n",
        "\n",
        "def logistic_predictor_from_data(train_targets, train_regressors):\n",
        "    \"\"\"Fit a statsmodel logistic predictor on supplied data\"\"\"\n",
        "    logit = sm.Logit(train_targets, train_regressors)\n",
        "    predictor = logit.fit(disp=0)\n",
        "    # print(predictor.summary())\n",
        "    return predictor\n",
        "\n",
        "def error_rate_for_model(test_model, train_set, test_set,\n",
        "                         reinfer_train=False, reinfer_test=False,\n",
        "                         infer_steps=None, infer_alpha=None, infer_subsample=0.2):\n",
        "    \"\"\"Report error rate on test_doc sentiments, using supplied model and train_docs\"\"\"\n",
        "\n",
        "    train_targets = [doc.sentiment for doc in train_set]\n",
        "    if reinfer_train:\n",
        "        train_regressors = [test_model.infer_vector(doc.words, steps=infer_steps, alpha=infer_alpha) for doc in train_set]\n",
        "    else:\n",
        "        train_regressors = [test_model.docvecs[doc.tags[0]] for doc in train_set]\n",
        "    train_regressors = sm.add_constant(train_regressors)\n",
        "    predictor = logistic_predictor_from_data(train_targets, train_regressors)\n",
        "\n",
        "    test_data = test_set\n",
        "    if reinfer_test:\n",
        "        if infer_subsample < 1.0:\n",
        "            test_data = sample(test_data, int(infer_subsample * len(test_data)))\n",
        "        test_regressors = [test_model.infer_vector(doc.words, steps=infer_steps, alpha=infer_alpha) for doc in test_data]\n",
        "    else:\n",
        "        test_regressors = [test_model.docvecs[doc.tags[0]] for doc in test_docs]\n",
        "    test_regressors = sm.add_constant(test_regressors)\n",
        "\n",
        "    # Predict & evaluate\n",
        "    test_predictions = predictor.predict(test_regressors)\n",
        "    corrects = sum(np.rint(test_predictions) == [doc.sentiment for doc in test_data])\n",
        "    errors = len(test_predictions) - corrects\n",
        "    error_rate = float(errors) / len(test_predictions)\n",
        "    return (error_rate, errors, len(test_predictions), predictor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SezBWfFdgZzv"
      },
      "source": [
        "Note that doc-vector training is occurring on all documents of the dataset, which includes all TRAIN/TEST/DEV docs.\n",
        "\n",
        "We evaluate each model's sentiment predictive power based on error rate, and the evaluation is done for each model.\n",
        "\n",
        "(On a 4-core 2.6Ghz Intel Core i7, these 20 passes training and evaluating 3 main models takes about an hour.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "10Zrb8_vgdDv"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "error_rates = defaultdict(lambda: 1.0)  # To selectively print only best errors achieved"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "t4u2LF_7geoo",
        "outputId": "31fdd7cc-d984-4183-f788-596c5597c3d4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:gensim.models.base_any2vec:Effective 'alpha' higher than previous training cycles\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Doc2Vec(dbow,d100,n5,mc2,t2)\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/models/doc2vec.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, documents, corpus_file, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, callbacks)\u001b[0m\n\u001b[1;32m    793\u001b[0m             \u001b[0mAdditional\u001b[0m \u001b[0marguments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msee\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword2vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWord2Vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 795\u001b[0;31m             \u001b[0mAdditional\u001b[0m \u001b[0marguments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msee\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword2vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWord2Vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m         \u001b[0mSee\u001b[0m \u001b[0mAlso\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/models/base_any2vec.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, sentences, corpus_file, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, compute_loss, callbacks, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/models/base_any2vec.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, data_iterable, corpus_file, epochs, total_examples, total_words, queue_factor, report_delay, callbacks, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/models/base_any2vec.py\u001b[0m in \u001b[0;36m_train_epoch\u001b[0;34m(self, data_iterable, cur_epoch, total_examples, total_words, queue_factor, report_delay)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/models/base_any2vec.py\u001b[0m in \u001b[0;36m_log_epoch_progress\u001b[0;34m(self, progress_queue, job_queue, cur_epoch, total_examples, total_words, report_delay, is_corpus_file_mode)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_qsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"'timeout' must be a non-negative number\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Evaluating Doc2Vec(dbow,d100,n5,mc2,t2)\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-7664142d2416>\u001b[0m in \u001b[0;36merror_rate_for_model\u001b[0;34m(test_model, train_set, test_set, reinfer_train, reinfer_test, infer_steps, infer_alpha, infer_subsample)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mtrain_regressors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtest_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdocvecs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mtrain_regressors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_constant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_regressors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mpredictor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogistic_predictor_from_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_targets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_regressors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-7664142d2416>\u001b[0m in \u001b[0;36mlogistic_predictor_from_data\u001b[0;34m(train_targets, train_regressors)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;34m\"\"\"Fit a statsmodel logistic predictor on supplied data\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mlogit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLogit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_targets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_regressors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mpredictor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;31m# print(predictor.summary())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/statsmodels/discrete/discrete_model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, start_params, method, maxiter, full_output, disp, callback, **kwargs)\u001b[0m\n\u001b[1;32m   1978\u001b[0m                               \u001b[0mdisp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdisp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1979\u001b[0m                               \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1980\u001b[0;31m                               **kwargs)\n\u001b[0m\u001b[1;32m   1981\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1982\u001b[0m         \u001b[0mdiscretefit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogitResults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbnryfit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/statsmodels/discrete/discrete_model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, start_params, method, maxiter, full_output, disp, callback, **kwargs)\u001b[0m\n\u001b[1;32m    231\u001b[0m                              \u001b[0mdisp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdisp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m                              \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m                              **kwargs)\n\u001b[0m\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmlefit\u001b[0m  \u001b[0;31m# It is up to subclasses to wrap results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, start_params, method, maxiter, full_output, disp, fargs, callback, retall, skip_hessian, **kwargs)\u001b[0m\n\u001b[1;32m    525\u001b[0m                                                        \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m                                                        \u001b[0mretall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretall\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 527\u001b[0;31m                                                        full_output=full_output)\n\u001b[0m\u001b[1;32m    528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0;31m# NOTE: this is for fit_regularized and should be generalized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/statsmodels/base/optimizer.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, objective, gradient, start_params, fargs, kwargs, hessian, method, maxiter, full_output, disp, callback, retall)\u001b[0m\n\u001b[1;32m    225\u001b[0m                             \u001b[0mdisp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdisp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaxiter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m                             \u001b[0mretall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfull_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m                             hess=hessian)\n\u001b[0m\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m         optim_settings = {'optimizer': method, 'start_params': start_params,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/statsmodels/base/optimizer.py\u001b[0m in \u001b[0;36m_fit_newton\u001b[0;34m(f, score, start_params, fargs, kwargs, disp, maxiter, callback, retall, full_output, hess, ridge_factor)\u001b[0m\n\u001b[1;32m    413\u001b[0m     while (iterations < maxiter and np.any(np.abs(newparams -\n\u001b[1;32m    414\u001b[0m             oldparams) > tol)):\n\u001b[0;32m--> 415\u001b[0;31m         \u001b[0mH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;31m# regularize Hessian, not clear what ridge factor should be\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m         \u001b[0;31m# keyword option with absolute default 1e-10, see #1847\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py\u001b[0m in \u001b[0;36mhess\u001b[0;34m(params, *args)\u001b[0m\n\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mhess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 509\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhessian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/statsmodels/discrete/discrete_model.py\u001b[0m in \u001b[0;36mhessian\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m   1967\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexog\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1968\u001b[0m         \u001b[0mL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1969\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1970\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1971\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mAppender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDiscreteModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:gensim.models.base_any2vec:Effective 'alpha' higher than previous training cycles\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "0.104480 Doc2Vec(dbow,d100,n5,mc2,t2)\n",
            "\n",
            "Training Doc2Vec(\"alpha=0.05\",dm/m,d100,n5,w10,mc2,t2)\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/models/doc2vec.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, documents, corpus_file, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, callbacks)\u001b[0m\n\u001b[1;32m    793\u001b[0m             \u001b[0mAdditional\u001b[0m \u001b[0marguments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msee\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword2vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWord2Vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 795\u001b[0;31m             \u001b[0mAdditional\u001b[0m \u001b[0marguments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msee\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword2vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWord2Vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m         \u001b[0mSee\u001b[0m \u001b[0mAlso\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/models/base_any2vec.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, sentences, corpus_file, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, compute_loss, callbacks, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/models/base_any2vec.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, data_iterable, corpus_file, epochs, total_examples, total_words, queue_factor, report_delay, callbacks, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/models/base_any2vec.py\u001b[0m in \u001b[0;36m_train_epoch\u001b[0;34m(self, data_iterable, cur_epoch, total_examples, total_words, queue_factor, report_delay)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/models/base_any2vec.py\u001b[0m in \u001b[0;36m_log_epoch_progress\u001b[0;34m(self, progress_queue, job_queue, cur_epoch, total_examples, total_words, report_delay, is_corpus_file_mode)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_qsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"'timeout' must be a non-negative number\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Evaluating Doc2Vec(\"alpha=0.05\",dm/m,d100,n5,w10,mc2,t2)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:gensim.models.base_any2vec:Effective 'alpha' higher than previous training cycles\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 994 ms, sys: 283 ms, total: 1.28 s\n",
            "Wall time: 691 ms\n",
            "\n",
            "0.385720 Doc2Vec(\"alpha=0.05\",dm/m,d100,n5,w10,mc2,t2)\n",
            "\n",
            "Training Doc2Vec(dm/c,d100,n5,w5,mc2,t2)\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/models/doc2vec.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, documents, corpus_file, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, callbacks)\u001b[0m\n\u001b[1;32m    793\u001b[0m             \u001b[0mAdditional\u001b[0m \u001b[0marguments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msee\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword2vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWord2Vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 795\u001b[0;31m             \u001b[0mAdditional\u001b[0m \u001b[0marguments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msee\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword2vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWord2Vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m         \u001b[0mSee\u001b[0m \u001b[0mAlso\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/models/base_any2vec.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, sentences, corpus_file, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, compute_loss, callbacks, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/models/base_any2vec.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, data_iterable, corpus_file, epochs, total_examples, total_words, queue_factor, report_delay, callbacks, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/models/base_any2vec.py\u001b[0m in \u001b[0;36m_train_epoch\u001b[0;34m(self, data_iterable, cur_epoch, total_examples, total_words, queue_factor, report_delay)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/models/base_any2vec.py\u001b[0m in \u001b[0;36m_log_epoch_progress\u001b[0;34m(self, progress_queue, job_queue, cur_epoch, total_examples, total_words, report_delay, is_corpus_file_mode)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_qsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"'timeout' must be a non-negative number\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Evaluating Doc2Vec(dm/c,d100,n5,w5,mc2,t2)\n",
            "CPU times: user 1.23 s, sys: 321 ms, total: 1.56 s\n",
            "Wall time: 805 ms\n",
            "\n",
            "0.453640 Doc2Vec(dm/c,d100,n5,w5,mc2,t2)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for model in simple_models:\n",
        "    print(\"Training %s\" % model)\n",
        "    %time model.train(doc_list, total_examples=len(doc_list), epochs=model.epochs)\n",
        "\n",
        "    print(\"\\nEvaluating %s\" % model)\n",
        "    %time err_rate, err_count, test_count, predictor = error_rate_for_model(model, train_docs, test_docs)\n",
        "    error_rates[str(model)] = err_rate\n",
        "    print(\"\\n%f %s\\n\" % (err_rate, model))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 651
        },
        "id": "_Ou7PLpiggy7",
        "outputId": "58e2b5f9-dd78-4bad-d639-bed211b21f73"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Evaluating Doc2Vec(dbow,d100,n5,mc2,t2)+Doc2Vec(\"alpha=0.05\",dm/m,d100,n5,w10,mc2,t2)\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-7664142d2416>\u001b[0m in \u001b[0;36merror_rate_for_model\u001b[0;34m(test_model, train_set, test_set, reinfer_train, reinfer_test, infer_steps, infer_alpha, infer_subsample)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mtrain_regressors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtest_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdocvecs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mtrain_regressors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_constant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_regressors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mpredictor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogistic_predictor_from_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_targets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_regressors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-7664142d2416>\u001b[0m in \u001b[0;36mlogistic_predictor_from_data\u001b[0;34m(train_targets, train_regressors)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;34m\"\"\"Fit a statsmodel logistic predictor on supplied data\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mlogit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLogit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_targets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_regressors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mpredictor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;31m# print(predictor.summary())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/statsmodels/discrete/discrete_model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, start_params, method, maxiter, full_output, disp, callback, **kwargs)\u001b[0m\n\u001b[1;32m   1978\u001b[0m                               \u001b[0mdisp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdisp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1979\u001b[0m                               \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1980\u001b[0;31m                               **kwargs)\n\u001b[0m\u001b[1;32m   1981\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1982\u001b[0m         \u001b[0mdiscretefit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogitResults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbnryfit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/statsmodels/discrete/discrete_model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, start_params, method, maxiter, full_output, disp, callback, **kwargs)\u001b[0m\n\u001b[1;32m    231\u001b[0m                              \u001b[0mdisp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdisp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m                              \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m                              **kwargs)\n\u001b[0m\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmlefit\u001b[0m  \u001b[0;31m# It is up to subclasses to wrap results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, start_params, method, maxiter, full_output, disp, fargs, callback, retall, skip_hessian, **kwargs)\u001b[0m\n\u001b[1;32m    525\u001b[0m                                                        \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m                                                        \u001b[0mretall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretall\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 527\u001b[0;31m                                                        full_output=full_output)\n\u001b[0m\u001b[1;32m    528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0;31m# NOTE: this is for fit_regularized and should be generalized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/statsmodels/base/optimizer.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, objective, gradient, start_params, fargs, kwargs, hessian, method, maxiter, full_output, disp, callback, retall)\u001b[0m\n\u001b[1;32m    225\u001b[0m                             \u001b[0mdisp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdisp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaxiter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m                             \u001b[0mretall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfull_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m                             hess=hessian)\n\u001b[0m\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m         optim_settings = {'optimizer': method, 'start_params': start_params,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/statsmodels/base/optimizer.py\u001b[0m in \u001b[0;36m_fit_newton\u001b[0;34m(f, score, start_params, fargs, kwargs, disp, maxiter, callback, retall, full_output, hess, ridge_factor)\u001b[0m\n\u001b[1;32m    413\u001b[0m     while (iterations < maxiter and np.any(np.abs(newparams -\n\u001b[1;32m    414\u001b[0m             oldparams) > tol)):\n\u001b[0;32m--> 415\u001b[0;31m         \u001b[0mH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;31m# regularize Hessian, not clear what ridge factor should be\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m         \u001b[0;31m# keyword option with absolute default 1e-10, see #1847\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py\u001b[0m in \u001b[0;36mhess\u001b[0;34m(params, *args)\u001b[0m\n\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mhess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 509\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhessian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/statsmodels/discrete/discrete_model.py\u001b[0m in \u001b[0;36mhessian\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m   1967\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexog\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1968\u001b[0m         \u001b[0mL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1969\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1970\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1971\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mAppender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDiscreteModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "0.457480 Doc2Vec(dbow,d100,n5,mc2,t2)+Doc2Vec(\"alpha=0.05\",dm/m,d100,n5,w10,mc2,t2)\n",
            "\n",
            "\n",
            "Evaluating Doc2Vec(dbow,d100,n5,mc2,t2)+Doc2Vec(dm/c,d100,n5,w5,mc2,t2)\n",
            "CPU times: user 2.19 s, sys: 549 ms, total: 2.74 s\n",
            "Wall time: 1.55 s\n",
            "\n",
            "0.104480 Doc2Vec(dbow,d100,n5,mc2,t2)+Doc2Vec(dm/c,d100,n5,w5,mc2,t2)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for model in [models_by_name['dbow+dmm'], models_by_name['dbow+dmc']]:\n",
        "    print(\"\\nEvaluating %s\" % model)\n",
        "    %time err_rate, err_count, test_count, predictor = error_rate_for_model(model, train_docs, test_docs)\n",
        "    error_rates[str(model)] = err_rate\n",
        "    print(\"\\n%f %s\\n\" % (err_rate, model))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LEyXRG1VX6zq"
      },
      "source": [
        "### Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q52FVhBfX59d"
      },
      "outputs": [],
      "source": [
        "# Compare error rates achieved, best-to-worst\n",
        "print(\"Err_rate Model\")\n",
        "for rate, name in sorted((rate, name) for name, rate in error_rates.items()):\n",
        "    print(rate, name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47fPgYn0glWb"
      },
      "source": [
        "In our testing, contrary to the results of the paper, on this problem, PV-DBOW alone performs as good as anything else. Concatenating vectors from different models only sometimes offers a tiny predictive improvement – and stays generally close to the best-performing solo model included.\n",
        "\n",
        "The best results achieved here are just around 10% error rate, still a long way from the paper's reported 7.42% error rate.\n",
        "\n",
        "(Other trials not shown, with larger vectors and other changes, also don't come close to the paper's reported value. Others around the net have reported a similar inability to reproduce the paper's best numbers. The PV-DM/C mode improves a bit with many more training epochs – but doesn't reach parity with PV-DBOW.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MmSbhdlQlQV"
      },
      "source": [
        "Play with pretrained Doc2Vec model by yourself! The pretrained models can be found [here](https://github.com/jhlau/doc2vec)."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "sZYgBIdIVoR2"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}